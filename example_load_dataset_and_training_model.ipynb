{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "convertible-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from detanet_model import *\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "associate-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129817"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''First, the pytorch library can be used to load the dataset, which consists of 130K molecules, after importing the pytorch library.'''\n",
    "dataset=torch.load('qm9s.pt')\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f268e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 20], pos=[5, 3], number=1, smile='C', z=[5], quadrupole=[1, 3, 3], octapole=[1, 3, 3, 3], npacharge=[5], dipole=[1, 3], polar=[1, 3, 3], hyperpolar=[1, 3, 3, 3], energy=[1, 1], Hij=[20, 3, 3], Hi=[5, 3, 3], dedipole=[5, 3, 3], depolar=[5, 3, 6], tran_dipole=[1, 10, 3], tran_energy=[1, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''where each molecule is a gemetric.data.Data. containing coordinates, atomic numbers, edge indices, and various properties.'''\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797f5a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123326, 6491)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We divided the dataset evenly and used 5% of the data for testing and other for training:'''\n",
    "train_datasets=[]\n",
    "val_datasets=[]\n",
    "for i in range(len(dataset)):\n",
    "    if i%20==0:\n",
    "        val_datasets.append(dataset[i])\n",
    "    else:\n",
    "        train_datasets.append(dataset[i])\n",
    "        \n",
    "len(train_datasets),len(val_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1670e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Using torch_Geometric.dataloader.DataLoader Converts a dataset into a batch of 64 molecules of training data.'''\n",
    "bathes=64\n",
    "trainloader=DataLoader(train_datasets,batch_size=bathes,shuffle=True)\n",
    "valloader=DataLoader(val_datasets,batch_size=bathes,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "010b9f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetaNet(\n",
       "  (Embedding): Embedding(\n",
       "    (act): Swish()\n",
       "    (elec_emb): Linear(in_features=16, out_features=128, bias=False)\n",
       "    (nuclare_emb): Embedding(10, 128)\n",
       "    (ls): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (Radial): Radial_Basis(\n",
       "    (radial): Bessel_Function()\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Interaction_Block(\n",
       "      (message): Message(\n",
       "        (Attention): Edge_Attention(\n",
       "          (actq): Swish()\n",
       "          (actk): Swish()\n",
       "          (actv): Swish()\n",
       "          (acta): Swish()\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (lq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (la): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (lrbf): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (lkrbf): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (lvrbf): Linear(in_features=128, out_features=256, bias=False)\n",
       "        )\n",
       "        (tp): TensorProduct(128x0e x 1x1o+1x2e+1x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "      )\n",
       "      (update): Update(\n",
       "        (actu): Swish()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (outt): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "        (outs): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (uattn): Tensorproduct_Attention(\n",
       "          (lq): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lk): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lv): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (ls): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (lvs): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tp1): TensorProduct(128x1o+128x2e+128x3o x 128x1o+128x2e+128x3o -> 128x0e | 384 paths | 0 weights)\n",
       "          (tp2): TensorProduct(128x0e x 128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (actlvs): Swish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Interaction_Block(\n",
       "      (message): Message(\n",
       "        (Attention): Edge_Attention(\n",
       "          (actq): Swish()\n",
       "          (actk): Swish()\n",
       "          (actv): Swish()\n",
       "          (acta): Swish()\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (lq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (la): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (lrbf): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (lkrbf): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (lvrbf): Linear(in_features=128, out_features=256, bias=False)\n",
       "        )\n",
       "        (tp): TensorProduct(128x0e x 1x1o+1x2e+1x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "      )\n",
       "      (update): Update(\n",
       "        (actu): Swish()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (outt): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "        (outs): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (uattn): Tensorproduct_Attention(\n",
       "          (lq): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lk): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lv): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (ls): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (lvs): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tp1): TensorProduct(128x1o+128x2e+128x3o x 128x1o+128x2e+128x3o -> 128x0e | 384 paths | 0 weights)\n",
       "          (tp2): TensorProduct(128x0e x 128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (actlvs): Swish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Interaction_Block(\n",
       "      (message): Message(\n",
       "        (Attention): Edge_Attention(\n",
       "          (actq): Swish()\n",
       "          (actk): Swish()\n",
       "          (actv): Swish()\n",
       "          (acta): Swish()\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (lq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (la): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (lrbf): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (lkrbf): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (lvrbf): Linear(in_features=128, out_features=256, bias=False)\n",
       "        )\n",
       "        (tp): TensorProduct(128x0e x 1x1o+1x2e+1x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "      )\n",
       "      (update): Update(\n",
       "        (actu): Swish()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (outt): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "        (outs): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (uattn): Tensorproduct_Attention(\n",
       "          (lq): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lk): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lv): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (ls): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (lvs): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tp1): TensorProduct(128x1o+128x2e+128x3o x 128x1o+128x2e+128x3o -> 128x0e | 384 paths | 0 weights)\n",
       "          (tp2): TensorProduct(128x0e x 128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (actlvs): Swish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (sout): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): Swish()\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''After loading the dataset, we train a model using NPA charge as an example.\n",
    " \tFirstly, construct an untrained model:'''\n",
    "model=DetaNet(num_features=128,\n",
    "                 act='swish',\n",
    "                 maxl=3,\n",
    "                 num_block=3,\n",
    "                 radial_type='trainable_bessel',\n",
    "                 num_radial=32,\n",
    "                 attention_head=8,\n",
    "                 rc=5.0,\n",
    "                 dropout=0.0,\n",
    "                 use_cutoff=False,\n",
    "                 max_atomic_number=9,\n",
    "                 atom_ref=None,\n",
    "                 scale=None,\n",
    "                 scalar_outsize=1,\n",
    "                 irreps_out=None,\n",
    "                 summation=False,\n",
    "                 norm=False,\n",
    "                 out_type='scalar',\n",
    "                 grad_type=None ,\n",
    "                 device=torch.device('cuda'))\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reverse-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Next, define the trainer and the parameters used for training.'''\n",
    "class Trainer:\n",
    "    def __init__(self,model,train_loader,val_loader=None,loss_function=l2loss,device=torch.device('cuda'),\n",
    "                 optimizer='Adam_amsgrad',lr=5e-4,weight_decay=0):\n",
    "        self.opt_type=optimizer\n",
    "        self.device=device\n",
    "        self.model=model\n",
    "        self.train_data=train_loader\n",
    "        self.val_data=val_loader\n",
    "        self.device=device\n",
    "        self.opts={'AdamW':torch.optim.AdamW(self.model.parameters(),lr=lr,amsgrad=False,weight_decay=weight_decay),\n",
    "              'AdamW_amsgrad':torch.optim.AdamW(self.model.parameters(),lr=lr,amsgrad=True,weight_decay=weight_decay),\n",
    "              'Adam':torch.optim.Adam(self.model.parameters(),lr=lr,amsgrad=False,weight_decay=weight_decay),\n",
    "              'Adam_amsgrad':torch.optim.Adam(self.model.parameters(),lr=lr,amsgrad=True,weight_decay=weight_decay),\n",
    "              'Adadelta':torch.optim.Adadelta(self.model.parameters(),lr=lr,weight_decay=weight_decay),\n",
    "              'RMSprop':torch.optim.RMSprop(self.model.parameters(),lr=lr,weight_decay=weight_decay),\n",
    "              'SGD':torch.optim.SGD(self.model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "        }\n",
    "        self.optimizer=self.opts[self.opt_type]\n",
    "        self.loss_function=loss_function\n",
    "        self.step=-1\n",
    "    def train(self,num_train,targ,stop_loss=1e-8, val_per_train=50, print_per_epoch=10):\n",
    "        self.model.train()\n",
    "        len_train=len(self.train_data)\n",
    "        for i in range(num_train):\n",
    "            val_datas=iter(self.val_data)\n",
    "            for j,batch in enumerate(self.train_data):\n",
    "                self.step=self.step+1\n",
    "                torch.cuda.empty_cache()\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(pos=batch.pos.to(self.device), z=batch.z.to(self.device),\n",
    "                                     batch=batch.batch.to(self.device))\n",
    "                target = batch[targ].to(self.device)\n",
    "                loss = self.loss_function(out.reshape(target.shape),target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if (self.step%val_per_train==0) and (self.val_data is not None):\n",
    "                    val_batch = next(val_datas)\n",
    "                    val_target=val_batch[targ].to(self.device).reshape(-1)\n",
    "\n",
    "                    val_out = self.model(pos=val_batch.pos.to(self.device), z=val_batch.z.to(self.device),\n",
    "                                             batch=val_batch.batch.to(self.device)).reshape(val_target.shape)\n",
    "                    val_loss = self.loss_function(val_out, val_target).item()\n",
    "                    val_mae=l1loss(val_out, val_target).item()\n",
    "                    val_R2=R2(val_out,val_target).item()\n",
    "                    if self.step % print_per_epoch==0:\n",
    "                        print('Epoch[{}/{}],loss:{:.8f},val_loss:{:.8f},val_mae:{:.8f},val_R2:{:.8f}'\n",
    "                              .format(self.step,num_train*len_train,loss.item(),val_loss,val_mae,val_R2))\n",
    "\n",
    "                    assert (loss > stop_loss) or (val_loss > stop_loss),'Training and prediction Loss is less' \\\n",
    "                                                                        ' than cut-off Loss, so training stops'\n",
    "                elif (self.step % print_per_epoch == 0) and (self.step%val_per_train!=0):\n",
    "                    print('Epoch[{}/{}],loss:{:.8f}'.format(self.step,num_train*len_train, loss.item()))\n",
    "                    \n",
    "    def load_state_and_optimizer(self,state_path=None,optimizer_path=None):\n",
    "        if state_path is not None:\n",
    "            state_dict=torch.load(state_path)\n",
    "            self.model.load_state_dict(state_dict)\n",
    "        if optimizer_path is not None:\n",
    "            self.optimizer=torch.load(optimizer_path)\n",
    "\n",
    "    def save_param(self,path):\n",
    "        torch.save(self.model.state_dict(),path)\n",
    "\n",
    "    def save_model(self,path):\n",
    "        torch.save(self.model, path)\n",
    "\n",
    "    def save_opt(self,path):\n",
    "        torch.save(self.optimizer,path)\n",
    "\n",
    "    def params(self):\n",
    "        return self.model.state_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1acc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Then, modify the data type and device type'''\n",
    "device=torch.device('cuda')\n",
    "dtype=torch.float32\n",
    "model=model.to(dtype)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d1c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Finally, using the trainer, training 20 times from a 5e-4 learning rate'''\n",
    "trainer=Trainer(model,train_loader=trainloader,val_loader=valloader,loss_function=l2loss,lr=1e-5,weight_decay=0,optimizer='AdamW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8ea7b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/1927],loss:0.06453520,val_loss:0.09647646,val_mae:0.26150602,val_R2:0.05411941\n",
      "Epoch[10/1927],loss:0.03383980\n",
      "Epoch[20/1927],loss:0.02285156\n",
      "Epoch[30/1927],loss:0.01284886\n",
      "Epoch[40/1927],loss:0.01130290\n",
      "Epoch[50/1927],loss:0.00883452,val_loss:0.01035036,val_mae:0.06626014,val_R2:0.90387326\n",
      "Epoch[60/1927],loss:0.00643805\n",
      "Epoch[70/1927],loss:0.00432105\n",
      "Epoch[80/1927],loss:0.00278638\n",
      "Epoch[90/1927],loss:0.00219296\n",
      "Epoch[100/1927],loss:0.00170563,val_loss:0.00196205,val_mae:0.02748346,val_R2:0.98102534\n",
      "Epoch[110/1927],loss:0.00193614\n",
      "Epoch[120/1927],loss:0.00124189\n",
      "Epoch[130/1927],loss:0.00122081\n",
      "Epoch[140/1927],loss:0.00109711\n",
      "Epoch[150/1927],loss:0.00093220,val_loss:0.00098367,val_mae:0.02152115,val_R2:0.99056077\n",
      "Epoch[160/1927],loss:0.00097455\n",
      "Epoch[170/1927],loss:0.00074644\n",
      "Epoch[180/1927],loss:0.00097347\n",
      "Epoch[190/1927],loss:0.00087645\n",
      "Epoch[200/1927],loss:0.00071156,val_loss:0.00069464,val_mae:0.01792950,val_R2:0.99369150\n",
      "Epoch[210/1927],loss:0.00066975\n",
      "Epoch[220/1927],loss:0.00076993\n",
      "Epoch[230/1927],loss:0.00059851\n",
      "Epoch[240/1927],loss:0.00050863\n",
      "Epoch[250/1927],loss:0.00050260,val_loss:0.00044664,val_mae:0.01467644,val_R2:0.99582475\n",
      "Epoch[260/1927],loss:0.00050208\n",
      "Epoch[270/1927],loss:0.00040928\n",
      "Epoch[280/1927],loss:0.00040987\n",
      "Epoch[290/1927],loss:0.00039177\n",
      "Epoch[300/1927],loss:0.00032747,val_loss:0.00045864,val_mae:0.01462913,val_R2:0.99583966\n",
      "Epoch[310/1927],loss:0.00037078\n",
      "Epoch[320/1927],loss:0.00032542\n",
      "Epoch[330/1927],loss:0.00045079\n",
      "Epoch[340/1927],loss:0.00033930\n",
      "Epoch[350/1927],loss:0.00029844,val_loss:0.00038052,val_mae:0.01219143,val_R2:0.99639642\n",
      "Epoch[360/1927],loss:0.00026908\n",
      "Epoch[370/1927],loss:0.00043146\n",
      "Epoch[380/1927],loss:0.00028666\n",
      "Epoch[390/1927],loss:0.00023302\n",
      "Epoch[400/1927],loss:0.00026638,val_loss:0.00026076,val_mae:0.01114795,val_R2:0.99749947\n",
      "Epoch[410/1927],loss:0.00024293\n",
      "Epoch[420/1927],loss:0.00029338\n",
      "Epoch[430/1927],loss:0.00033772\n",
      "Epoch[440/1927],loss:0.00027230\n",
      "Epoch[450/1927],loss:0.00031892,val_loss:0.00026805,val_mae:0.01130458,val_R2:0.99754846\n",
      "Epoch[460/1927],loss:0.00027333\n",
      "Epoch[470/1927],loss:0.00025254\n",
      "Epoch[480/1927],loss:0.00018468\n",
      "Epoch[490/1927],loss:0.00022127\n",
      "Epoch[500/1927],loss:0.00030861,val_loss:0.00020176,val_mae:0.00988733,val_R2:0.99818671\n",
      "Epoch[510/1927],loss:0.00021887\n",
      "Epoch[520/1927],loss:0.00021697\n",
      "Epoch[530/1927],loss:0.00031220\n",
      "Epoch[540/1927],loss:0.00023505\n",
      "Epoch[550/1927],loss:0.00030863,val_loss:0.00028982,val_mae:0.01131398,val_R2:0.99729609\n",
      "Epoch[560/1927],loss:0.00023014\n",
      "Epoch[570/1927],loss:0.00018890\n",
      "Epoch[580/1927],loss:0.00028595\n",
      "Epoch[590/1927],loss:0.00021848\n",
      "Epoch[600/1927],loss:0.00020709,val_loss:0.00022999,val_mae:0.01024003,val_R2:0.99789923\n",
      "Epoch[610/1927],loss:0.00022095\n",
      "Epoch[620/1927],loss:0.00020587\n",
      "Epoch[630/1927],loss:0.00018033\n",
      "Epoch[640/1927],loss:0.00026323\n",
      "Epoch[650/1927],loss:0.00017268,val_loss:0.00018276,val_mae:0.00908111,val_R2:0.99829793\n",
      "Epoch[660/1927],loss:0.00022658\n",
      "Epoch[670/1927],loss:0.00017192\n",
      "Epoch[680/1927],loss:0.00023168\n",
      "Epoch[690/1927],loss:0.00019433\n",
      "Epoch[700/1927],loss:0.00019520,val_loss:0.00022992,val_mae:0.00973312,val_R2:0.99806756\n",
      "Epoch[710/1927],loss:0.00021707\n",
      "Epoch[720/1927],loss:0.00022272\n",
      "Epoch[730/1927],loss:0.00014170\n",
      "Epoch[740/1927],loss:0.00019796\n",
      "Epoch[750/1927],loss:0.00021326,val_loss:0.00018969,val_mae:0.00916320,val_R2:0.99830365\n",
      "Epoch[760/1927],loss:0.00022057\n",
      "Epoch[770/1927],loss:0.00022416\n",
      "Epoch[780/1927],loss:0.00022311\n",
      "Epoch[790/1927],loss:0.00026985\n",
      "Epoch[800/1927],loss:0.00016835,val_loss:0.00016074,val_mae:0.00869422,val_R2:0.99849111\n",
      "Epoch[810/1927],loss:0.00016412\n",
      "Epoch[820/1927],loss:0.00021526\n",
      "Epoch[830/1927],loss:0.00015025\n",
      "Epoch[840/1927],loss:0.00021764\n",
      "Epoch[850/1927],loss:0.00016004,val_loss:0.00025092,val_mae:0.01003307,val_R2:0.99774754\n",
      "Epoch[860/1927],loss:0.00015041\n",
      "Epoch[870/1927],loss:0.00012891\n",
      "Epoch[880/1927],loss:0.00013820\n",
      "Epoch[890/1927],loss:0.00013494\n",
      "Epoch[900/1927],loss:0.00016776,val_loss:0.00015727,val_mae:0.00859733,val_R2:0.99853456\n",
      "Epoch[910/1927],loss:0.00014841\n",
      "Epoch[920/1927],loss:0.00015930\n",
      "Epoch[930/1927],loss:0.00020042\n",
      "Epoch[940/1927],loss:0.00012096\n",
      "Epoch[950/1927],loss:0.00018918,val_loss:0.00015982,val_mae:0.00879411,val_R2:0.99848837\n",
      "Epoch[960/1927],loss:0.00017169\n",
      "Epoch[970/1927],loss:0.00017923\n",
      "Epoch[980/1927],loss:0.00017652\n",
      "Epoch[990/1927],loss:0.00017138\n",
      "Epoch[1000/1927],loss:0.00012766,val_loss:0.00014590,val_mae:0.00865258,val_R2:0.99874562\n",
      "Epoch[1010/1927],loss:0.00019953\n",
      "Epoch[1020/1927],loss:0.00018093\n",
      "Epoch[1030/1927],loss:0.00018850\n",
      "Epoch[1040/1927],loss:0.00016732\n",
      "Epoch[1050/1927],loss:0.00013926,val_loss:0.00014802,val_mae:0.00853072,val_R2:0.99865073\n",
      "Epoch[1060/1927],loss:0.00011718\n",
      "Epoch[1070/1927],loss:0.00013877\n",
      "Epoch[1080/1927],loss:0.00010892\n",
      "Epoch[1090/1927],loss:0.00015349\n",
      "Epoch[1100/1927],loss:0.00014517,val_loss:0.00010865,val_mae:0.00745918,val_R2:0.99898595\n",
      "Epoch[1110/1927],loss:0.00011767\n",
      "Epoch[1120/1927],loss:0.00016412\n",
      "Epoch[1130/1927],loss:0.00017561\n",
      "Epoch[1140/1927],loss:0.00013201\n",
      "Epoch[1150/1927],loss:0.00017868,val_loss:0.00009873,val_mae:0.00681628,val_R2:0.99898309\n",
      "Epoch[1160/1927],loss:0.00011667\n",
      "Epoch[1170/1927],loss:0.00013225\n",
      "Epoch[1180/1927],loss:0.00012412\n",
      "Epoch[1190/1927],loss:0.00012013\n",
      "Epoch[1200/1927],loss:0.00010947,val_loss:0.00012665,val_mae:0.00845093,val_R2:0.99887913\n",
      "Epoch[1210/1927],loss:0.00015703\n",
      "Epoch[1220/1927],loss:0.00017510\n",
      "Epoch[1230/1927],loss:0.00016446\n",
      "Epoch[1240/1927],loss:0.00020590\n",
      "Epoch[1250/1927],loss:0.00012213,val_loss:0.00012575,val_mae:0.00841152,val_R2:0.99878156\n",
      "Epoch[1260/1927],loss:0.00017205\n",
      "Epoch[1270/1927],loss:0.00021445\n",
      "Epoch[1280/1927],loss:0.00014995\n",
      "Epoch[1290/1927],loss:0.00014478\n",
      "Epoch[1300/1927],loss:0.00012722,val_loss:0.00015496,val_mae:0.00796724,val_R2:0.99853599\n",
      "Epoch[1310/1927],loss:0.00012551\n",
      "Epoch[1320/1927],loss:0.00012118\n",
      "Epoch[1330/1927],loss:0.00008937\n",
      "Epoch[1340/1927],loss:0.00012551\n",
      "Epoch[1350/1927],loss:0.00012044,val_loss:0.00015699,val_mae:0.00912481,val_R2:0.99856645\n",
      "Epoch[1360/1927],loss:0.00013817\n",
      "Epoch[1370/1927],loss:0.00010001\n",
      "Epoch[1380/1927],loss:0.00011411\n",
      "Epoch[1390/1927],loss:0.00015399\n",
      "Epoch[1400/1927],loss:0.00011805,val_loss:0.00014067,val_mae:0.00911630,val_R2:0.99870121\n",
      "Epoch[1410/1927],loss:0.00013116\n",
      "Epoch[1420/1927],loss:0.00011919\n",
      "Epoch[1430/1927],loss:0.00013316\n",
      "Epoch[1440/1927],loss:0.00014393\n",
      "Epoch[1450/1927],loss:0.00011337,val_loss:0.00021040,val_mae:0.01162039,val_R2:0.99815983\n",
      "Epoch[1460/1927],loss:0.00026785\n",
      "Epoch[1470/1927],loss:0.00013814\n",
      "Epoch[1480/1927],loss:0.00022951\n",
      "Epoch[1490/1927],loss:0.00012374\n",
      "Epoch[1500/1927],loss:0.00010404,val_loss:0.00014543,val_mae:0.00948186,val_R2:0.99857223\n",
      "Epoch[1510/1927],loss:0.00018024\n",
      "Epoch[1520/1927],loss:0.00010609\n",
      "Epoch[1530/1927],loss:0.00011266\n",
      "Epoch[1540/1927],loss:0.00011525\n",
      "Epoch[1550/1927],loss:0.00018853,val_loss:0.00017093,val_mae:0.01033098,val_R2:0.99838769\n",
      "Epoch[1560/1927],loss:0.00012965\n",
      "Epoch[1570/1927],loss:0.00014077\n",
      "Epoch[1580/1927],loss:0.00014124\n",
      "Epoch[1590/1927],loss:0.00013549\n",
      "Epoch[1600/1927],loss:0.00010631,val_loss:0.00012666,val_mae:0.00749614,val_R2:0.99882817\n",
      "Epoch[1610/1927],loss:0.00013628\n",
      "Epoch[1620/1927],loss:0.00014637\n",
      "Epoch[1630/1927],loss:0.00013596\n",
      "Epoch[1640/1927],loss:0.00010527\n",
      "Epoch[1650/1927],loss:0.00015433,val_loss:0.00009606,val_mae:0.00708031,val_R2:0.99904180\n",
      "Epoch[1660/1927],loss:0.00011826\n",
      "Epoch[1670/1927],loss:0.00016220\n",
      "Epoch[1680/1927],loss:0.00017137\n",
      "Epoch[1690/1927],loss:0.00010718\n",
      "Epoch[1700/1927],loss:0.00017252,val_loss:0.00014046,val_mae:0.00843952,val_R2:0.99864203\n",
      "Epoch[1710/1927],loss:0.00016520\n",
      "Epoch[1720/1927],loss:0.00011735\n",
      "Epoch[1730/1927],loss:0.00012219\n",
      "Epoch[1740/1927],loss:0.00010489\n",
      "Epoch[1750/1927],loss:0.00010095,val_loss:0.00011669,val_mae:0.00729438,val_R2:0.99887276\n",
      "Epoch[1760/1927],loss:0.00013568\n",
      "Epoch[1770/1927],loss:0.00012609\n",
      "Epoch[1780/1927],loss:0.00015097\n",
      "Epoch[1790/1927],loss:0.00015687\n",
      "Epoch[1800/1927],loss:0.00015342,val_loss:0.00018826,val_mae:0.01046325,val_R2:0.99810684\n",
      "Epoch[1810/1927],loss:0.00017898\n",
      "Epoch[1820/1927],loss:0.00012087\n",
      "Epoch[1830/1927],loss:0.00010379\n",
      "Epoch[1840/1927],loss:0.00014565\n",
      "Epoch[1850/1927],loss:0.00012363,val_loss:0.00013839,val_mae:0.00833107,val_R2:0.99863178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1860/1927],loss:0.00012250\n",
      "Epoch[1870/1927],loss:0.00011756\n",
      "Epoch[1880/1927],loss:0.00034985\n",
      "Epoch[1890/1927],loss:0.00022203\n",
      "Epoch[1900/1927],loss:0.00012808,val_loss:0.00011116,val_mae:0.00736343,val_R2:0.99896818\n",
      "Epoch[1910/1927],loss:0.00011418\n",
      "Epoch[1920/1927],loss:0.00008459\n"
     ]
    }
   ],
   "source": [
    "trainer.train(num_train=20,targ='npacharge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4d3a45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Embedding.act.alpha',\n",
       "              tensor([0.9962, 0.9973, 0.9957, 0.9963, 0.9970, 0.9955, 0.9992, 0.9982, 0.9989,\n",
       "                      0.9986, 0.9998, 0.9981, 0.9985, 1.0003, 0.9984, 0.9977, 0.9996, 0.9986,\n",
       "                      0.9977, 0.9981, 0.9999, 0.9982, 1.0006, 1.0010, 0.9995, 0.9943, 0.9993,\n",
       "                      0.9981, 1.0002, 0.9980, 0.9988, 0.9987, 0.9986, 0.9991, 0.9979, 1.0001,\n",
       "                      0.9977, 0.9989, 0.9933, 1.0012, 0.9985, 0.9986, 1.0006, 1.0005, 0.9991,\n",
       "                      0.9958, 0.9984, 0.9982, 0.9971, 0.9978, 0.9963, 0.9995, 0.9972, 0.9947,\n",
       "                      0.9982, 0.9947, 0.9979, 1.0004, 0.9943, 0.9986, 0.9994, 0.9996, 0.9954,\n",
       "                      1.0031, 0.9999, 0.9978, 0.9997, 0.9979, 1.0004, 0.9998, 0.9987, 0.9994,\n",
       "                      0.9980, 0.9966, 0.9999, 0.9983, 0.9955, 0.9986, 0.9960, 0.9936, 1.0008,\n",
       "                      0.9938, 0.9968, 0.9962, 0.9958, 0.9984, 0.9957, 1.0001, 0.9967, 0.9959,\n",
       "                      0.9994, 0.9981, 0.9956, 0.9963, 0.9987, 0.9982, 0.9934, 0.9995, 0.9982,\n",
       "                      0.9979, 0.9978, 0.9980, 0.9993, 0.9997, 0.9994, 0.9987, 0.9982, 0.9981,\n",
       "                      0.9946, 0.9959, 0.9992, 0.9975, 0.9977, 0.9971, 1.0007, 0.9945, 0.9958,\n",
       "                      1.0002, 1.0001, 0.9965, 0.9989, 0.9922, 0.9941, 0.9975, 0.9988, 1.0004,\n",
       "                      0.9989, 0.9939], device='cuda:0')),\n",
       "             ('Embedding.act.beta',\n",
       "              tensor([1.7003, 1.7009, 1.6966, 1.6985, 1.6990, 1.7053, 1.7019, 1.7040, 1.7023,\n",
       "                      1.7014, 1.7005, 1.7022, 1.7007, 1.7020, 1.7014, 1.7017, 1.7023, 1.7007,\n",
       "                      1.7024, 1.7030, 1.7019, 1.7004, 1.7028, 1.7048, 1.7009, 1.7024, 1.7030,\n",
       "                      1.7007, 1.7024, 1.6996, 1.7048, 1.7030, 1.7029, 1.7032, 1.7012, 1.7030,\n",
       "                      1.7010, 1.7010, 1.7010, 1.7016, 1.7015, 1.7026, 1.7038, 1.7033, 1.7029,\n",
       "                      1.6995, 1.7038, 1.7009, 1.7001, 1.7024, 1.6983, 1.7084, 1.6966, 1.7002,\n",
       "                      1.7042, 1.6987, 1.7028, 1.7033, 1.6966, 1.7013, 1.7032, 1.7015, 1.7016,\n",
       "                      1.6897, 1.7019, 1.7009, 1.7010, 1.7034, 1.7039, 1.7021, 1.7006, 1.7020,\n",
       "                      1.7023, 1.7018, 1.6976, 1.7012, 1.6982, 1.7005, 1.7025, 1.7033, 1.7022,\n",
       "                      1.7006, 1.7065, 1.6981, 1.7003, 1.7015, 1.7020, 1.7049, 1.7049, 1.7057,\n",
       "                      1.7027, 1.7030, 1.7020, 1.7015, 1.7021, 1.7008, 1.6968, 1.7041, 1.7027,\n",
       "                      1.7011, 1.7029, 1.6996, 1.7035, 1.7026, 1.7023, 1.6995, 1.7027, 1.7004,\n",
       "                      1.6986, 1.7003, 1.7014, 1.7016, 1.6998, 1.7032, 1.7034, 1.7020, 1.7003,\n",
       "                      1.7028, 1.7004, 1.7013, 1.7034, 1.7012, 1.7069, 1.7015, 1.7034, 1.7012,\n",
       "                      1.7011, 1.6994], device='cuda:0')),\n",
       "             ('Embedding.elec_emb.weight',\n",
       "              tensor([[-0.2022, -0.0816,  0.0697,  ...,  0.0409,  0.0920,  0.0732],\n",
       "                      [ 0.1557, -0.0441,  0.0280,  ...,  0.0168,  0.0528,  0.0146],\n",
       "                      [-0.1097,  0.1105, -0.1493,  ..., -0.0126,  0.0381, -0.0901],\n",
       "                      ...,\n",
       "                      [ 0.0621,  0.1702, -0.0305,  ...,  0.0875,  0.0937, -0.0209],\n",
       "                      [-0.1965, -0.1161,  0.0299,  ...,  0.1391, -0.2024, -0.0906],\n",
       "                      [-0.0983,  0.0742, -0.0499,  ..., -0.0714, -0.0590, -0.1166]],\n",
       "                     device='cuda:0')),\n",
       "             ('Embedding.nuclare_emb.weight',\n",
       "              tensor([[ 1.1051, -0.7603, -0.6517,  ...,  0.5555,  0.2526,  1.1166],\n",
       "                      [-0.6822,  0.6432, -0.7677,  ...,  0.6910, -0.5178,  1.3518],\n",
       "                      [-1.2499,  0.5282, -2.4507,  ..., -2.0302, -0.2078,  2.2681],\n",
       "                      ...,\n",
       "                      [-0.1249, -0.2163, -1.8242,  ..., -0.1301,  0.9147,  0.1820],\n",
       "                      [-0.6836,  0.5820,  0.2711,  ...,  0.4494,  0.6044,  0.4724],\n",
       "                      [-0.6447, -0.0439, -0.4623,  ..., -0.5125,  1.1476, -2.1015]],\n",
       "                     device='cuda:0')),\n",
       "             ('Embedding.ls.weight',\n",
       "              tensor([[-0.0552,  0.0085, -0.0478,  ..., -0.0613,  0.0650, -0.0096],\n",
       "                      [-0.0783, -0.1371,  0.1084,  ...,  0.0639, -0.0682,  0.1257],\n",
       "                      [-0.0431,  0.0909,  0.0175,  ...,  0.0883,  0.1391, -0.0967],\n",
       "                      ...,\n",
       "                      [-0.0477,  0.0198, -0.0821,  ...,  0.1145,  0.1497, -0.1310],\n",
       "                      [-0.1492, -0.1169,  0.0434,  ..., -0.0597,  0.1042,  0.1157],\n",
       "                      [-0.0517, -0.0442, -0.1337,  ..., -0.0848, -0.0283, -0.0738]],\n",
       "                     device='cuda:0')),\n",
       "             ('Embedding.ls.bias',\n",
       "              tensor([ 5.1866e-04, -1.7548e-03, -6.9878e-04, -2.5489e-03, -3.4926e-03,\n",
       "                      -2.7299e-03,  3.2170e-04, -9.1366e-04,  1.5571e-03, -1.3309e-03,\n",
       "                       3.3121e-04, -1.9977e-03, -6.2075e-03,  6.8106e-04, -5.1853e-04,\n",
       "                      -1.1961e-03, -3.7915e-04,  1.1718e-03, -2.3935e-03, -1.1814e-03,\n",
       "                       7.0183e-04, -1.7605e-03,  1.1416e-03, -3.6062e-03,  4.5587e-04,\n",
       "                      -1.4866e-03,  8.6582e-04, -1.1978e-03,  8.3733e-04,  2.9552e-04,\n",
       "                      -2.1709e-04, -2.2873e-03, -3.9655e-04,  5.1778e-05, -2.1737e-03,\n",
       "                      -1.6185e-03, -1.7896e-03,  6.4532e-04, -1.9247e-03,  3.2371e-03,\n",
       "                      -6.1251e-04,  7.3873e-04,  1.6659e-03,  1.0975e-03, -3.0981e-04,\n",
       "                      -1.8699e-03, -1.0822e-03, -1.3886e-03, -2.6382e-03, -1.8721e-03,\n",
       "                      -3.0096e-03, -2.3597e-03, -3.0610e-03,  4.6881e-04,  5.0761e-05,\n",
       "                      -7.9474e-03, -1.1346e-03,  5.3974e-04, -2.6736e-03, -7.6056e-04,\n",
       "                      -2.1878e-03,  3.5680e-04, -6.3217e-03,  2.6616e-03,  2.1736e-04,\n",
       "                      -1.0860e-03,  8.9420e-04, -1.8283e-03, -1.5129e-04,  3.6922e-04,\n",
       "                      -1.0960e-03,  4.0006e-04, -1.4738e-03, -2.1183e-03, -1.9698e-03,\n",
       "                       2.9867e-04, -2.1433e-03, -1.1965e-03,  3.5584e-04, -7.0234e-04,\n",
       "                      -2.2447e-03, -6.4023e-03, -6.2294e-04,  1.0781e-03,  3.2239e-04,\n",
       "                      -4.5219e-04, -2.7814e-05,  3.7607e-04, -1.2944e-03, -2.3430e-03,\n",
       "                       3.8612e-04, -1.2412e-05, -3.0221e-03, -1.4725e-04, -3.7637e-04,\n",
       "                      -1.0516e-04, -3.5116e-03, -1.5787e-03, -1.2794e-03,  6.3211e-04,\n",
       "                      -2.9825e-04, -2.8282e-04, -3.3947e-04,  5.4315e-04, -1.2194e-04,\n",
       "                       1.0316e-03, -2.2876e-03, -1.7078e-03, -3.4022e-03, -1.4391e-03,\n",
       "                      -1.0580e-04, -1.4236e-04, -2.2118e-03,  1.2208e-03,  1.5570e-03,\n",
       "                       4.8945e-04, -1.2448e-03,  6.4576e-04,  5.1780e-04, -8.6147e-04,\n",
       "                       1.2821e-03,  6.5211e-05, -4.9206e-03, -1.4471e-03, -1.2493e-04,\n",
       "                       1.0257e-03, -8.9855e-04, -4.9062e-03], device='cuda:0')),\n",
       "             ('Radial.radial.alpha',\n",
       "              tensor([[-2.6754e-03,  1.0170e+00,  1.9960e+00,  2.9883e+00,  4.0136e+00,\n",
       "                        5.0184e+00,  5.9928e+00,  7.0048e+00,  7.9982e+00,  8.9875e+00,\n",
       "                        9.9926e+00,  1.0995e+01,  1.2021e+01,  1.3004e+01,  1.3993e+01,\n",
       "                        1.5006e+01,  1.6003e+01,  1.6997e+01,  1.8018e+01,  1.9006e+01,\n",
       "                        1.9993e+01,  2.1012e+01,  2.2003e+01,  2.3001e+01,  2.4008e+01,\n",
       "                        2.5009e+01,  2.6013e+01,  2.7003e+01,  2.8014e+01,  2.9004e+01,\n",
       "                        3.0006e+01,  3.1048e+01]], device='cuda:0')),\n",
       "             ('Radial.radial.beta',\n",
       "              tensor([[2.0040, 2.0051, 1.9634, 1.9860, 1.9752, 1.9731, 1.9919, 1.9906, 1.9686,\n",
       "                       1.9906, 1.9887, 1.9937, 1.9884, 1.9818, 1.9898, 1.9872, 1.9927, 1.9919,\n",
       "                       1.9948, 1.9777, 1.9953, 1.9974, 1.9844, 1.9779, 1.9894, 1.9991, 1.9980,\n",
       "                       1.9881, 1.9855, 2.0058, 2.0010, 1.9843]], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.actq.alpha',\n",
       "              tensor([1.0290, 1.0840, 1.0219, 1.0868, 1.0555, 1.0134, 0.9975, 0.9971, 1.0504,\n",
       "                      1.0097, 1.0195, 1.0159, 0.9798, 0.9873, 1.0783, 0.9528, 1.0185, 0.9973,\n",
       "                      1.0244, 1.0331, 1.0349, 1.0108, 1.0616, 1.0765, 1.0245, 1.0253, 1.0019,\n",
       "                      1.0370, 1.0096, 1.1113, 1.0599, 1.0626, 0.9946, 1.0570, 1.1085, 1.0788,\n",
       "                      1.1041, 1.0091, 1.0119, 1.0146, 1.0588, 1.0078, 0.9997, 1.0286, 1.0127,\n",
       "                      1.0877, 0.9977, 1.0488, 1.0459, 1.0342, 1.1043, 1.0209, 1.0189, 1.0094,\n",
       "                      1.0502, 1.0028, 1.0485, 1.0182, 1.0533, 1.0394, 1.0435, 1.0908, 1.0751,\n",
       "                      1.0656, 1.0825, 1.0645, 1.0586, 0.9956, 0.9967, 0.9912, 0.9998, 1.0547,\n",
       "                      1.0515, 1.0498, 1.1207, 1.0352, 1.0206, 1.0002, 1.0250, 1.0395, 1.0037,\n",
       "                      1.0887, 1.0053, 1.0408, 1.0565, 0.9979, 0.9973, 1.0053, 0.9991, 1.0274,\n",
       "                      1.0102, 1.0131, 1.0131, 1.0362, 1.0072, 1.0090, 1.0074, 0.9992, 1.0194,\n",
       "                      1.0287, 1.0148, 1.0178, 0.9897, 1.0209, 1.0556, 1.0435, 1.0026, 1.0560,\n",
       "                      0.9974, 1.0187, 1.0090, 1.0520, 1.0219, 1.0465, 1.0172, 1.0728, 1.0584,\n",
       "                      1.0027, 0.9967, 1.0410, 1.0558, 1.0490, 0.9963, 1.0256, 1.0155, 1.0005,\n",
       "                      0.9887, 1.0414], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.actq.beta',\n",
       "              tensor([1.6904, 1.7784, 1.7239, 1.7671, 1.7497, 1.6805, 1.7001, 1.7019, 1.7480,\n",
       "                      1.6962, 1.7132, 1.6874, 1.6860, 1.7133, 1.7225, 1.7284, 1.6942, 1.7370,\n",
       "                      1.7097, 1.7342, 1.7332, 1.6973, 1.7442, 1.7325, 1.7194, 1.7162, 1.7049,\n",
       "                      1.7258, 1.7070, 1.7762, 1.7274, 1.7496, 1.7129, 1.7658, 1.7566, 1.7169,\n",
       "                      1.7483, 1.7106, 1.7041, 1.7059, 1.7343, 1.7159, 1.7099, 1.6556, 1.7113,\n",
       "                      1.6965, 1.7109, 1.7165, 1.6804, 1.7182, 1.7444, 1.7189, 1.7170, 1.7090,\n",
       "                      1.7340, 1.7001, 1.7022, 1.6973, 1.7177, 1.7475, 1.7052, 1.7024, 1.7480,\n",
       "                      1.7347, 1.7529, 1.7120, 1.7111, 1.6939, 1.6943, 1.6897, 1.6978, 1.7157,\n",
       "                      1.7072, 1.7114, 1.7224, 1.7244, 1.7189, 1.6875, 1.7023, 1.7236, 1.6925,\n",
       "                      1.7199, 1.7054, 1.7026, 1.7248, 1.6997, 1.6967, 1.6929, 1.7069, 1.7260,\n",
       "                      1.7088, 1.7225, 1.6921, 1.7253, 1.7026, 1.7546, 1.6975, 1.6695, 1.7200,\n",
       "                      1.6815, 1.6893, 1.6949, 1.7148, 1.7142, 1.7155, 1.7320, 1.7003, 1.7082,\n",
       "                      1.7079, 1.6991, 1.6935, 1.7217, 1.7207, 1.7479, 1.7264, 1.7148, 1.7118,\n",
       "                      1.7019, 1.7010, 1.7343, 1.7092, 1.7334, 1.6976, 1.6960, 1.7155, 1.7105,\n",
       "                      1.6958, 1.7521], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.actk.alpha',\n",
       "              tensor([0.9972, 1.1223, 1.0269, 0.9890, 0.9914, 0.9980, 0.9890, 1.0119, 1.0003,\n",
       "                      1.0221, 1.0000, 0.9938, 1.0041, 1.0024, 1.0127, 1.0781, 1.0647, 1.1055,\n",
       "                      1.0304, 1.0310, 1.0828, 1.0103, 1.0546, 1.0013, 1.0414, 1.0269, 1.0679,\n",
       "                      1.0531, 1.0372, 1.0255, 1.1641, 1.0737, 1.0682, 1.0872, 1.0315, 1.0137,\n",
       "                      1.0336, 1.0046, 1.0016, 1.0054, 1.0255, 1.0082, 1.0124, 1.0082, 0.9908,\n",
       "                      1.1184, 1.0094, 1.0613, 1.0244, 1.0811, 1.0916, 1.0455, 1.1024, 1.0284,\n",
       "                      0.9957, 1.0107, 1.0622, 0.9996, 1.0101, 1.0144, 1.0071, 1.0368, 1.0462,\n",
       "                      1.0845, 1.0398, 1.0597, 1.0475, 1.0198, 1.0313, 1.0132, 1.0471, 1.0193,\n",
       "                      1.0586, 1.0434, 1.0058, 1.0835, 1.0097, 1.0909, 1.0332, 1.1220, 1.0051,\n",
       "                      1.0941, 1.0580, 1.0896, 1.0113, 1.0088, 1.0106, 1.0235, 1.0632, 1.0623,\n",
       "                      1.0091, 1.0288, 1.0593, 1.0403, 1.0323, 1.0027, 1.0134, 1.0487, 1.0054,\n",
       "                      1.0032, 1.0898, 1.0144, 0.9957, 1.0012, 0.9940, 1.0020, 0.9929, 1.0181,\n",
       "                      1.0612, 1.0799, 1.0033, 1.0144, 1.0038, 1.1402, 1.0494, 1.1468, 1.0941,\n",
       "                      0.9949, 1.0294, 1.1078, 1.0460, 1.0162, 1.0016, 1.0419, 1.0327, 1.0372,\n",
       "                      1.0118, 1.0239], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.actk.beta',\n",
       "              tensor([1.7054, 1.7606, 1.7301, 1.7003, 1.6941, 1.7004, 1.7066, 1.7064, 1.7014,\n",
       "                      1.7255, 1.7004, 1.6965, 1.6887, 1.6801, 1.6884, 1.7461, 1.7514, 1.6449,\n",
       "                      1.6516, 1.7230, 1.7626, 1.7112, 1.7529, 1.6976, 1.6661, 1.7270, 1.7509,\n",
       "                      1.7473, 1.6554, 1.6936, 1.7707, 1.6230, 1.7545, 1.6085, 1.7199, 1.7163,\n",
       "                      1.6396, 1.7063, 1.7012, 1.6912, 1.6724, 1.7040, 1.7140, 1.6943, 1.7088,\n",
       "                      1.7267, 1.7105, 1.7594, 1.6853, 1.7794, 1.7797, 1.6572, 1.7766, 1.7241,\n",
       "                      1.7055, 1.6849, 1.7623, 1.6992, 1.6944, 1.6823, 1.7117, 1.7349, 1.7486,\n",
       "                      1.7725, 1.7134, 1.7213, 1.6836, 1.6734, 1.7229, 1.6854, 1.6378, 1.7190,\n",
       "                      1.7525, 1.7345, 1.7110, 1.7038, 1.6720, 1.7646, 1.6631, 1.7515, 1.6990,\n",
       "                      1.6408, 1.7422, 1.7816, 1.6779, 1.6981, 1.6853, 1.6752, 1.6372, 1.7398,\n",
       "                      1.7035, 1.6774, 1.7229, 1.6620, 1.6969, 1.7031, 1.7150, 1.7369, 1.6954,\n",
       "                      1.7072, 1.7217, 1.6915, 1.7043, 1.7032, 1.6913, 1.6962, 1.7168, 1.7184,\n",
       "                      1.7382, 1.7551, 1.7001, 1.6794, 1.6970, 1.7697, 1.6405, 1.7577, 1.7617,\n",
       "                      1.7096, 1.6907, 1.7565, 1.6568, 1.6709, 1.6904, 1.6850, 1.6613, 1.6980,\n",
       "                      1.7103, 1.7276], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.actv.alpha',\n",
       "              tensor([0.9942, 0.9990, 0.9990, 0.9998, 1.0160, 0.9986, 0.9964, 1.0025, 1.0039,\n",
       "                      1.0063, 1.0024, 0.9966, 1.0223, 1.0052, 0.9984, 1.0025, 1.0071, 1.0092,\n",
       "                      0.9928, 0.9954, 0.9994, 0.9958, 0.9984, 0.9983, 0.9989, 1.0033, 1.0038,\n",
       "                      0.9965, 1.0001, 0.9988, 0.9955, 0.9972, 1.0025, 1.0043, 0.9978, 0.9943,\n",
       "                      1.0585, 0.9973, 0.9986, 0.9952, 0.9998, 1.0033, 0.9969, 0.9951, 0.9966,\n",
       "                      1.0043, 1.0045, 0.9877, 0.9948, 0.9982, 0.9974, 1.0141, 0.9972, 0.9940,\n",
       "                      0.9952, 1.0089, 0.9858, 0.9970, 0.9979, 0.9992, 0.9967, 0.9988, 0.9872,\n",
       "                      0.9967, 0.9996, 0.9967, 1.0086, 1.0028, 0.9938, 0.9899, 0.9942, 1.0055,\n",
       "                      0.9993, 0.9990, 0.9993, 1.0058, 0.9947, 0.9978, 1.0050, 1.0062, 0.9959,\n",
       "                      1.0000, 1.0026, 1.0004, 1.0028, 1.0197, 1.0017, 0.9999, 1.0008, 0.9908,\n",
       "                      1.0061, 1.0022, 0.9962, 0.9949, 0.9949, 1.0024, 0.9887, 1.0013, 0.9953,\n",
       "                      1.0096, 0.9981, 1.0002, 1.0019, 1.0231, 0.9981, 0.9905, 1.0057, 0.9980,\n",
       "                      1.0148, 0.9977, 0.9935, 1.0009, 1.0192, 0.9975, 1.0267, 1.0048, 1.0003,\n",
       "                      1.0133, 0.9841, 1.0241, 1.0205, 1.0048, 1.0026, 1.0100, 1.0156, 1.0315,\n",
       "                      0.9972, 1.0016, 1.0314, 1.0026, 1.0029, 1.0108, 0.9946, 1.0049, 0.9901,\n",
       "                      0.9983, 1.0046, 0.9936, 0.9967, 0.9951, 1.0108, 1.0026, 0.9791, 1.0096,\n",
       "                      1.0017, 1.0032, 0.9916, 1.0116, 0.9995, 1.0010, 0.9968, 1.0014, 1.0010,\n",
       "                      0.9991, 0.9950, 0.9984, 1.0106, 0.9955, 0.9936, 0.9979, 1.0005, 1.0080,\n",
       "                      1.0045, 0.9971, 0.9980, 1.0027, 0.9991, 0.9978, 0.9966, 1.0016, 1.0053,\n",
       "                      1.0000, 0.9984, 1.0017, 0.9951, 1.0228, 0.9901, 0.9983, 0.9969, 0.9993,\n",
       "                      0.9993, 0.9982, 0.9876, 0.9960, 0.9975, 1.0015, 0.9976, 0.9960, 0.9973,\n",
       "                      0.9969, 0.9879, 0.9957, 1.0042, 1.0016, 1.0096, 0.9913, 0.9966, 0.9876,\n",
       "                      1.0383, 1.0080, 1.0000, 0.9979, 0.9953, 0.9984, 1.0012, 0.9952, 1.0158,\n",
       "                      0.9947, 1.0079, 0.9952, 0.9974, 0.9979, 0.9968, 0.9905, 1.0492, 0.9873,\n",
       "                      0.9918, 1.0009, 0.9899, 0.9960, 1.0086, 0.9969, 1.0054, 1.0204, 0.9788,\n",
       "                      0.9991, 0.9981, 0.9874, 0.9696, 1.0091, 1.0316, 0.9987, 0.9979, 0.9878,\n",
       "                      1.0162, 0.9986, 0.9935, 1.0145, 1.0181, 1.0093, 0.9994, 0.9958, 0.9962,\n",
       "                      0.9895, 1.0053, 0.9903, 1.0162, 1.0000, 1.0509, 1.0009, 1.0001, 1.0006,\n",
       "                      0.9986, 1.0035, 0.9972, 1.0004], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.actv.beta',\n",
       "              tensor([1.6959, 1.6978, 1.7005, 1.7021, 1.7165, 1.7020, 1.7042, 1.6989, 1.6962,\n",
       "                      1.7069, 1.7086, 1.7046, 1.6893, 1.6944, 1.6917, 1.7038, 1.6959, 1.7047,\n",
       "                      1.6955, 1.7059, 1.6999, 1.7022, 1.7009, 1.6930, 1.7000, 1.6998, 1.7052,\n",
       "                      1.7049, 1.7027, 1.7013, 1.7051, 1.7046, 1.7042, 1.6974, 1.7072, 1.6999,\n",
       "                      1.7558, 1.7107, 1.7037, 1.7199, 1.7031, 1.7011, 1.6986, 1.7031, 1.6931,\n",
       "                      1.7029, 1.7035, 1.6927, 1.7046, 1.7010, 1.7038, 1.7168, 1.6961, 1.6942,\n",
       "                      1.7119, 1.7031, 1.7031, 1.6989, 1.7036, 1.7007, 1.7116, 1.6993, 1.6868,\n",
       "                      1.6990, 1.7109, 1.6978, 1.6983, 1.7053, 1.7026, 1.6919, 1.7036, 1.6929,\n",
       "                      1.7031, 1.7008, 1.7033, 1.6999, 1.6928, 1.6977, 1.6893, 1.7039, 1.6979,\n",
       "                      1.7049, 1.7049, 1.6946, 1.7002, 1.6909, 1.7032, 1.6978, 1.7033, 1.7050,\n",
       "                      1.7085, 1.7011, 1.6984, 1.6971, 1.6996, 1.7000, 1.7079, 1.7037, 1.7034,\n",
       "                      1.6932, 1.6995, 1.7030, 1.7035, 1.7174, 1.6995, 1.6927, 1.6977, 1.6985,\n",
       "                      1.7185, 1.6977, 1.7052, 1.6992, 1.7381, 1.6930, 1.7374, 1.6915, 1.6956,\n",
       "                      1.7157, 1.7110, 1.7249, 1.6799, 1.7065, 1.7069, 1.6938, 1.6890, 1.7330,\n",
       "                      1.7051, 1.7037, 1.7238, 1.6999, 1.7182, 1.7169, 1.7105, 1.6984, 1.6943,\n",
       "                      1.7034, 1.6968, 1.6953, 1.7031, 1.7035, 1.7129, 1.6999, 1.6803, 1.6988,\n",
       "                      1.6997, 1.7043, 1.7051, 1.7156, 1.7019, 1.7031, 1.7087, 1.7081, 1.6978,\n",
       "                      1.7029, 1.6958, 1.6997, 1.7148, 1.7157, 1.6989, 1.6979, 1.6968, 1.6930,\n",
       "                      1.7068, 1.6985, 1.6939, 1.7043, 1.7012, 1.6996, 1.6993, 1.7019, 1.7100,\n",
       "                      1.7028, 1.7030, 1.7003, 1.7056, 1.7070, 1.6914, 1.7041, 1.6994, 1.7016,\n",
       "                      1.7004, 1.7047, 1.7104, 1.6979, 1.7077, 1.7032, 1.7047, 1.6936, 1.7028,\n",
       "                      1.6971, 1.7107, 1.7070, 1.6957, 1.7031, 1.6901, 1.7086, 1.6984, 1.7070,\n",
       "                      1.6459, 1.6929, 1.7019, 1.7033, 1.7065, 1.7010, 1.7033, 1.7079, 1.7181,\n",
       "                      1.6970, 1.7078, 1.6970, 1.6995, 1.7018, 1.7014, 1.6941, 1.7455, 1.7146,\n",
       "                      1.6950, 1.7005, 1.7026, 1.6977, 1.7097, 1.7080, 1.7082, 1.7166, 1.7105,\n",
       "                      1.7011, 1.6993, 1.7110, 1.7295, 1.6940, 1.7263, 1.6930, 1.7035, 1.6955,\n",
       "                      1.7153, 1.7031, 1.7096, 1.6882, 1.7194, 1.7105, 1.7003, 1.7099, 1.7065,\n",
       "                      1.6914, 1.6979, 1.7126, 1.7044, 1.7018, 1.7374, 1.6959, 1.7021, 1.7005,\n",
       "                      1.6955, 1.6988, 1.7030, 1.7072], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.acta.alpha',\n",
       "              tensor([1.0581, 1.0364, 1.0587, 1.0534, 1.0542, 1.1055, 1.0774, 1.0574, 1.0260,\n",
       "                      1.0915, 1.0769, 1.0373, 1.0189, 1.0431, 1.0480, 1.0699, 1.0565, 1.0402,\n",
       "                      1.0486, 1.0941, 1.1267, 1.0803, 1.0837, 1.0765, 1.0677, 1.0990, 1.0858,\n",
       "                      1.0891, 1.1504, 1.0677, 1.0517, 1.0641, 1.0272, 1.0440, 1.0697, 1.0938,\n",
       "                      1.0400, 1.0859, 1.0350, 1.1035, 1.0632, 1.0491, 1.0469, 1.0367, 1.0700,\n",
       "                      1.0517, 1.0773, 1.0436, 1.0322, 1.0473, 1.0562, 1.0931, 1.0531, 1.1231,\n",
       "                      1.1036, 1.0757, 1.0405, 1.0491, 1.0720, 1.0474, 1.0177, 1.0855, 1.0252,\n",
       "                      1.0146, 1.0625, 1.0325, 1.0293, 1.0618, 1.1289, 1.0357, 1.1007, 1.0386,\n",
       "                      1.0731, 1.0509, 1.0086, 1.0493, 1.0469, 1.0444, 1.0491, 1.0332, 1.1551,\n",
       "                      1.0535, 1.0768, 1.0425, 1.1208, 1.1295, 1.0349, 1.0554, 1.0402, 1.0379,\n",
       "                      1.0403, 1.0513, 1.0815, 1.0266, 1.0466, 1.0384, 1.0766, 1.0374, 1.0448,\n",
       "                      1.0741, 1.0226, 1.0253, 1.0661, 1.0537, 1.0387, 1.0472, 1.0576, 1.1009,\n",
       "                      1.0419, 1.0314, 1.0220, 1.0171, 1.0616, 1.0288, 1.0522, 1.1056, 1.0756,\n",
       "                      1.1012, 1.0160, 1.0088, 1.0402, 1.0395, 1.0599, 1.0408, 1.0953, 1.0515,\n",
       "                      1.0517, 1.0994, 1.0007, 0.9974, 1.0091, 0.9984, 0.9878, 0.9932, 1.0111,\n",
       "                      1.0018, 0.9944, 1.0509, 0.9961, 0.9970, 0.9878, 1.0014, 0.9918, 0.9953,\n",
       "                      1.0011, 0.9941, 1.0156, 1.0058, 0.9984, 1.0023, 0.9995, 0.9937, 0.9919,\n",
       "                      0.9981, 0.9806, 1.0020, 0.9965, 1.0161, 0.9972, 1.0018, 0.9914, 1.0042,\n",
       "                      0.9940, 0.9982, 0.9953, 0.9927, 0.9959, 0.9988, 1.0071, 1.0037, 1.0136,\n",
       "                      1.0013, 0.9918, 1.0045, 0.9934, 1.0065, 0.9960, 0.9939, 1.0133, 1.0203,\n",
       "                      0.9974, 0.9930, 0.9804, 0.9959, 0.9961, 1.0038, 1.0069, 1.0133, 1.0157,\n",
       "                      1.0190, 0.9990, 0.9961, 1.0040, 0.9969, 0.9996, 0.9941, 1.0140, 1.0041,\n",
       "                      0.9915, 1.0010, 0.9959, 0.9925, 0.9996, 1.0007, 0.9984, 0.9888, 0.9937,\n",
       "                      0.9947, 0.9983, 1.0037, 0.9975, 1.0001, 1.0051, 0.9989, 0.9967, 0.9975,\n",
       "                      0.9931, 0.9899, 0.9945, 1.0037, 1.0077, 0.9953, 1.0167, 0.9965, 0.9975,\n",
       "                      0.9928, 0.9869, 0.9997, 0.9970, 0.9964, 1.0017, 0.9835, 1.0025, 1.0019,\n",
       "                      0.9985, 1.0063, 0.9972, 0.9966, 0.9983, 1.0018, 0.9967, 0.9964, 0.9962,\n",
       "                      1.0019, 0.9984, 1.0090, 1.0002, 0.9990, 0.9963, 0.9972, 0.9922, 1.0038,\n",
       "                      0.9934, 1.0302, 0.9974, 0.9965], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.acta.beta',\n",
       "              tensor([1.7741, 1.6894, 1.7229, 1.6621, 1.6663, 1.6975, 1.7016, 1.7340, 1.6928,\n",
       "                      1.6022, 1.7186, 1.7377, 1.7096, 1.6732, 1.6779, 1.7658, 1.7389, 1.6909,\n",
       "                      1.7387, 1.6613, 1.7608, 1.7141, 1.7083, 1.6861, 1.6937, 1.6569, 1.7090,\n",
       "                      1.7335, 1.7250, 1.6421, 1.7172, 1.6281, 1.6940, 1.7018, 1.7079, 1.6783,\n",
       "                      1.6827, 1.6954, 1.7045, 1.7044, 1.7701, 1.7066, 1.6891, 1.7243, 1.7325,\n",
       "                      1.6868, 1.6317, 1.7442, 1.6692, 1.7271, 1.6213, 1.7129, 1.7138, 1.7497,\n",
       "                      1.7158, 1.6718, 1.6590, 1.6355, 1.7643, 1.6709, 1.6745, 1.7031, 1.7122,\n",
       "                      1.6739, 1.7332, 1.7328, 1.7276, 1.7106, 1.7558, 1.7105, 1.7491, 1.7057,\n",
       "                      1.7208, 1.6561, 1.7036, 1.7556, 1.7250, 1.7252, 1.6893, 1.7066, 1.5966,\n",
       "                      1.6843, 1.7061, 1.7436, 1.7965, 1.7978, 1.7046, 1.7323, 1.6791, 1.6845,\n",
       "                      1.6695, 1.6646, 1.7011, 1.6896, 1.6955, 1.7180, 1.8061, 1.7020, 1.6873,\n",
       "                      1.7139, 1.7209, 1.7147, 1.7078, 1.6940, 1.7184, 1.7433, 1.7525, 1.7472,\n",
       "                      1.7294, 1.7134, 1.6963, 1.7040, 1.6655, 1.7010, 1.6620, 1.7480, 1.7849,\n",
       "                      1.7872, 1.7043, 1.6957, 1.7109, 1.7259, 1.7151, 1.7255, 1.7961, 1.6166,\n",
       "                      1.6952, 1.7379, 1.6975, 1.6911, 1.6958, 1.7072, 1.7087, 1.7018, 1.6915,\n",
       "                      1.6808, 1.6856, 1.7334, 1.7035, 1.6869, 1.7014, 1.6959, 1.6975, 1.7113,\n",
       "                      1.7064, 1.7077, 1.6915, 1.6981, 1.6974, 1.7170, 1.7098, 1.7000, 1.7083,\n",
       "                      1.6588, 1.6778, 1.6848, 1.6929, 1.6522, 1.7139, 1.6995, 1.6983, 1.7049,\n",
       "                      1.7132, 1.7213, 1.7029, 1.7374, 1.7074, 1.7138, 1.7180, 1.7000, 1.6885,\n",
       "                      1.7011, 1.6988, 1.7013, 1.7038, 1.7098, 1.6917, 1.6998, 1.6919, 1.7384,\n",
       "                      1.6869, 1.6991, 1.7133, 1.7121, 1.7022, 1.6906, 1.7033, 1.7142, 1.6916,\n",
       "                      1.7143, 1.7019, 1.6895, 1.7031, 1.7080, 1.6949, 1.7008, 1.6923, 1.6986,\n",
       "                      1.6966, 1.7035, 1.7005, 1.6971, 1.7040, 1.7014, 1.6937, 1.7051, 1.7014,\n",
       "                      1.7031, 1.7244, 1.7052, 1.6956, 1.6973, 1.6641, 1.6852, 1.6959, 1.7076,\n",
       "                      1.6945, 1.7050, 1.7182, 1.7120, 1.6873, 1.7000, 1.6990, 1.7061, 1.7032,\n",
       "                      1.6949, 1.6968, 1.7015, 1.7016, 1.6976, 1.6923, 1.6923, 1.7110, 1.6997,\n",
       "                      1.6897, 1.6967, 1.7045, 1.7217, 1.6895, 1.6912, 1.6998, 1.7114, 1.7046,\n",
       "                      1.6940, 1.7053, 1.7517, 1.7085, 1.7104, 1.6987, 1.7070, 1.6899, 1.7056,\n",
       "                      1.7220, 1.7524, 1.7135, 1.6925], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.lq.weight',\n",
       "              tensor([[ 0.0178,  0.1228, -0.0460,  ...,  0.1146, -0.0881,  0.1312],\n",
       "                      [ 0.2177,  0.0980, -0.0381,  ...,  0.0041, -0.1712, -0.0568],\n",
       "                      [-0.0119,  0.1255,  0.1047,  ...,  0.1203, -0.1309,  0.1553],\n",
       "                      ...,\n",
       "                      [-0.1064,  0.0908, -0.1337,  ...,  0.0420, -0.1519,  0.1056],\n",
       "                      [-0.1101, -0.0140,  0.0783,  ...,  0.0870,  0.0827, -0.0561],\n",
       "                      [ 0.0534,  0.0861, -0.0655,  ...,  0.0950, -0.1485, -0.1430]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.lq.bias',\n",
       "              tensor([ 0.0188,  0.0709,  0.0264,  0.0303,  0.0396,  0.0144, -0.0025, -0.0010,\n",
       "                       0.0328, -0.0066,  0.0082,  0.0055, -0.0088, -0.0106,  0.0085,  0.0006,\n",
       "                       0.0013, -0.0555,  0.0166,  0.0366,  0.0297, -0.0139,  0.0577,  0.0408,\n",
       "                       0.0345,  0.0051,  0.0038,  0.0282, -0.0003,  0.0652,  0.0289,  0.0402,\n",
       "                      -0.0062,  0.0388,  0.0267,  0.0363,  0.0456,  0.0099, -0.0043,  0.0047,\n",
       "                       0.0581, -0.0320, -0.0142,  0.0126,  0.0099,  0.0726, -0.0075,  0.0255,\n",
       "                       0.0196,  0.0262,  0.0475,  0.0100,  0.0184,  0.0018,  0.0419,  0.0010,\n",
       "                       0.0412,  0.0080,  0.0186,  0.0193,  0.0214,  0.0545,  0.0133,  0.0379,\n",
       "                       0.0080,  0.0751,  0.0007, -0.0059, -0.0073, -0.0063,  0.0014,  0.0701,\n",
       "                       0.0349,  0.0330,  0.0150,  0.0337,  0.0145, -0.0260,  0.0155,  0.0235,\n",
       "                       0.0099,  0.0726, -0.0095,  0.0051,  0.0304, -0.0012, -0.0091,  0.0231,\n",
       "                      -0.0031,  0.0158,  0.0109,  0.0084,  0.0053, -0.0112, -0.0030,  0.0039,\n",
       "                      -0.0073, -0.0171,  0.0042,  0.0077,  0.0089,  0.0012,  0.0034, -0.0011,\n",
       "                       0.0461,  0.0204,  0.0033,  0.0365, -0.0124, -0.0048,  0.0069,  0.0073,\n",
       "                       0.0001,  0.0349,  0.0005,  0.0482,  0.0388,  0.0069, -0.0044,  0.0094,\n",
       "                       0.0504,  0.0287, -0.0082,  0.0148,  0.0093, -0.0068,  0.0009,  0.0116],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.lk.weight',\n",
       "              tensor([[-0.0493,  0.0458,  0.1436,  ..., -0.0411, -0.0172,  0.0364],\n",
       "                      [ 0.1045,  0.2121,  0.1679,  ...,  0.0559,  0.0840, -0.1237],\n",
       "                      [-0.0076,  0.0793,  0.0521,  ...,  0.1176,  0.0582,  0.0474],\n",
       "                      ...,\n",
       "                      [-0.0190, -0.0397, -0.1279,  ..., -0.0644, -0.1266, -0.0568],\n",
       "                      [ 0.1801, -0.0103, -0.0355,  ..., -0.1018,  0.1407, -0.0862],\n",
       "                      [ 0.0696,  0.1702,  0.0494,  ..., -0.1579,  0.0141,  0.0732]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.lk.bias',\n",
       "              tensor([-3.3507e-03,  8.3699e-02,  1.3862e-02, -1.6748e-02, -9.2623e-03,\n",
       "                       1.1223e-04, -1.7229e-02,  6.9720e-03, -1.0680e-02,  2.1467e-02,\n",
       "                      -2.4057e-03, -7.5373e-03, -3.9795e-03, -1.8030e-02,  4.7503e-04,\n",
       "                       7.3130e-02,  5.1985e-02,  3.1071e-02, -1.2818e-02,  1.7403e-02,\n",
       "                       6.6778e-02,  9.4536e-03,  4.6596e-02,  1.2245e-03,  1.4382e-02,\n",
       "                       2.2119e-02,  5.4463e-02,  5.1419e-02, -9.1222e-03, -1.7294e-02,\n",
       "                       1.0242e-01, -2.0134e-02,  4.4090e-02, -1.6980e-02,  1.8348e-02,\n",
       "                       1.1842e-02, -1.9147e-02,  5.3508e-03, -5.1735e-03, -4.2863e-03,\n",
       "                      -2.4971e-02,  4.6271e-03,  1.2130e-02, -4.8129e-03, -6.4660e-04,\n",
       "                       6.2210e-02,  9.3222e-03,  3.1071e-02, -1.1654e-02,  8.2151e-02,\n",
       "                       6.6443e-02,  6.6951e-03,  8.7390e-02,  2.7219e-02,  1.0895e-02,\n",
       "                       3.3246e-03,  6.7176e-02, -3.1816e-03,  7.0449e-03, -1.3121e-02,\n",
       "                       3.1411e-02,  3.0826e-02,  7.1288e-02,  7.9132e-02,  2.9018e-02,\n",
       "                      -3.2573e-03,  6.1807e-03, -5.0460e-03,  2.6134e-02, -1.0320e-02,\n",
       "                      -7.3623e-03,  1.6516e-02,  4.6779e-02,  2.4040e-02, -8.9782e-03,\n",
       "                       4.8225e-02, -3.4948e-03,  8.0601e-02, -2.1862e-02,  6.5485e-02,\n",
       "                      -1.2897e-02,  3.2043e-02,  8.3203e-03,  5.5897e-02, -7.6192e-03,\n",
       "                      -1.4849e-03, -6.7210e-03, -7.4570e-03, -1.8321e-02,  4.0830e-02,\n",
       "                      -4.2539e-03, -3.8658e-03,  1.4574e-02, -6.5440e-03,  2.6685e-02,\n",
       "                       1.0678e-03,  1.1137e-02,  3.8407e-02, -4.4857e-03,  4.7223e-03,\n",
       "                       9.6659e-02, -1.1890e-02,  3.1455e-03,  4.1004e-03, -2.1782e-02,\n",
       "                       8.0045e-03, -2.0610e-02,  1.6427e-02,  3.4030e-02,  6.9070e-02,\n",
       "                       5.4175e-03, -2.6853e-03,  2.0253e-02,  1.1288e-01, -2.5529e-02,\n",
       "                       8.1374e-02,  6.9508e-02, -3.8446e-03,  1.3116e-02,  8.9707e-02,\n",
       "                      -1.6466e-02, -8.7706e-03, -1.2932e-02, -1.1874e-03,  8.8047e-03,\n",
       "                      -7.0116e-03,  9.1590e-03,  1.9987e-02], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.lv.weight',\n",
       "              tensor([[-0.0677,  0.0422,  0.0225,  ..., -0.1163, -0.0627,  0.1192],\n",
       "                      [ 0.0385,  0.0566,  0.0589,  ...,  0.1206, -0.0806,  0.0049],\n",
       "                      [-0.0434, -0.1195,  0.0840,  ..., -0.1019,  0.1262, -0.0935],\n",
       "                      ...,\n",
       "                      [-0.0005, -0.1114,  0.0476,  ...,  0.0536,  0.0498,  0.0665],\n",
       "                      [-0.1015,  0.0828, -0.0461,  ..., -0.0939,  0.0663,  0.0981],\n",
       "                      [ 0.0754, -0.1044, -0.0553,  ..., -0.0576,  0.0024, -0.0092]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.lv.bias',\n",
       "              tensor([-5.4174e-03, -4.5731e-03,  5.8508e-03,  6.5009e-04,  4.0631e-03,\n",
       "                      -2.6165e-03,  5.3166e-03,  5.2998e-03, -7.5380e-03,  6.0959e-03,\n",
       "                      -2.4724e-03, -1.4051e-03,  7.5181e-04, -1.6160e-02,  2.1883e-03,\n",
       "                       3.0758e-03, -2.6355e-03,  8.0537e-03,  2.2666e-03,  1.1077e-02,\n",
       "                       1.2384e-03, -2.1216e-03, -4.6597e-03, -1.0772e-02, -9.8744e-04,\n",
       "                      -1.0054e-02,  5.2898e-03, -1.6051e-03, -3.4986e-03, -3.7819e-04,\n",
       "                       5.1875e-03, -5.1566e-03,  1.2148e-03,  4.5871e-03, -5.8747e-03,\n",
       "                       6.2934e-03,  3.8619e-02,  5.8800e-04, -4.3826e-03, -5.8409e-03,\n",
       "                       8.3687e-04, -1.6300e-03, -3.6649e-03,  4.4922e-03, -4.0756e-03,\n",
       "                       4.9000e-03,  9.6934e-03, -1.3201e-03, -3.9269e-03, -2.3985e-03,\n",
       "                      -1.0095e-03,  1.5985e-02, -5.6040e-03, -2.0157e-03,  7.0609e-03,\n",
       "                       2.4095e-02, -3.7384e-04, -2.4192e-03,  7.9130e-04, -6.2113e-03,\n",
       "                       1.0714e-02, -2.0139e-03, -1.0580e-02, -3.8548e-03,  4.5401e-03,\n",
       "                       2.6999e-03,  5.6973e-03,  4.1507e-03, -6.3446e-04, -2.2346e-03,\n",
       "                      -4.7798e-03, -2.9083e-03, -3.4998e-03, -6.7940e-04,  8.9367e-05,\n",
       "                      -2.5982e-03, -6.6851e-03,  2.9041e-04, -1.1575e-02,  7.2368e-03,\n",
       "                      -3.7317e-03, -6.8761e-03,  4.1143e-03, -1.2573e-02, -5.5216e-03,\n",
       "                       2.5135e-03,  5.6274e-04, -5.0991e-03, -8.8254e-04,  5.9885e-03,\n",
       "                       6.2224e-03, -1.5806e-03, -5.2470e-03, -3.7474e-03, -3.6711e-03,\n",
       "                       7.8523e-03,  5.6420e-03,  5.8069e-03, -3.4315e-03, -9.7495e-03,\n",
       "                       4.3740e-03,  4.1467e-04,  1.9834e-03,  3.4256e-02, -1.5329e-03,\n",
       "                      -1.2471e-02,  5.2611e-05, -2.0958e-04,  1.8637e-02, -5.9258e-03,\n",
       "                      -7.9843e-03, -4.9147e-03,  1.8607e-02, -1.0110e-03,  2.6156e-02,\n",
       "                      -1.2657e-02,  1.1706e-03,  1.3747e-02, -9.8216e-03,  2.1820e-02,\n",
       "                       8.6150e-03,  5.6719e-03,  2.0295e-03,  8.4850e-03, -1.6309e-02,\n",
       "                       2.9175e-02, -5.1840e-05, -3.9440e-04,  2.4976e-02,  1.6119e-03,\n",
       "                       9.2282e-03,  1.0195e-02, -1.5200e-03, -2.2743e-03, -7.4292e-03,\n",
       "                      -1.9557e-03,  3.6975e-04, -7.2079e-03, -9.1382e-04, -1.5596e-03,\n",
       "                       1.2136e-02,  7.8891e-04, -1.0324e-02, -1.4983e-03, -6.9266e-03,\n",
       "                       6.0028e-03, -8.8081e-04,  2.2728e-02,  1.3388e-03,  1.5298e-03,\n",
       "                      -4.4091e-03,  1.4797e-02, -6.4414e-03, -5.6868e-04, -4.2166e-03,\n",
       "                      -9.7786e-04,  5.5613e-03,  4.3533e-03,  1.4610e-03, -7.2475e-03,\n",
       "                       4.1191e-04, -1.0061e-02,  3.4789e-03, -3.2025e-03, -2.0729e-03,\n",
       "                       1.8960e-03, -4.0151e-03, -2.5633e-03, -1.6157e-03,  4.0842e-03,\n",
       "                       2.3482e-03, -1.4444e-04,  3.0877e-04, -2.3813e-03,  4.4678e-03,\n",
       "                       2.1226e-02, -6.0417e-03, -3.4652e-04, -1.2932e-03,  9.0151e-05,\n",
       "                       3.8133e-04,  1.1895e-02,  3.9435e-03, -3.8208e-03,  1.5364e-03,\n",
       "                       1.8844e-03, -1.8342e-03, -2.2314e-03, -2.9133e-03, -6.2561e-03,\n",
       "                       3.8521e-03, -4.5168e-03,  8.4318e-03,  2.6968e-03, -6.2416e-03,\n",
       "                       3.4837e-03, -2.4367e-03, -1.8691e-03, -9.8129e-03, -3.7705e-03,\n",
       "                       5.9065e-04, -4.4501e-04, -6.2480e-03,  2.4729e-03,  1.4884e-03,\n",
       "                       1.0911e-02,  9.9341e-03, -7.1028e-03,  4.6373e-03, -3.0679e-03,\n",
       "                      -5.1863e-04, -8.1151e-03, -6.0583e-06, -1.1352e-02,  3.1133e-02,\n",
       "                      -6.1835e-03, -6.3358e-03, -5.3833e-03, -3.5700e-03, -1.3920e-03,\n",
       "                       1.3293e-02,  4.6957e-03,  6.6217e-03,  1.8962e-02,  2.5736e-03,\n",
       "                      -8.8601e-05,  5.9533e-04, -1.1876e-02, -7.1814e-03, -7.9933e-03,\n",
       "                       2.3763e-02, -8.0272e-03, -6.2650e-03, -4.1612e-03,  1.3835e-02,\n",
       "                      -5.4829e-04, -7.5975e-03, -1.2334e-02,  1.3475e-02,  1.1709e-02,\n",
       "                       2.1615e-03, -3.5266e-03,  2.0469e-03, -7.9129e-04, -6.4718e-04,\n",
       "                       1.6501e-03, -6.4097e-04,  9.5787e-03,  2.9385e-02, -3.9660e-03,\n",
       "                       4.4313e-04, -2.2777e-03,  4.6841e-03, -7.9190e-03,  1.0360e-03,\n",
       "                       7.7452e-03], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.la.weight',\n",
       "              tensor([[-0.0620, -0.1241,  0.0723,  ..., -0.1839, -0.0414, -0.0406],\n",
       "                      [-0.0028, -0.0689, -0.0037,  ..., -0.0991, -0.0384, -0.0763],\n",
       "                      [ 0.1005,  0.1266,  0.0938,  ...,  0.0921, -0.0571, -0.0868],\n",
       "                      ...,\n",
       "                      [-0.0035, -0.0553,  0.0719,  ..., -0.0824, -0.0653,  0.0304],\n",
       "                      [ 0.0190, -0.0916, -0.0649,  ...,  0.0151, -0.0848,  0.0675],\n",
       "                      [ 0.0200, -0.0069, -0.1092,  ..., -0.0675, -0.0523, -0.0950]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.la.bias',\n",
       "              tensor([ 2.7268e-02, -2.4745e-02, -4.6425e-03, -5.8521e-02, -4.5887e-02,\n",
       "                       5.1774e-02, -1.0005e-02, -4.8813e-03,  4.1034e-02, -3.7483e-03,\n",
       "                      -1.9220e-02,  1.3713e-02,  9.0447e-04, -3.6035e-02, -4.3608e-02,\n",
       "                       4.3798e-03,  6.0279e-02,  4.3576e-03,  3.5764e-02,  9.1388e-03,\n",
       "                       9.1179e-02, -6.9164e-03, -1.8579e-03, -1.9515e-02, -8.2102e-03,\n",
       "                      -1.3920e-02,  4.7051e-02,  4.2116e-02,  4.9528e-03, -1.0032e-03,\n",
       "                      -4.9072e-03, -2.2276e-02, -3.9236e-02, -3.2517e-03,  9.8509e-03,\n",
       "                       1.0360e-01,  4.6017e-03,  3.6532e-02, -2.6753e-02, -2.5267e-02,\n",
       "                      -3.3306e-03,  2.3289e-02, -2.9231e-03,  3.1463e-02,  4.0478e-02,\n",
       "                      -2.5098e-02,  6.1369e-04,  2.9565e-02, -2.5201e-03,  5.9906e-03,\n",
       "                      -2.4495e-02,  4.2713e-04, -4.4429e-03, -2.9257e-03, -2.3741e-02,\n",
       "                       2.3486e-02,  2.3148e-02, -2.8967e-02,  2.2441e-02,  6.3329e-02,\n",
       "                      -1.1175e-02, -8.9765e-03,  2.3871e-02, -1.0744e-02,  4.0759e-03,\n",
       "                       4.0297e-03, -1.0450e-02, -3.8786e-03,  1.0792e-02, -2.1101e-02,\n",
       "                       9.6356e-03,  2.9834e-02,  5.1629e-04, -4.1701e-02, -1.9563e-02,\n",
       "                       1.4272e-02,  3.6775e-02,  1.3496e-03, -9.0984e-03, -3.7569e-02,\n",
       "                      -1.2262e-03, -1.5003e-03,  1.4216e-02,  3.0194e-02,  4.6732e-02,\n",
       "                       4.2376e-02, -2.8092e-02,  2.4308e-02, -3.4800e-02, -3.9762e-02,\n",
       "                      -5.9900e-03, -2.5997e-02, -4.6813e-02,  7.7602e-03, -2.5361e-02,\n",
       "                       2.6667e-02,  2.7923e-02, -2.3202e-03, -3.5564e-05,  2.0416e-02,\n",
       "                      -6.3639e-03,  2.1895e-02, -9.9193e-03, -3.7747e-04,  1.2488e-02,\n",
       "                      -3.7918e-03, -7.6671e-03,  1.0694e-02,  1.0030e-02,  6.7554e-03,\n",
       "                      -1.7485e-02,  1.0117e-02,  2.1619e-02, -2.8212e-03, -9.2610e-03,\n",
       "                       2.5443e-02,  1.8284e-02,  6.1865e-02,  1.2790e-02, -1.3938e-02,\n",
       "                       1.8515e-02,  3.7834e-03, -3.1945e-02,  3.3342e-02,  2.0766e-03,\n",
       "                      -1.0068e-02,  3.2202e-02,  2.2591e-02,  7.5053e-04, -2.3367e-03,\n",
       "                       1.1511e-03,  9.1518e-04,  1.2318e-03, -8.3499e-04,  2.1699e-03,\n",
       "                      -5.3730e-03,  5.2701e-03,  4.6745e-03, -2.1054e-04, -6.5307e-04,\n",
       "                      -1.5431e-03,  3.2919e-04,  9.4660e-04, -8.7107e-05,  1.6502e-03,\n",
       "                       2.5143e-04,  5.8618e-03,  1.2391e-03, -1.9824e-04, -2.7583e-04,\n",
       "                      -3.4363e-03, -1.3996e-03,  2.4113e-04, -1.8454e-03, -2.5785e-03,\n",
       "                       1.0503e-03,  2.1661e-03, -4.3037e-03, -9.4086e-04, -5.2379e-04,\n",
       "                      -1.1363e-05, -5.1331e-04,  1.7308e-05,  1.5940e-03,  8.0587e-04,\n",
       "                       1.4646e-03,  3.8129e-04,  8.9612e-04, -2.0231e-03, -1.4483e-03,\n",
       "                       1.1228e-03, -1.0576e-03, -4.0958e-04,  7.0602e-04,  2.4152e-03,\n",
       "                       5.4107e-04, -1.5102e-03, -1.1566e-03, -1.4085e-03,  2.6044e-04,\n",
       "                      -9.2916e-04, -4.6042e-04,  2.4255e-04,  1.2597e-04,  7.1157e-05,\n",
       "                      -3.0771e-03,  1.3387e-04,  4.1080e-03, -3.8291e-05,  3.5957e-03,\n",
       "                      -4.3773e-03, -4.2733e-04, -3.2121e-04, -3.3140e-04, -2.4858e-04,\n",
       "                      -7.2539e-04,  2.1182e-04, -1.3912e-03, -9.1700e-04,  2.3287e-03,\n",
       "                      -1.6780e-04,  8.9905e-04, -4.4957e-04, -6.7212e-04, -3.5357e-04,\n",
       "                      -5.2042e-04, -3.0216e-03,  7.2854e-04, -3.3600e-04,  2.4738e-03,\n",
       "                      -7.3034e-04, -7.9814e-04, -2.4630e-03, -1.6111e-03, -3.7390e-04,\n",
       "                       6.2160e-04, -1.5013e-03,  6.1106e-05,  4.2973e-05,  5.1691e-05,\n",
       "                       4.6077e-04,  2.0306e-04,  3.5091e-03,  1.6297e-04, -3.5304e-04,\n",
       "                      -3.0431e-05,  1.0390e-03,  7.5576e-04,  5.1782e-04,  1.2351e-03,\n",
       "                      -3.1081e-04, -1.6259e-03, -1.5190e-04,  9.7125e-04,  6.5793e-04,\n",
       "                       1.8569e-03,  8.5888e-04,  1.0257e-03, -2.0508e-04,  2.7245e-03,\n",
       "                      -1.3250e-03,  1.0432e-03,  6.0790e-04, -1.1356e-03,  1.8529e-04,\n",
       "                       4.2348e-03,  6.0176e-04, -9.3960e-04,  1.1693e-04,  1.6846e-03,\n",
       "                      -1.3697e-03,  2.1598e-04,  5.1842e-03,  2.5410e-04, -9.2380e-04,\n",
       "                      -9.6906e-05], device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.lrbf.weight',\n",
       "              tensor([[ 0.0645,  0.0294, -0.1491,  ..., -0.1379, -0.1641, -0.1589],\n",
       "                      [ 0.1003,  0.0823,  0.1000,  ...,  0.1673,  0.1521, -0.0585],\n",
       "                      [ 0.0319,  0.0053, -0.1345,  ..., -0.0651,  0.1674, -0.1981],\n",
       "                      ...,\n",
       "                      [-0.1403,  0.0961, -0.1969,  ..., -0.1463,  0.0039, -0.1709],\n",
       "                      [ 0.0447,  0.1545, -0.0648,  ..., -0.0455,  0.1151, -0.0041],\n",
       "                      [-0.1696, -0.0632,  0.1191,  ...,  0.0337, -0.1326,  0.1504]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.lkrbf.weight',\n",
       "              tensor([[-0.0651, -0.0303, -0.1302,  ..., -0.0050, -0.1476, -0.1247],\n",
       "                      [-0.0732, -0.0799,  0.0638,  ..., -0.0802,  0.0749,  0.0899],\n",
       "                      [-0.0264, -0.0302,  0.1118,  ...,  0.1417, -0.1001,  0.0522],\n",
       "                      ...,\n",
       "                      [ 0.1214,  0.0658,  0.0029,  ..., -0.0482, -0.0787,  0.0756],\n",
       "                      [-0.1382, -0.1192,  0.1447,  ...,  0.0464,  0.1160,  0.0256],\n",
       "                      [-0.0961, -0.0978,  0.0513,  ...,  0.0837,  0.1843,  0.1195]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.message.Attention.lvrbf.weight',\n",
       "              tensor([[ 0.1149, -0.0518, -0.1011,  ...,  0.1201,  0.0218, -0.0459],\n",
       "                      [ 0.1230,  0.0278, -0.1016,  ..., -0.0355,  0.0396,  0.0650],\n",
       "                      [-0.0485, -0.0036, -0.0949,  ..., -0.0613,  0.1044,  0.1052],\n",
       "                      ...,\n",
       "                      [ 0.0709, -0.0715,  0.0894,  ..., -0.0219,  0.0870, -0.1159],\n",
       "                      [-0.0980,  0.1165,  0.0482,  ..., -0.1101,  0.0018, -0.0014],\n",
       "                      [ 0.0888, -0.0813, -0.0315,  ..., -0.0994,  0.0678, -0.0088]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.message.tp.weight',\n",
       "              tensor([ 1.1031,  1.8291, -1.6246,  0.0065, -0.6535, -0.6778,  0.7530, -0.3675,\n",
       "                       0.2018,  0.1232,  0.0674, -0.4174,  2.7063,  1.9940,  0.9097,  1.7624,\n",
       "                      -0.1811, -1.6577,  0.4763, -0.1473,  1.6576,  0.9284, -0.2524,  0.9220,\n",
       "                      -0.3176,  1.0048,  1.2527, -1.3402, -1.9728, -0.0954,  0.5332, -0.3770,\n",
       "                       0.2021,  0.9063,  0.3699, -0.2085,  1.1109,  2.5873,  0.5765, -0.8844,\n",
       "                       1.3752,  0.5699,  2.2755,  1.3509, -1.7196, -1.1806,  0.2511,  0.4878,\n",
       "                      -0.6830,  0.4325,  1.8152, -0.6210,  1.5299, -2.1678, -0.0375,  1.9187,\n",
       "                      -0.7920, -0.6613,  0.4751, -1.1574,  0.3772, -0.2956, -0.0477,  0.4590,\n",
       "                       0.0965, -2.0204, -0.7770,  0.0051,  2.9436, -0.0515, -0.4059, -1.3160,\n",
       "                      -0.0370,  2.7116,  0.0388, -1.3215,  0.9266, -0.6507, -0.3710,  0.8059,\n",
       "                      -1.7280, -0.3196, -0.3394,  0.2447, -1.2627, -1.0936,  0.4406,  1.4398,\n",
       "                       2.2832, -0.3405,  0.6187,  0.6885,  0.7723,  0.9733,  2.2074, -0.1454,\n",
       "                       0.8801, -0.5481, -0.1037,  0.3626, -0.1179,  1.4819,  0.1115,  1.5634,\n",
       "                       0.4083,  1.3252, -1.9371, -0.3127, -0.0463, -1.0045, -0.2905,  0.7546,\n",
       "                      -1.2662,  0.6359,  0.4914,  2.4117,  2.1033,  0.6540, -0.5566,  0.2483,\n",
       "                       1.4690, -0.1864,  0.7357,  1.3328,  0.6378, -1.4176,  0.2399, -0.6152,\n",
       "                       1.9372,  1.0647, -0.2811, -1.2185, -0.7405, -0.4295, -0.4383, -1.0031,\n",
       "                       0.4208, -1.1971, -1.4015, -0.5653,  1.0149,  0.4726,  0.8846,  0.0936,\n",
       "                      -1.0847,  1.2030, -1.0375,  2.1662, -1.7604,  2.0317,  0.4726, -0.0820,\n",
       "                       1.1472, -0.3303,  0.6804, -0.8281, -0.0270, -1.7718, -0.7120, -2.3060,\n",
       "                       2.5772,  1.1951,  0.0536,  1.0386, -0.8115,  0.5304, -0.7859,  0.2581,\n",
       "                      -2.1759,  0.7595, -0.4509,  0.1905, -2.0963,  0.4019,  0.9602,  1.4111,\n",
       "                       0.4671, -0.0345, -1.2715, -0.7742, -0.7851,  0.0857, -2.3173, -0.6163,\n",
       "                      -0.3007, -0.5420,  1.2027,  0.8227, -1.5180, -0.4869, -0.4210,  1.1026,\n",
       "                      -0.5963, -1.5286, -0.0819, -1.0940,  1.3394,  0.4748, -0.1122, -0.6034,\n",
       "                       0.1470,  1.3756,  0.2132, -0.0031,  0.9925,  0.7637, -0.0893,  0.6001,\n",
       "                       0.8603, -1.2084, -1.1416,  1.8635,  1.7044, -0.0341,  0.0145,  0.9648,\n",
       "                       0.9099,  0.1736, -0.9374, -1.1859, -1.0640,  0.2968, -0.6124, -0.2824,\n",
       "                       1.1494, -0.4963,  0.0994, -1.9579,  0.2560, -0.4886,  0.0519,  0.2929,\n",
       "                      -0.6994, -1.0900, -0.0086, -0.3498, -0.2400, -0.3739, -0.2751, -0.2973,\n",
       "                       0.8253,  0.4601, -0.3634, -0.6701,  1.1827,  1.0299,  0.2647,  1.4374,\n",
       "                       0.7718,  0.1721,  0.5302,  1.2359, -0.7491, -0.1491,  0.6642,  2.3661,\n",
       "                      -0.1938, -0.7700, -1.3441, -1.4790, -0.1085,  0.4526, -1.2509, -0.7945,\n",
       "                       0.5748, -0.7147, -1.4085,  1.3039,  0.8577, -0.1754, -0.1962, -0.3481,\n",
       "                       0.5638,  0.7553, -0.3840, -1.4127,  0.3518, -0.6395, -1.1798, -0.5103,\n",
       "                       1.0149, -0.6491,  1.3403, -1.5123,  0.1880,  1.0530,  1.2525, -0.6845,\n",
       "                      -1.1075, -0.1443,  0.8718,  1.5658, -0.2088,  1.7215, -1.9930,  0.3860,\n",
       "                       0.6688, -0.6484, -1.6802, -0.6667,  0.5009,  0.1304, -1.1162,  0.5854,\n",
       "                      -1.0505,  0.8016,  1.7545,  0.7196, -1.1496, -0.2842, -2.1941,  1.0265,\n",
       "                      -0.2677,  0.6370, -0.4352, -2.5952, -0.8724, -0.7916,  0.8709,  0.0750,\n",
       "                       1.6862, -0.2954, -0.3761,  0.9711,  0.7285,  0.4953, -0.6354, -0.1720,\n",
       "                       0.4031,  0.1679, -0.1791,  1.4839,  0.2396,  0.2550,  0.8779, -0.0967,\n",
       "                       0.8864,  1.9191,  0.2382,  0.2390,  0.9866,  1.7984,  0.8071, -0.3798,\n",
       "                      -0.3926, -1.6913, -0.0405, -0.1431,  0.5695,  0.4361,  0.6222,  0.3080,\n",
       "                       0.6063, -0.1971,  1.6425, -0.2649, -0.5053,  0.1729, -1.1176,  1.6757,\n",
       "                       1.2030,  0.1029, -0.5223, -1.3217, -1.5024,  0.6880, -0.3264,  0.7675,\n",
       "                      -1.2494, -1.4629, -1.3402,  0.1747,  0.5065,  0.6147, -0.1241,  0.6640,\n",
       "                       1.6749, -1.5031, -0.1826,  0.7526, -1.9306,  1.5867, -0.6783, -0.0766],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.message.tp.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.0.update.actu.alpha',\n",
       "              tensor([0.9877, 1.0215, 0.9938, 1.0009, 0.9927, 1.0136, 0.9983, 1.0096, 0.9886,\n",
       "                      0.9887, 0.9948, 0.9965, 1.0086, 0.9905, 0.9998, 1.0093, 1.0224, 0.9994,\n",
       "                      0.9892, 0.9970, 0.9966, 1.0011, 1.0005, 1.0025, 0.9940, 1.0044, 0.9906,\n",
       "                      1.0021, 0.9972, 0.9967, 0.9939, 1.0007, 0.9986, 0.9988, 0.9981, 1.0001,\n",
       "                      0.9974, 1.0010, 1.0258, 0.9971, 1.0022, 1.0019, 0.9937, 0.9963, 0.9932,\n",
       "                      1.0074, 1.0050, 0.9999, 0.9961, 1.0052, 0.9997, 0.9945, 0.9951, 1.0275,\n",
       "                      1.0016, 1.0035, 0.9936, 0.9936, 1.0063, 0.9941, 1.0065, 1.0066, 0.9986,\n",
       "                      1.0641, 1.0010, 0.9980, 1.0055, 1.0047, 0.9996, 0.9948, 0.9920, 1.0242,\n",
       "                      1.0016, 0.9934, 1.0008, 0.9954, 1.0014, 0.9988, 1.0041, 1.0053, 0.9818,\n",
       "                      0.9946, 1.0202, 1.0003, 0.9961, 0.9988, 1.0030, 0.9890, 1.0015, 0.9963,\n",
       "                      0.9922, 0.9962, 1.0018, 1.0042, 0.9940, 0.9949, 0.9740, 0.9986, 1.0041,\n",
       "                      1.0135, 0.9978, 0.9944, 0.9962, 0.9869, 1.0125, 1.0465, 1.0076, 0.9954,\n",
       "                      0.9885, 0.9872, 0.9911, 0.9880, 1.0022, 1.0124, 0.9943, 1.0031, 0.9920,\n",
       "                      0.9925, 0.9930, 0.9981, 0.9979, 0.9944, 1.0118, 1.0053, 0.9916, 1.0057,\n",
       "                      1.0069, 0.9917], device='cuda:0')),\n",
       "             ('blocks.0.update.actu.beta',\n",
       "              tensor([1.6800, 1.6743, 1.6980, 1.6920, 1.7149, 1.6425, 1.6994, 1.7260, 1.6949,\n",
       "                      1.7191, 1.6966, 1.7072, 1.7292, 1.6876, 1.7092, 1.7212, 1.6793, 1.7099,\n",
       "                      1.7043, 1.7086, 1.7134, 1.6939, 1.7059, 1.7108, 1.6865, 1.6976, 1.7033,\n",
       "                      1.6967, 1.6966, 1.7123, 1.6967, 1.7451, 1.7048, 1.7000, 1.6991, 1.7298,\n",
       "                      1.7064, 1.7374, 1.6610, 1.7285, 1.6654, 1.7138, 1.6896, 1.6977, 1.7237,\n",
       "                      1.7321, 1.7126, 1.7010, 1.6941, 1.6792, 1.6974, 1.7017, 1.7037, 1.7587,\n",
       "                      1.7101, 1.7286, 1.7160, 1.7866, 1.7338, 1.6891, 1.7050, 1.7376, 1.6973,\n",
       "                      1.8249, 1.7115, 1.7320, 1.7264, 1.7078, 1.7088, 1.7056, 1.6905, 1.6998,\n",
       "                      1.7089, 1.7006, 1.7077, 1.7009, 1.7094, 1.6927, 1.7279, 1.7243, 1.6892,\n",
       "                      1.7146, 1.7565, 1.7181, 1.6973, 1.7118, 1.6939, 1.7126, 1.6976, 1.6937,\n",
       "                      1.7219, 1.6807, 1.7012, 1.7180, 1.7179, 1.7033, 1.6955, 1.6921, 1.7162,\n",
       "                      1.6780, 1.6891, 1.7059, 1.7226, 1.7140, 1.6715, 1.7555, 1.6987, 1.7069,\n",
       "                      1.7251, 1.6966, 1.6772, 1.6662, 1.6923, 1.7224, 1.7001, 1.6898, 1.6949,\n",
       "                      1.7005, 1.7018, 1.6952, 1.6906, 1.6899, 1.6944, 1.7046, 1.6850, 1.7226,\n",
       "                      1.6925, 1.6972], device='cuda:0')),\n",
       "             ('blocks.0.update.outt.weight',\n",
       "              tensor([-1.3250, -1.9413,  0.5497,  ...,  0.0529, -0.9668, -0.0667],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.update.outt.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.0.update.outt.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.0.update.outs.weight',\n",
       "              tensor([[ 0.0946, -0.0320, -0.0067,  ...,  0.0588, -0.0936,  0.1455],\n",
       "                      [-0.0977, -0.0117, -0.0556,  ...,  0.1409, -0.1484,  0.0325],\n",
       "                      [ 0.0695, -0.1284,  0.1162,  ..., -0.0035, -0.0785, -0.0442],\n",
       "                      ...,\n",
       "                      [-0.0697, -0.1366,  0.1439,  ...,  0.0581,  0.0402,  0.0741],\n",
       "                      [-0.1453,  0.1421, -0.0775,  ..., -0.1231, -0.0625,  0.1065],\n",
       "                      [-0.0582,  0.1257, -0.0890,  ..., -0.0967, -0.1293, -0.0540]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.update.outs.bias',\n",
       "              tensor([ 7.8910e-05,  1.4508e-03, -6.1649e-05, -1.2074e-03, -4.2431e-03,\n",
       "                       1.9953e-03,  2.5176e-04,  5.8806e-03,  5.4557e-04,  6.1656e-04,\n",
       "                      -1.4400e-03,  5.6297e-04, -2.7787e-03,  6.7122e-05,  4.2723e-04,\n",
       "                       2.1321e-04,  3.4394e-04,  2.7580e-03,  1.2487e-04,  1.3349e-03,\n",
       "                       1.8179e-03, -2.6617e-03,  1.2072e-03, -1.6965e-03, -9.5746e-04,\n",
       "                      -5.3688e-04,  1.9050e-03, -8.0727e-04,  7.3715e-04,  1.1137e-03,\n",
       "                       8.2728e-04, -2.4119e-03,  3.9341e-03,  1.4330e-03, -1.3140e-03,\n",
       "                       8.1568e-04, -7.4772e-04,  1.4580e-03,  3.7583e-04, -2.4981e-04,\n",
       "                      -1.8260e-05,  1.8384e-03,  2.6208e-03,  1.5908e-03,  5.4318e-04,\n",
       "                       2.2185e-03,  2.3484e-03, -1.1414e-03, -2.3358e-03, -4.6619e-04,\n",
       "                      -2.4172e-03, -4.3914e-04, -6.3451e-03,  3.2366e-03,  2.3671e-03,\n",
       "                      -3.2738e-03,  6.8671e-06, -8.9983e-04, -1.1176e-03, -2.2611e-04,\n",
       "                       1.7640e-03,  2.7476e-04, -6.8834e-03, -4.8340e-04,  6.9530e-04,\n",
       "                       1.1632e-04,  2.5653e-03,  4.2256e-04,  9.8406e-04,  6.9923e-04,\n",
       "                      -1.3367e-03,  1.7862e-03, -8.8974e-04, -2.5056e-04, -2.8571e-03,\n",
       "                       6.8389e-04, -4.1483e-03, -2.3457e-03,  2.6648e-03,  3.4562e-03,\n",
       "                      -2.2597e-03, -1.3432e-03,  5.6677e-03,  2.1113e-03,  1.2244e-03,\n",
       "                      -8.7387e-05,  6.6988e-04,  8.2997e-04,  3.6899e-03, -1.1486e-03,\n",
       "                       1.0263e-03,  1.4000e-03, -7.5618e-04,  7.7349e-04,  4.9101e-04,\n",
       "                       2.2965e-03, -2.8425e-03, -4.1368e-04,  3.2316e-04,  1.5515e-03,\n",
       "                       1.9437e-04,  8.6424e-05,  2.5796e-03,  8.2702e-04, -4.0477e-04,\n",
       "                       2.7879e-03,  1.1301e-03, -2.7028e-03, -5.2074e-03,  9.0418e-04,\n",
       "                       2.3339e-04,  6.0010e-04, -2.2271e-03,  1.9864e-03,  1.2649e-03,\n",
       "                       7.1181e-04, -1.7764e-03,  2.3986e-04, -5.0253e-04, -9.1163e-04,\n",
       "                       1.4575e-03,  9.4591e-04,  8.6249e-03, -1.8437e-03,  1.6072e-03,\n",
       "                       1.6379e-04, -1.1435e-03, -3.0048e-04], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lq.weight',\n",
       "              tensor([-1.7548, -0.0309,  0.6803,  ..., -0.0993,  0.2707,  0.4723],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lq.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lq.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lk.weight',\n",
       "              tensor([-0.5161,  1.3389, -0.0831,  ..., -0.5635, -0.4749,  1.1584],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lk.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lk.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lv.weight',\n",
       "              tensor([ 0.1610, -0.7199, -0.3215,  ..., -0.4843,  2.2450,  0.8753],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lv.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lv.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.ls.weight',\n",
       "              tensor([[-0.0044, -0.0620, -0.1245,  ..., -0.1311, -0.0161,  0.1343],\n",
       "                      [ 0.0762,  0.0252,  0.1034,  ..., -0.0388, -0.0137,  0.0310],\n",
       "                      [-0.1212,  0.0014, -0.0821,  ...,  0.0296,  0.0872, -0.0539],\n",
       "                      ...,\n",
       "                      [ 0.0689, -0.0335,  0.0857,  ...,  0.0109, -0.1087,  0.0446],\n",
       "                      [-0.0320, -0.0778, -0.1042,  ...,  0.0801, -0.1386, -0.1350],\n",
       "                      [-0.0406,  0.0916,  0.0933,  ..., -0.0134,  0.0767, -0.0600]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.ls.bias',\n",
       "              tensor([ 2.7426e-04, -1.4442e-04,  6.6494e-04, -2.7274e-04,  7.7553e-04,\n",
       "                      -2.3061e-03,  3.6952e-03, -5.2290e-04, -6.0019e-04, -1.6539e-03,\n",
       "                      -1.4208e-03,  6.1107e-04, -8.6204e-04, -1.7106e-03, -2.5268e-03,\n",
       "                      -3.4159e-03,  9.2438e-03,  9.2802e-04, -7.4118e-04, -2.3032e-03,\n",
       "                      -7.4024e-04, -1.7937e-03,  3.7635e-04, -2.1032e-03, -1.1974e-03,\n",
       "                      -3.5651e-03,  4.9024e-04, -1.8386e-03,  1.9276e-03, -2.6376e-04,\n",
       "                       3.9879e-04, -1.6213e-03,  3.4064e-03, -1.6231e-03, -2.0633e-03,\n",
       "                      -3.6118e-03, -2.9828e-03, -1.8038e-03,  7.7103e-04, -7.4087e-04,\n",
       "                      -4.0882e-04, -5.1340e-03, -1.9699e-03, -6.2463e-07,  7.9045e-04,\n",
       "                       2.3515e-02, -7.9035e-05,  2.9820e-04, -4.3813e-03, -8.4214e-04,\n",
       "                       1.5110e-03, -1.2413e-03,  3.8121e-03, -2.5844e-03, -8.4531e-04,\n",
       "                      -1.0882e-03,  2.0751e-04,  1.5953e-03, -1.3483e-03, -6.5780e-04,\n",
       "                      -7.6633e-03,  8.5859e-04,  7.2037e-04,  3.6326e-04, -2.4381e-03,\n",
       "                      -8.2114e-03,  1.4268e-03, -1.5523e-03, -2.4175e-03,  6.7066e-04,\n",
       "                      -9.6644e-04, -3.7785e-03, -2.4361e-03,  9.1358e-04,  6.1079e-04,\n",
       "                      -2.3953e-03, -2.2688e-03, -1.1207e-03, -1.1470e-03,  1.3793e-03,\n",
       "                      -3.3447e-03, -2.5637e-03, -2.2740e-03,  1.7608e-03,  5.8993e-04,\n",
       "                      -3.3350e-03,  1.2791e-03, -7.1658e-04,  1.3429e-03, -2.0414e-03,\n",
       "                       3.7320e-04,  5.2794e-04,  3.8735e-03, -2.6012e-03, -5.9059e-04,\n",
       "                      -7.6389e-03, -4.3624e-03, -8.3286e-04,  1.2496e-03, -7.8477e-04,\n",
       "                      -1.1978e-03, -1.0700e-03,  3.8408e-03, -7.6037e-03,  9.0232e-04,\n",
       "                       2.5493e-03, -8.1987e-03, -2.8638e-03, -1.9501e-04,  8.0394e-04,\n",
       "                      -1.6544e-03,  4.2351e-03, -4.3475e-03,  1.2449e-03, -1.2828e-03,\n",
       "                      -5.3805e-04, -2.6319e-04,  9.9750e-04, -5.7118e-03, -5.0462e-04,\n",
       "                      -8.8335e-03, -2.2082e-03, -4.5034e-03, -1.1224e-03, -3.6466e-03,\n",
       "                      -1.7809e-04, -1.4090e-03, -3.7454e-03, -3.0447e-03, -2.3015e-03,\n",
       "                      -1.4000e-03, -1.5627e-03, -3.1682e-03, -2.2549e-03, -1.5883e-03,\n",
       "                      -3.1412e-03, -2.8489e-03, -2.7984e-03, -1.7435e-03, -1.9468e-03,\n",
       "                      -4.0386e-03, -1.4678e-03, -3.4849e-04, -3.6744e-03, -1.6017e-03,\n",
       "                      -1.6757e-03, -1.4890e-03, -1.1170e-03, -2.1943e-03, -8.6080e-04,\n",
       "                      -1.3349e-03, -1.5148e-03, -2.5639e-03, -1.6842e-03, -3.1593e-03,\n",
       "                      -2.2236e-03, -3.0721e-03, -2.1553e-03, -2.8458e-03, -6.0497e-04,\n",
       "                      -1.8315e-03, -2.1022e-03, -2.3875e-03, -1.7118e-03, -1.6265e-03,\n",
       "                      -1.5358e-03, -4.2350e-03, -3.2326e-03, -2.1423e-03, -2.0683e-03,\n",
       "                      -2.0617e-03,  1.7303e-03, -1.5963e-03, -3.2640e-03, -1.4573e-03,\n",
       "                      -1.6879e-03, -3.2417e-03, -2.0299e-03, -1.6883e-03, -2.5643e-03,\n",
       "                      -1.7606e-03, -2.7841e-03, -1.7903e-03, -1.4898e-03, -7.3578e-04,\n",
       "                      -1.0871e-03, -2.9831e-03, -1.9461e-03, -8.5074e-04, -2.1013e-03,\n",
       "                      -1.8017e-03, -1.4145e-03, -3.4381e-03, -2.4326e-03, -1.8196e-03,\n",
       "                      -2.2834e-03, -1.5655e-03, -1.3711e-03, -1.9460e-03, -2.1250e-03,\n",
       "                      -2.0588e-03, -2.3727e-03, -2.8889e-03, -2.7160e-03, -4.2624e-03,\n",
       "                      -2.1250e-03, -2.5472e-03, -2.3344e-03, -1.8361e-03, -2.7975e-03,\n",
       "                      -4.3283e-04, -3.1762e-03, -2.0691e-03, -1.7175e-03, -1.8718e-03,\n",
       "                      -1.8242e-03, -1.3252e-03, -1.9951e-03, -2.2299e-03, -2.6861e-03,\n",
       "                      -2.2585e-03, -2.5952e-03, -1.6081e-03, -3.3511e-03, -2.1000e-03,\n",
       "                       4.5896e-04, -3.6860e-03, -3.9664e-03, -2.0755e-03, -6.2502e-04,\n",
       "                      -2.5826e-03, -3.0472e-03, -1.5852e-03, -1.1207e-03, -1.8222e-03,\n",
       "                      -1.4214e-03, -1.6079e-03, -2.6467e-03, -3.4120e-03, -2.2817e-03,\n",
       "                      -2.4303e-03, -3.2898e-03, -1.8070e-03, -1.7002e-03, -1.7259e-03,\n",
       "                      -2.4501e-03, -2.3013e-03, -7.4682e-04, -2.6353e-03, -1.9633e-03,\n",
       "                       1.1741e-03,  6.2144e-03, -2.0356e-03, -2.5146e-03, -2.9990e-03,\n",
       "                      -2.0567e-03], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lvs.weight',\n",
       "              tensor([[-0.0161,  0.0393,  0.0870,  ..., -0.0112, -0.0208,  0.1018],\n",
       "                      [ 0.0828, -0.0877,  0.1067,  ..., -0.0520, -0.0529,  0.0914],\n",
       "                      [ 0.1485,  0.0984, -0.1127,  ..., -0.0743,  0.0332, -0.0381],\n",
       "                      ...,\n",
       "                      [ 0.1392, -0.1409, -0.1357,  ...,  0.0483,  0.1162,  0.0335],\n",
       "                      [-0.1294,  0.1503,  0.0741,  ..., -0.1098, -0.0038,  0.0398],\n",
       "                      [-0.0754,  0.0337, -0.0399,  ...,  0.0896,  0.0228, -0.0982]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.lvs.bias',\n",
       "              tensor([ 1.8076e-03,  1.4688e-03,  8.1572e-04,  2.5843e-03,  4.6298e-04,\n",
       "                       2.3954e-03, -1.4000e-03,  2.0917e-03,  5.4056e-04, -9.2511e-05,\n",
       "                      -2.8974e-03,  1.2214e-03, -1.1567e-03, -2.1676e-03,  1.9169e-04,\n",
       "                      -2.9781e-04,  1.4529e-02,  1.5566e-03,  4.4233e-03, -2.2030e-03,\n",
       "                       3.3924e-03, -2.1367e-03,  9.8588e-04, -1.4422e-03, -5.8142e-04,\n",
       "                      -7.8823e-04,  1.4053e-03, -8.6018e-04,  1.2344e-03, -4.8266e-04,\n",
       "                       1.0748e-03, -9.6487e-04,  4.8825e-03, -1.1248e-03, -1.6019e-03,\n",
       "                      -1.9625e-03, -1.4095e-03, -6.1653e-04,  2.5225e-03, -2.5082e-04,\n",
       "                      -5.6020e-05, -1.8646e-03,  2.1566e-03,  2.0491e-04,  3.8822e-04,\n",
       "                       3.7264e-02,  1.8010e-03, -8.1041e-04, -2.6744e-03,  1.5919e-03,\n",
       "                      -1.5020e-03, -9.4239e-04, -1.4522e-03,  6.4404e-04,  1.9148e-03,\n",
       "                      -3.8519e-03,  2.0233e-04,  1.1951e-03, -6.4950e-05, -2.8996e-04,\n",
       "                      -7.3129e-04,  2.6105e-03, -1.1701e-03, -2.9964e-03,  4.9469e-04,\n",
       "                       2.9079e-04,  2.2970e-03, -6.5720e-05, -1.9772e-04,  2.9302e-04,\n",
       "                      -1.3245e-03,  7.2794e-04, -1.6794e-03,  7.4424e-04, -3.6539e-04,\n",
       "                      -4.7390e-04, -2.0197e-03, -9.4153e-04,  1.2671e-03,  2.7197e-03,\n",
       "                      -3.2764e-03, -2.6310e-03, -2.9102e-03,  5.0453e-04,  8.9636e-04,\n",
       "                      -7.6263e-04,  1.9617e-03,  3.1248e-03,  2.2940e-03, -1.6152e-03,\n",
       "                       1.2567e-03,  2.1071e-03,  1.9765e-03, -2.6479e-03,  3.4416e-04,\n",
       "                       1.2922e-03, -2.3770e-03, -5.7573e-04,  7.7013e-04,  4.2565e-03,\n",
       "                       2.3087e-04,  5.7272e-04,  1.8640e-03, -7.5793e-04,  1.6513e-03,\n",
       "                       2.7257e-03, -3.2362e-03, -2.8215e-03, -2.4208e-03,  5.9625e-04,\n",
       "                      -3.7636e-06,  5.4454e-05, -2.5187e-03,  1.6822e-03, -1.4254e-03,\n",
       "                       1.5541e-04, -7.9204e-04,  5.2772e-04, -2.2391e-03, -5.5715e-04,\n",
       "                      -1.2312e-03,  1.2687e-03,  8.0312e-03,  4.3562e-04,  1.3035e-03,\n",
       "                       8.1063e-04, -1.1318e-03, -1.4700e-03], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.tp1.weight', tensor([], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.tp1.output_mask',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.tp2.weight',\n",
       "              tensor([-1.6385e+00, -3.1945e-01,  4.4935e-01, -4.7947e-01,  1.8587e+00,\n",
       "                       2.8364e-01, -1.5153e-01,  2.5286e-01,  5.7552e-01, -9.0742e-02,\n",
       "                       1.5690e+00,  1.5579e-01,  4.3840e-01,  7.1254e-03, -1.3406e+00,\n",
       "                      -1.5299e+00,  7.9125e-01, -4.3376e-01, -1.2351e-01, -9.4298e-01,\n",
       "                       1.5575e+00, -5.5806e-01,  1.0060e+00,  2.3421e+00,  8.2904e-02,\n",
       "                       4.1577e-01, -4.9807e-01,  2.9379e-01,  1.9088e+00,  1.0297e+00,\n",
       "                      -1.3995e+00, -1.1696e+00, -6.1406e-01,  1.2666e+00,  1.1376e-01,\n",
       "                      -1.6315e+00,  1.8737e+00, -1.0205e+00,  7.5771e-01,  1.3447e+00,\n",
       "                      -6.0387e-01,  1.0821e+00, -5.4952e-02,  2.6687e-01, -1.6085e+00,\n",
       "                       1.3524e+00, -6.6692e-01,  1.8490e+00, -9.0439e-01,  4.1893e-01,\n",
       "                       1.8656e-03, -1.3531e+00, -2.0524e-01, -3.3000e-01, -3.4975e-01,\n",
       "                      -2.0648e+00, -3.0306e-01,  6.8704e-01,  1.7218e-01, -1.8206e+00,\n",
       "                      -4.1133e-01,  7.1975e-01,  1.4969e+00, -6.6633e-01,  1.3312e+00,\n",
       "                       3.1837e-01, -5.4575e-01, -9.0233e-01, -1.6069e-01,  4.8234e-01,\n",
       "                      -7.6684e-01,  1.5499e+00, -8.5313e-02,  4.1955e-01, -9.8168e-01,\n",
       "                      -1.0454e+00,  4.7424e-01, -1.6706e+00,  7.2075e-01,  4.8549e-01,\n",
       "                      -3.2979e+00, -1.0382e+00,  4.3080e-01, -3.8823e-01,  2.5721e-02,\n",
       "                      -5.7936e-01, -7.8789e-02, -1.1832e+00, -5.5012e-01,  8.0584e-01,\n",
       "                      -2.7441e-01, -4.8691e-01, -5.5770e-01,  3.7772e-01, -1.0516e-01,\n",
       "                      -9.0668e-01,  4.5436e-01, -2.7616e-02, -1.0024e+00,  1.8116e+00,\n",
       "                       2.2095e-01,  1.7443e+00,  2.0306e+00, -5.5971e-01,  2.5915e-01,\n",
       "                      -1.6248e-01,  1.4011e+00, -1.2834e-01, -1.8595e+00,  5.9150e-01,\n",
       "                       7.7307e-02, -9.6540e-01,  5.2972e-01,  8.2348e-02, -3.1691e-01,\n",
       "                      -1.2004e+00, -8.7058e-01,  1.1824e-01,  2.0307e-01, -1.3535e+00,\n",
       "                      -8.8113e-01,  7.5166e-01,  9.1397e-01,  1.1581e-01, -6.3724e-01,\n",
       "                      -1.4418e+00,  5.6664e-01, -1.6100e+00,  5.9238e-01,  1.5736e-01,\n",
       "                      -1.1864e+00, -1.5953e-01,  9.2309e-01,  2.4026e-01,  5.9798e-01,\n",
       "                       3.0882e-01,  2.1328e+00,  3.9013e-01,  1.3771e+00, -6.5604e-01,\n",
       "                      -1.6234e+00, -2.0771e-01, -3.3743e-01, -7.1473e-01, -2.1875e+00,\n",
       "                      -2.4797e-01, -5.6598e-01,  1.0981e+00,  2.2390e+00, -1.2947e+00,\n",
       "                       1.0702e+00, -1.0588e+00, -2.0694e-02,  2.3042e-01, -6.8488e-01,\n",
       "                      -4.5907e-01, -6.9440e-01,  8.5714e-01, -3.4112e-01,  1.9918e+00,\n",
       "                      -4.0263e-01,  2.2687e+00,  9.0181e-01,  6.1010e-01, -6.5975e-01,\n",
       "                       9.9036e-01,  1.1949e+00, -8.3162e-01, -1.0066e+00,  6.4923e-01,\n",
       "                      -6.3636e-01, -4.5637e-01,  1.7086e+00, -5.2325e-01, -3.4729e-01,\n",
       "                      -6.1358e-01, -2.7088e-02, -1.5276e-01,  7.4926e-01,  3.8046e-01,\n",
       "                       2.7353e-01,  1.5547e+00, -2.7458e-01,  5.8117e-01,  1.9806e-01,\n",
       "                      -2.4906e-01,  6.8989e-02,  2.0440e+00,  2.4687e+00,  2.6044e-02,\n",
       "                      -3.7735e-02, -3.3969e-01, -1.4058e-01,  1.6772e+00,  1.3478e-01,\n",
       "                      -1.1095e+00,  1.2564e+00,  5.9887e-02,  1.7487e+00,  3.1637e-01,\n",
       "                       1.3780e-01, -2.1810e+00, -6.7272e-01,  3.6232e-01,  9.0527e-01,\n",
       "                       8.3284e-01, -1.7031e-01, -6.5216e-01,  2.9709e-01,  1.5405e+00,\n",
       "                      -1.1618e+00,  5.0694e-01, -4.2719e-01,  1.4506e-01,  3.4135e-01,\n",
       "                       7.0284e-01, -5.6121e-01,  5.4583e-01,  5.2772e-01, -4.6649e-01,\n",
       "                      -1.4473e+00, -7.6566e-01,  8.9009e-01,  1.1445e-01,  2.7939e-01,\n",
       "                      -2.3552e+00,  3.1218e-01,  9.8156e-01, -1.8709e+00, -6.9857e-01,\n",
       "                       9.9820e-01, -1.7174e+00,  1.2976e+00,  1.4139e+00,  1.9964e-01,\n",
       "                       1.6691e+00, -1.4890e-01,  4.3117e-01, -1.0079e+00,  2.7501e-01,\n",
       "                       9.1253e-02,  6.1251e-02,  2.3996e-01, -6.1942e-01, -5.5700e-01,\n",
       "                       1.3441e+00,  1.5252e+00,  2.3297e-01, -7.9761e-01,  2.5463e-01,\n",
       "                       1.6370e-01,  7.8070e-01, -1.5673e+00,  4.0566e-01, -1.1054e+00,\n",
       "                      -3.1337e-01, -1.4771e+00,  9.3829e-02,  1.0054e+00, -2.0418e-01,\n",
       "                      -8.9950e-01, -1.7920e+00,  9.7436e-01,  1.8828e+00,  2.6121e-01,\n",
       "                      -2.1042e+00,  5.6663e-01,  7.7747e-01, -2.0078e-01,  1.2243e+00,\n",
       "                       7.9148e-01,  7.4854e-01,  6.6296e-01, -8.7495e-01,  1.3323e+00,\n",
       "                      -1.0043e+00,  1.2923e+00,  1.3076e+00, -1.6787e+00,  1.1540e+00,\n",
       "                      -9.9279e-01, -9.2075e-01,  2.0594e-01, -2.3035e-01, -1.3542e-01,\n",
       "                       8.5173e-01,  2.2043e+00,  5.0026e-01, -5.2620e-01,  1.8381e+00,\n",
       "                      -1.6783e+00, -1.1094e+00,  8.0417e-01, -1.5045e+00, -6.3118e-01,\n",
       "                      -2.5715e+00, -3.9808e-01,  6.6518e-01,  1.1334e+00,  1.2649e-01,\n",
       "                       9.9517e-01,  5.5134e-01, -1.2465e+00, -1.5499e+00, -8.8326e-01,\n",
       "                      -5.7488e-01,  5.7740e-01,  7.7889e-01, -1.0663e+00, -1.6247e-01,\n",
       "                       5.2348e-02,  1.5684e+00,  1.9636e+00, -7.2691e-02,  1.4627e+00,\n",
       "                       1.9042e+00, -1.6748e-01, -2.9408e+00,  4.8281e-01, -5.9948e-01,\n",
       "                      -1.1287e+00,  1.2399e-01,  1.1510e-01, -1.3892e+00, -1.6940e+00,\n",
       "                      -2.5298e+00,  4.2445e-01,  6.1598e-01, -1.7035e-01, -1.3188e-01,\n",
       "                      -6.7910e-01,  5.2606e-02,  8.1618e-01,  6.8662e-01, -8.4765e-01,\n",
       "                      -2.8008e-01,  3.9642e-01, -1.3458e+00,  1.0963e+00,  3.0945e+00,\n",
       "                       2.6619e-01, -5.9141e-01,  1.7114e+00, -4.5753e-02, -1.0405e+00,\n",
       "                      -1.1767e-01, -1.0111e+00, -5.6452e-01,  8.6697e-02,  1.2141e+00,\n",
       "                       8.5612e-01, -1.9954e-01,  1.2103e+00,  2.8887e-01,  9.1584e-01,\n",
       "                      -9.3856e-01, -7.6978e-02,  1.5046e+00,  1.9253e-01, -1.2369e-01,\n",
       "                      -3.1943e-01,  4.7818e-01,  1.6988e-01,  6.2452e-01, -1.1417e+00,\n",
       "                       7.6875e-01,  5.7837e-01,  9.5008e-01,  1.4463e-01, -3.4193e-02,\n",
       "                       3.6112e-02, -1.3672e+00,  1.5241e+00, -8.8170e-01, -3.9265e-01,\n",
       "                      -8.1016e-01,  2.2261e-01,  1.0177e-02, -1.5222e+00, -1.2587e+00,\n",
       "                      -8.0715e-01,  8.3285e-02,  4.7698e-01,  9.7756e-01], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.tp2.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.actlvs.alpha',\n",
       "              tensor([1.0009, 1.0036, 1.0007, 1.0031, 1.0010, 1.0007, 0.9971, 1.0015, 0.9997,\n",
       "                      0.9987, 0.9997, 1.0012, 1.0004, 0.9988, 0.9998, 0.9975, 1.0197, 1.0011,\n",
       "                      0.9997, 0.9976, 1.0000, 0.9982, 1.0011, 0.9991, 1.0015, 0.9989, 1.0008,\n",
       "                      0.9988, 1.0021, 1.0000, 1.0010, 0.9989, 1.0035, 0.9985, 0.9980, 0.9960,\n",
       "                      0.9971, 0.9982, 1.0033, 0.9994, 1.0006, 0.9948, 0.9992, 1.0003, 1.0008,\n",
       "                      1.0421, 1.0005, 1.0019, 1.0002, 1.0011, 1.0026, 0.9990, 1.0012, 0.9980,\n",
       "                      1.0015, 0.9992, 1.0006, 1.0015, 0.9999, 0.9997, 0.9988, 1.0014, 1.0010,\n",
       "                      1.0087, 0.9986, 0.9988, 1.0016, 1.0019, 0.9997, 0.9999, 0.9998, 0.9980,\n",
       "                      0.9978, 1.0010, 1.0010, 0.9973, 0.9981, 0.9989, 0.9996, 1.0016, 0.9969,\n",
       "                      0.9995, 0.9968, 1.0034, 1.0008, 0.9984, 1.0013, 1.0000, 1.0015, 0.9985,\n",
       "                      1.0008, 1.0007, 1.0027, 0.9977, 0.9999, 0.9965, 0.9944, 0.9994, 1.0013,\n",
       "                      1.0002, 1.0000, 0.9993, 1.0030, 0.9966, 1.0011, 1.0028, 0.9988, 0.9972,\n",
       "                      1.0002, 1.0008, 0.9991, 0.9947, 0.9947, 1.0016, 0.9989, 1.0000, 0.9999,\n",
       "                      1.0014, 0.9951, 1.0009, 0.9929, 0.9984, 0.9998, 0.9996, 0.9983, 1.0002,\n",
       "                      0.9987, 0.9957], device='cuda:0')),\n",
       "             ('blocks.0.update.uattn.actlvs.beta',\n",
       "              tensor([1.7031, 1.7066, 1.7025, 1.7084, 1.7017, 1.7018, 1.7012, 1.7036, 1.7015,\n",
       "                      1.7008, 1.7003, 1.7027, 1.6979, 1.7024, 1.7029, 1.6995, 1.7197, 1.7032,\n",
       "                      1.7000, 1.7052, 1.7026, 1.7003, 1.7036, 1.7001, 1.7015, 1.7013, 1.7028,\n",
       "                      1.7005, 1.7051, 1.7012, 1.6978, 1.7010, 1.7058, 1.7009, 1.7000, 1.7101,\n",
       "                      1.6997, 1.7035, 1.7060, 1.7014, 1.7021, 1.7060, 1.7029, 1.7031, 1.7046,\n",
       "                      1.7559, 1.7025, 1.7002, 1.7025, 1.7013, 1.7051, 1.7018, 1.6928, 1.7016,\n",
       "                      1.7040, 1.7009, 1.7028, 1.7027, 1.7012, 1.7017, 1.7020, 1.7017, 1.7031,\n",
       "                      1.7003, 1.7005, 1.7012, 1.7040, 1.7008, 1.7024, 1.7002, 1.7007, 1.7022,\n",
       "                      1.7023, 1.7023, 1.6998, 1.7045, 1.7009, 1.7009, 1.7001, 1.7038, 1.6994,\n",
       "                      1.7009, 1.7046, 1.7034, 1.7029, 1.7019, 1.7039, 1.7020, 1.7022, 1.7004,\n",
       "                      1.7032, 1.7030, 1.7017, 1.7024, 1.7037, 1.7077, 1.7012, 1.7015, 1.7034,\n",
       "                      1.7023, 1.7023, 1.7013, 1.7031, 1.7085, 1.7034, 1.6998, 1.7039, 1.6990,\n",
       "                      1.7026, 1.7023, 1.7009, 1.7056, 1.7014, 1.7030, 1.7030, 1.7026, 1.6973,\n",
       "                      1.7037, 1.6998, 1.7013, 1.7103, 1.6996, 1.7036, 1.7012, 1.6995, 1.6948,\n",
       "                      1.7008, 1.6976], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.actq.alpha',\n",
       "              tensor([1.1424, 1.0574, 1.1550, 1.0824, 1.0091, 1.0283, 1.0624, 1.0856, 1.1397,\n",
       "                      1.1690, 0.9955, 1.0849, 1.0744, 1.0686, 0.9987, 1.0655, 1.0077, 1.0757,\n",
       "                      1.1308, 1.0382, 1.0462, 1.0832, 1.0713, 1.0579, 0.9665, 1.1199, 1.1425,\n",
       "                      1.0915, 1.1050, 1.0830, 1.0146, 1.0446, 1.0585, 1.0987, 1.0896, 1.1198,\n",
       "                      1.0012, 1.0135, 1.0570, 1.0680, 1.0611, 1.0502, 1.1104, 1.0966, 1.0411,\n",
       "                      1.0288, 1.0397, 1.0004, 1.0560, 1.0465, 1.0834, 1.0473, 1.0147, 1.0118,\n",
       "                      1.1338, 1.0672, 1.0717, 1.0391, 0.9825, 1.0572, 1.0794, 1.0094, 0.9992,\n",
       "                      1.0055, 1.1692, 1.0074, 1.1031, 1.0042, 0.9828, 1.0610, 1.0237, 1.0152,\n",
       "                      1.2288, 1.1181, 1.1219, 1.1028, 1.1079, 1.0429, 1.0214, 1.0684, 1.0940,\n",
       "                      1.0756, 1.0745, 1.0658, 0.9879, 1.0227, 1.1244, 1.0415, 1.0771, 1.0363,\n",
       "                      1.1141, 1.1303, 1.0468, 1.0607, 1.0588, 1.0039, 1.0552, 1.0109, 1.1074,\n",
       "                      1.1148, 0.9988, 1.0420, 1.0754, 1.0403, 0.9909, 1.0930, 1.0052, 1.0846,\n",
       "                      1.0259, 1.0578, 1.0066, 1.0955, 1.0592, 1.0620, 1.1217, 1.0897, 1.0365,\n",
       "                      1.0555, 1.0700, 1.0746, 1.0177, 1.1234, 1.1291, 1.1384, 1.1607, 1.0791,\n",
       "                      1.0164, 1.2645], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.actq.beta',\n",
       "              tensor([1.7627, 1.7254, 1.7573, 1.7747, 1.7047, 1.7103, 1.7327, 1.7487, 1.7457,\n",
       "                      1.8863, 1.7352, 1.7476, 1.7322, 1.7183, 1.7226, 1.7556, 1.7139, 1.7566,\n",
       "                      1.7511, 1.6810, 1.7121, 1.7338, 1.7371, 1.6762, 1.7532, 1.7773, 1.7133,\n",
       "                      1.7242, 1.7320, 1.7095, 1.7156, 1.7196, 1.7589, 1.7258, 1.7223, 1.7736,\n",
       "                      1.7029, 1.6947, 1.6954, 1.7304, 1.7350, 1.7283, 1.7212, 1.7264, 1.7265,\n",
       "                      1.7087, 1.7262, 1.7030, 1.7003, 1.7164, 1.7522, 1.7465, 1.6752, 1.7152,\n",
       "                      1.7574, 1.7477, 1.7281, 1.7157, 1.7303, 1.7012, 1.7025, 1.6992, 1.6977,\n",
       "                      1.7021, 1.7469, 1.7060, 1.7735, 1.7087, 1.6924, 1.7437, 1.7152, 1.7605,\n",
       "                      1.7302, 1.7771, 1.6997, 1.7633, 1.7163, 1.7037, 1.6948, 1.7256, 1.7137,\n",
       "                      1.7305, 1.7633, 1.7505, 1.7169, 1.6970, 1.7351, 1.7302, 1.7299, 1.6904,\n",
       "                      1.7581, 1.7759, 1.7425, 1.7304, 1.7319, 1.7051, 1.7416, 1.7200, 1.7663,\n",
       "                      1.7033, 1.6897, 1.7062, 1.7129, 1.7002, 1.7146, 1.7621, 1.7428, 1.7597,\n",
       "                      1.7180, 1.7150, 1.7119, 1.7173, 1.6938, 1.7359, 1.7641, 1.7220, 1.7256,\n",
       "                      1.7327, 1.7469, 1.7430, 1.7268, 1.7821, 1.7278, 1.7224, 1.7267, 1.7360,\n",
       "                      1.7121, 1.7274], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.actk.alpha',\n",
       "              tensor([1.0344, 1.0444, 1.1260, 1.0810, 1.0063, 1.0068, 1.0074, 1.0300, 1.1679,\n",
       "                      1.1127, 1.0514, 1.0879, 1.0070, 1.0831, 1.0057, 1.0064, 1.0546, 1.0086,\n",
       "                      1.0554, 1.0661, 1.0028, 1.1292, 1.0096, 1.0824, 0.9892, 1.0282, 1.1080,\n",
       "                      1.0827, 1.0150, 1.0271, 0.9945, 1.0013, 1.0130, 1.0094, 1.1406, 1.0819,\n",
       "                      0.9992, 1.0080, 1.0817, 1.0996, 1.0154, 1.1383, 1.0394, 1.0886, 1.1127,\n",
       "                      1.0390, 1.0052, 1.0203, 1.2345, 1.0073, 1.0969, 1.0434, 1.0563, 1.0549,\n",
       "                      1.0790, 1.1794, 1.0235, 1.1218, 1.0923, 1.0900, 1.1074, 1.0470, 1.0065,\n",
       "                      1.1415, 1.0375, 1.0296, 1.1329, 1.0713, 1.0017, 1.0053, 1.2555, 1.1352,\n",
       "                      1.0517, 1.0929, 1.0449, 1.0553, 1.1138, 1.0844, 1.0151, 1.1554, 1.0329,\n",
       "                      1.0421, 1.0798, 1.0652, 1.0083, 0.9960, 1.0020, 0.9981, 1.0345, 1.1051,\n",
       "                      1.1594, 1.1327, 1.1624, 1.0856, 1.0018, 1.0049, 1.0596, 1.0920, 1.0587,\n",
       "                      1.0948, 1.0143, 1.0230, 1.0329, 1.0601, 1.0264, 1.0346, 1.0155, 1.0454,\n",
       "                      1.0569, 1.0121, 1.0498, 1.0101, 1.0657, 0.9990, 1.0817, 1.0207, 1.0409,\n",
       "                      0.9991, 1.1360, 1.0771, 1.0064, 1.0282, 0.9980, 1.0430, 1.0126, 0.9962,\n",
       "                      0.9911, 1.0043], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.actk.beta',\n",
       "              tensor([1.7367, 1.7417, 1.7705, 1.7314, 1.7045, 1.7091, 1.6920, 1.7271, 1.6963,\n",
       "                      1.7694, 1.6543, 1.7854, 1.6799, 1.6614, 1.7073, 1.7011, 1.7403, 1.7092,\n",
       "                      1.6517, 1.6355, 1.7054, 1.7746, 1.7035, 1.7543, 1.7130, 1.6781, 1.7740,\n",
       "                      1.7574, 1.6854, 1.6844, 1.6985, 1.7114, 1.6998, 1.6985, 1.7924, 1.6806,\n",
       "                      1.7030, 1.6874, 1.7663, 1.7650, 1.7072, 1.7705, 1.6854, 1.6412, 1.5966,\n",
       "                      1.6728, 1.6874, 1.7077, 1.8287, 1.7096, 1.7437, 1.7383, 1.7424, 1.7471,\n",
       "                      1.7537, 1.7422, 1.7137, 1.7642, 1.7551, 1.8433, 1.5973, 1.7376, 1.7014,\n",
       "                      1.7771, 1.6602, 1.6702, 1.7840, 1.6910, 1.7036, 1.7066, 1.7045, 1.6896,\n",
       "                      1.7329, 1.7674, 1.6959, 1.7423, 1.7052, 1.7045, 1.7059, 1.7381, 1.7068,\n",
       "                      1.6566, 1.7606, 1.7211, 1.7096, 1.6720, 1.6998, 1.6824, 1.7362, 1.6877,\n",
       "                      1.7958, 1.7140, 1.7655, 1.6344, 1.7069, 1.7055, 1.6325, 1.7646, 1.6455,\n",
       "                      1.7670, 1.7032, 1.6844, 1.6679, 1.7333, 1.6531, 1.6496, 1.6869, 1.6574,\n",
       "                      1.6501, 1.6856, 1.7407, 1.7116, 1.7151, 1.6996, 1.7264, 1.7287, 1.7257,\n",
       "                      1.6881, 1.6979, 1.7795, 1.7058, 1.7344, 1.6996, 1.7103, 1.6998, 1.6882,\n",
       "                      1.6969, 1.6961], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.actv.alpha',\n",
       "              tensor([1.0035, 0.9994, 1.0009, 0.9985, 1.0014, 0.9993, 1.0102, 1.0140, 0.9970,\n",
       "                      1.0057, 1.0491, 0.9874, 1.0002, 0.9958, 1.0010, 1.0015, 1.0015, 1.0001,\n",
       "                      1.0399, 0.9986, 0.9950, 0.9993, 1.0004, 1.0079, 1.0173, 0.9952, 0.9977,\n",
       "                      1.0019, 1.0003, 1.0031, 1.0041, 1.0003, 0.9965, 0.9947, 0.9971, 1.0000,\n",
       "                      0.9989, 1.0049, 1.0130, 0.9995, 0.9998, 1.0090, 0.9877, 1.0055, 1.0026,\n",
       "                      1.0263, 1.0019, 1.0068, 1.0027, 0.9993, 0.9995, 0.9955, 1.0028, 1.0039,\n",
       "                      0.9979, 1.0099, 1.0004, 1.0018, 1.0008, 0.9977, 1.0006, 0.9928, 0.9978,\n",
       "                      1.0031, 1.0030, 0.9982, 1.0018, 0.9950, 1.0097, 1.0134, 1.0161, 0.9993,\n",
       "                      0.9938, 1.0033, 0.9914, 1.0111, 1.0072, 1.0038, 0.9991, 1.0261, 1.0098,\n",
       "                      1.0585, 1.0011, 1.0189, 1.0011, 1.0045, 1.0021, 1.0162, 1.0035, 0.9969,\n",
       "                      1.0078, 1.0000, 0.9991, 1.0043, 1.0173, 0.9980, 0.9994, 1.0158, 0.9978,\n",
       "                      1.0080, 0.9912, 0.9993, 0.9917, 1.0081, 1.0003, 1.0001, 1.0415, 0.9898,\n",
       "                      1.0088, 1.0422, 0.9967, 1.0002, 1.0065, 1.0016, 1.0242, 1.0052, 1.0090,\n",
       "                      1.0112, 1.0038, 1.0018, 1.0115, 1.0061, 1.0154, 1.0045, 1.0312, 1.0042,\n",
       "                      0.9996, 1.0074, 0.9910, 0.9982, 1.0075, 0.9992, 0.9997, 0.9915, 1.0139,\n",
       "                      1.0042, 0.9985, 1.0342, 0.9989, 0.9992, 1.0067, 0.9992, 1.0130, 0.9947,\n",
       "                      1.0041, 1.0035, 1.0035, 1.0060, 1.0034, 1.0013, 1.0076, 1.0089, 1.0107,\n",
       "                      1.0012, 1.0024, 1.0007, 1.0015, 1.0068, 1.0102, 1.0028, 0.9930, 1.0121,\n",
       "                      0.9939, 0.9990, 0.9997, 1.0033, 1.0045, 1.0012, 0.9993, 1.0080, 1.0287,\n",
       "                      1.0026, 1.0043, 1.0351, 1.0100, 0.9795, 0.9892, 0.9927, 0.9957, 1.0041,\n",
       "                      1.0010, 0.9999, 1.0009, 0.9940, 1.0014, 0.9943, 1.0074, 0.9872, 0.9969,\n",
       "                      1.0191, 0.9999, 1.0078, 0.9951, 0.9949, 1.0002, 0.9944, 1.0087, 0.9989,\n",
       "                      0.9990, 1.0017, 0.9972, 1.0039, 1.0220, 1.0057, 0.9899, 0.9961, 1.0025,\n",
       "                      0.9930, 0.9966, 0.9901, 1.0026, 0.9957, 0.9897, 0.9981, 0.9961, 1.0120,\n",
       "                      1.0118, 0.9991, 1.0095, 1.0143, 1.0086, 1.0064, 0.9982, 1.0206, 1.0367,\n",
       "                      0.9944, 1.0060, 0.9963, 0.9916, 1.0028, 1.0024, 0.9990, 0.9975, 1.0084,\n",
       "                      0.9854, 1.0036, 1.0235, 0.9970, 0.9961, 1.0042, 0.9991, 0.9962, 1.0139,\n",
       "                      0.9960, 1.0020, 0.9956, 0.9963, 0.9971, 1.0193, 1.0140, 0.9965, 0.9984,\n",
       "                      0.9943, 1.0074, 1.0004, 1.0016], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.actv.beta',\n",
       "              tensor([1.7080, 1.7009, 1.7017, 1.7006, 1.7035, 1.6898, 1.7189, 1.6984, 1.6989,\n",
       "                      1.6985, 1.7474, 1.7186, 1.7019, 1.7074, 1.7042, 1.7037, 1.6916, 1.6986,\n",
       "                      1.7432, 1.6930, 1.7021, 1.7065, 1.7023, 1.6963, 1.7298, 1.7088, 1.7046,\n",
       "                      1.7007, 1.6994, 1.7361, 1.6878, 1.6994, 1.7042, 1.7037, 1.6979, 1.7036,\n",
       "                      1.7009, 1.6991, 1.6815, 1.7039, 1.7010, 1.6932, 1.7173, 1.7086, 1.7011,\n",
       "                      1.7305, 1.7044, 1.6941, 1.6972, 1.6972, 1.7003, 1.7042, 1.7053, 1.7055,\n",
       "                      1.6916, 1.7073, 1.7024, 1.7034, 1.7080, 1.6955, 1.6993, 1.6954, 1.7052,\n",
       "                      1.7042, 1.7042, 1.6998, 1.7050, 1.6968, 1.6930, 1.7158, 1.7187, 1.7019,\n",
       "                      1.6955, 1.7009, 1.7057, 1.6911, 1.6946, 1.6975, 1.7011, 1.7275, 1.6915,\n",
       "                      1.7244, 1.7000, 1.7201, 1.7030, 1.6978, 1.6952, 1.6841, 1.7004, 1.7021,\n",
       "                      1.6944, 1.7004, 1.6964, 1.7067, 1.6785, 1.7026, 1.6996, 1.7098, 1.6989,\n",
       "                      1.7106, 1.7003, 1.7024, 1.7054, 1.7136, 1.7044, 1.6978, 1.7400, 1.6870,\n",
       "                      1.6855, 1.7091, 1.6976, 1.7000, 1.7074, 1.6995, 1.6970, 1.6996, 1.6942,\n",
       "                      1.6907, 1.6927, 1.6982, 1.7130, 1.7033, 1.7175, 1.7125, 1.7408, 1.6920,\n",
       "                      1.6859, 1.6794, 1.7132, 1.7000, 1.7115, 1.7021, 1.7029, 1.7159, 1.7050,\n",
       "                      1.7077, 1.7004, 1.7258, 1.6957, 1.7036, 1.6856, 1.6969, 1.7227, 1.6976,\n",
       "                      1.6897, 1.6950, 1.7052, 1.6960, 1.7102, 1.7033, 1.6948, 1.7094, 1.7134,\n",
       "                      1.7016, 1.6985, 1.7027, 1.7033, 1.7124, 1.6820, 1.7089, 1.7046, 1.7133,\n",
       "                      1.7031, 1.7008, 1.7034, 1.7053, 1.7054, 1.7008, 1.6998, 1.6958, 1.7177,\n",
       "                      1.6997, 1.6990, 1.7539, 1.7080, 1.7124, 1.6896, 1.7090, 1.6990, 1.6984,\n",
       "                      1.7067, 1.7027, 1.7038, 1.7102, 1.7039, 1.7079, 1.7093, 1.7113, 1.7022,\n",
       "                      1.7238, 1.7018, 1.7106, 1.6983, 1.7095, 1.7017, 1.7000, 1.6941, 1.7013,\n",
       "                      1.7018, 1.6992, 1.7053, 1.6896, 1.7233, 1.7067, 1.6923, 1.7185, 1.6982,\n",
       "                      1.7052, 1.7110, 1.7120, 1.6979, 1.7011, 1.7018, 1.6997, 1.6978, 1.7128,\n",
       "                      1.7098, 1.6998, 1.7090, 1.6952, 1.7089, 1.7091, 1.7020, 1.7292, 1.7302,\n",
       "                      1.7078, 1.6942, 1.6930, 1.7074, 1.7054, 1.7053, 1.7027, 1.7049, 1.7199,\n",
       "                      1.7254, 1.7085, 1.7057, 1.6991, 1.6976, 1.6882, 1.7069, 1.7066, 1.7199,\n",
       "                      1.6957, 1.6988, 1.7070, 1.6981, 1.6988, 1.7267, 1.6874, 1.7101, 1.7045,\n",
       "                      1.7100, 1.6972, 1.7027, 1.7008], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.acta.alpha',\n",
       "              tensor([1.0506, 1.2603, 1.0806, 1.0459, 1.0628, 1.0458, 1.0548, 1.1246, 1.0523,\n",
       "                      1.0390, 1.0800, 1.0636, 1.0794, 1.0668, 1.0515, 1.0587, 1.1150, 1.0146,\n",
       "                      1.0668, 1.0806, 1.0441, 1.0385, 1.0476, 1.0787, 1.0890, 1.1127, 1.0279,\n",
       "                      1.1023, 1.0972, 1.1822, 1.0483, 1.0967, 1.0323, 1.0764, 1.1053, 1.0890,\n",
       "                      1.1058, 1.0134, 1.1594, 1.0708, 1.0384, 1.1279, 1.0705, 1.0617, 1.0674,\n",
       "                      1.0356, 1.0505, 1.0657, 1.0953, 1.0847, 1.1016, 1.0816, 1.0349, 1.0436,\n",
       "                      1.0305, 1.0395, 1.0728, 1.0321, 1.0264, 1.0549, 1.1404, 1.0679, 1.0616,\n",
       "                      1.0513, 1.0974, 1.0629, 1.0729, 1.0279, 1.0473, 1.0641, 1.0284, 1.0658,\n",
       "                      1.0657, 1.0494, 1.0524, 1.1043, 1.0896, 1.0885, 1.3182, 1.1136, 1.0668,\n",
       "                      1.0743, 1.0390, 1.0609, 1.0764, 1.0525, 1.1266, 1.0563, 1.0561, 1.0647,\n",
       "                      1.0842, 1.0985, 1.0628, 1.0481, 1.0545, 1.1311, 1.0577, 1.1141, 1.0192,\n",
       "                      1.1024, 1.0350, 1.0785, 1.0937, 1.0461, 1.1177, 1.0296, 1.1059, 1.1212,\n",
       "                      1.0533, 1.1171, 1.0644, 1.1375, 1.0375, 1.0504, 1.0283, 1.0450, 1.1053,\n",
       "                      1.1114, 1.0832, 1.1011, 1.1460, 1.0404, 1.0879, 1.0307, 1.0528, 1.0334,\n",
       "                      1.0690, 1.1157, 1.0032, 0.9920, 1.0013, 0.9952, 0.9908, 0.9918, 0.9996,\n",
       "                      0.9945, 0.9938, 1.0020, 0.9926, 1.0005, 0.9913, 0.9907, 0.9988, 0.9992,\n",
       "                      0.9915, 1.0038, 0.9926, 0.9910, 0.9934, 0.9988, 1.0017, 0.9959, 1.0023,\n",
       "                      0.9871, 0.9959, 0.9985, 0.9947, 0.9953, 0.9912, 0.9948, 1.0007, 0.9986,\n",
       "                      1.0023, 1.0013, 0.9961, 0.9935, 0.9988, 0.9976, 0.9985, 0.9939, 0.9987,\n",
       "                      0.9970, 0.9980, 0.9945, 1.0018, 0.9970, 0.9961, 0.9988, 0.9965, 1.0007,\n",
       "                      0.9984, 1.0018, 1.0094, 0.9943, 0.9983, 0.9958, 0.9967, 0.9905, 1.0003,\n",
       "                      1.0106, 1.0137, 0.9970, 0.9913, 0.9996, 0.9968, 1.0033, 0.9946, 0.9985,\n",
       "                      0.9991, 0.9972, 1.0006, 1.0006, 0.9988, 0.9956, 0.9945, 0.9967, 0.9943,\n",
       "                      1.0005, 0.9979, 0.9999, 1.0020, 0.9894, 0.9991, 0.9961, 0.9952, 0.9932,\n",
       "                      0.9958, 1.0025, 0.9907, 0.9918, 0.9990, 0.9949, 1.0015, 1.0011, 0.9966,\n",
       "                      0.9986, 0.9982, 0.9975, 1.0017, 0.9963, 0.9944, 0.9955, 0.9942, 1.0073,\n",
       "                      0.9948, 0.9934, 1.0010, 0.9949, 1.0015, 1.0030, 0.9883, 0.9920, 0.9926,\n",
       "                      0.9978, 1.0017, 0.9918, 0.9918, 1.0025, 0.9958, 1.0004, 0.9940, 0.9910,\n",
       "                      0.9952, 1.0025, 0.9970, 1.0014], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.acta.beta',\n",
       "              tensor([1.7191, 1.7828, 1.7363, 1.7140, 1.6920, 1.7243, 1.7361, 1.7750, 1.7102,\n",
       "                      1.6769, 1.7486, 1.6861, 1.7081, 1.7367, 1.6872, 1.6979, 1.7550, 1.6723,\n",
       "                      1.7421, 1.6280, 1.7006, 1.6904, 1.7092, 1.7480, 1.7244, 1.7384, 1.7183,\n",
       "                      1.7267, 1.7435, 1.7179, 1.7251, 1.7354, 1.7422, 1.6788, 1.6621, 1.7689,\n",
       "                      1.6973, 1.7064, 1.6709, 1.7061, 1.6847, 1.7096, 1.6781, 1.7127, 1.7093,\n",
       "                      1.6988, 1.7388, 1.6665, 1.6919, 1.7461, 1.6721, 1.7134, 1.6625, 1.7228,\n",
       "                      1.7101, 1.6704, 1.6672, 1.7357, 1.6939, 1.6887, 1.6889, 1.7120, 1.6557,\n",
       "                      1.6806, 1.7477, 1.6722, 1.6847, 1.6824, 1.7566, 1.6959, 1.6912, 1.7136,\n",
       "                      1.6671, 1.7200, 1.6850, 1.6713, 1.7663, 1.7190, 1.8466, 1.7323, 1.7255,\n",
       "                      1.7476, 1.7185, 1.7322, 1.7828, 1.6813, 1.7240, 1.7564, 1.7205, 1.6985,\n",
       "                      1.7553, 1.7806, 1.7313, 1.7185, 1.6825, 1.6816, 1.7010, 1.7173, 1.6959,\n",
       "                      1.7555, 1.6796, 1.7521, 1.7832, 1.7147, 1.6969, 1.7204, 1.7594, 1.7067,\n",
       "                      1.6809, 1.7506, 1.6321, 1.6573, 1.6854, 1.7050, 1.7074, 1.7007, 1.8214,\n",
       "                      1.6787, 1.6439, 1.7352, 1.6956, 1.7313, 1.7237, 1.6798, 1.6919, 1.7450,\n",
       "                      1.7813, 1.6343, 1.6788, 1.6958, 1.7074, 1.7137, 1.6798, 1.7112, 1.7161,\n",
       "                      1.6974, 1.7009, 1.7165, 1.7013, 1.7032, 1.6981, 1.7068, 1.7045, 1.7062,\n",
       "                      1.6953, 1.7224, 1.7041, 1.7011, 1.7024, 1.6976, 1.7208, 1.7020, 1.7271,\n",
       "                      1.7046, 1.6928, 1.6979, 1.7167, 1.7295, 1.7054, 1.7091, 1.6997, 1.7001,\n",
       "                      1.6994, 1.7100, 1.7095, 1.6899, 1.6880, 1.7185, 1.7040, 1.6993, 1.6984,\n",
       "                      1.7037, 1.6993, 1.7003, 1.6821, 1.7037, 1.7196, 1.7089, 1.7042, 1.7062,\n",
       "                      1.7064, 1.6909, 1.7068, 1.6996, 1.6990, 1.7020, 1.7038, 1.6992, 1.7113,\n",
       "                      1.6900, 1.6819, 1.7086, 1.7013, 1.7131, 1.7247, 1.7099, 1.7236, 1.6885,\n",
       "                      1.7040, 1.6809, 1.6916, 1.6990, 1.7037, 1.7016, 1.6966, 1.7013, 1.7041,\n",
       "                      1.7028, 1.7050, 1.6933, 1.7131, 1.6927, 1.6984, 1.7011, 1.7001, 1.7063,\n",
       "                      1.7117, 1.7024, 1.6989, 1.6965, 1.7076, 1.7095, 1.6892, 1.7054, 1.6990,\n",
       "                      1.7090, 1.6970, 1.7071, 1.6966, 1.6949, 1.7070, 1.7080, 1.7143, 1.7427,\n",
       "                      1.7047, 1.7062, 1.6721, 1.7027, 1.7051, 1.7074, 1.6992, 1.7003, 1.7004,\n",
       "                      1.7008, 1.6909, 1.6905, 1.7047, 1.7110, 1.6964, 1.6997, 1.7102, 1.6981,\n",
       "                      1.6984, 1.7050, 1.6897, 1.7077], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.lq.weight',\n",
       "              tensor([[ 0.2185, -0.0917,  0.1258,  ...,  0.1237,  0.0941,  0.0197],\n",
       "                      [-0.1312, -0.1192, -0.0640,  ...,  0.0516,  0.0203, -0.0126],\n",
       "                      [ 0.2422,  0.0068, -0.0543,  ...,  0.2772, -0.1858,  0.2113],\n",
       "                      ...,\n",
       "                      [ 0.1392,  0.0653, -0.0187,  ..., -0.0701,  0.1020,  0.0303],\n",
       "                      [-0.0777, -0.1053,  0.0547,  ...,  0.1439, -0.1596,  0.1085],\n",
       "                      [ 0.3182,  0.1998,  0.1434,  ...,  0.1558,  0.0410, -0.0407]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.lq.bias',\n",
       "              tensor([ 0.0370,  0.0271,  0.1006,  0.0630, -0.0202,  0.0394,  0.0509,  0.0730,\n",
       "                       0.0593,  0.0919, -0.0395,  0.0611,  0.0561,  0.0392,  0.0133, -0.0033,\n",
       "                      -0.0206,  0.0336,  0.0651,  0.0228,  0.0340,  0.0430,  0.0620,  0.0310,\n",
       "                      -0.0078,  0.0724,  0.0739,  0.0569,  0.0524,  0.0336,  0.0022,  0.0035,\n",
       "                       0.0281,  0.0255,  0.0444,  0.0747,  0.0012,  0.0090,  0.0400,  0.0263,\n",
       "                       0.0301,  0.0193,  0.0404,  0.0610,  0.0192,  0.0200,  0.0280, -0.0106,\n",
       "                      -0.0131,  0.0179,  0.0225,  0.0366, -0.0037,  0.0045,  0.0661,  0.0348,\n",
       "                       0.0426,  0.0325, -0.0206,  0.0544,  0.0668,  0.0036,  0.0071, -0.0069,\n",
       "                       0.0253, -0.0111,  0.0340, -0.0055, -0.0118,  0.0428,  0.0169, -0.0047,\n",
       "                       0.0754,  0.0627,  0.0869,  0.0732,  0.0674,  0.0087,  0.0038,  0.0011,\n",
       "                       0.0288,  0.0244,  0.0342,  0.0252, -0.0164,  0.0134,  0.0438,  0.0107,\n",
       "                       0.0413,  0.0002,  0.0569,  0.1069,  0.0017,  0.0251,  0.0158, -0.0017,\n",
       "                      -0.0048, -0.0017,  0.0390,  0.0704,  0.0024,  0.0392,  0.0553,  0.0360,\n",
       "                      -0.0112,  0.0544, -0.0156,  0.0669, -0.0041,  0.0165, -0.0004,  0.0116,\n",
       "                       0.0026,  0.0328,  0.1047,  0.0423,  0.0125,  0.0247,  0.0550,  0.0165,\n",
       "                       0.0245,  0.0941,  0.0555,  0.0672,  0.1368,  0.0288,  0.0006,  0.0493],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.lk.weight',\n",
       "              tensor([[ 0.1169, -0.0468,  0.1074,  ..., -0.1147, -0.0583, -0.1029],\n",
       "                      [ 0.0895, -0.0598,  0.0095,  ...,  0.1510,  0.1174,  0.1564],\n",
       "                      [ 0.0866,  0.0939,  0.0993,  ..., -0.0304,  0.0537,  0.0343],\n",
       "                      ...,\n",
       "                      [-0.1367, -0.0426, -0.1166,  ..., -0.1449, -0.0809,  0.0729],\n",
       "                      [ 0.0671, -0.0393, -0.0971,  ...,  0.0168, -0.1375,  0.0558],\n",
       "                      [-0.1327, -0.0964, -0.1296,  ...,  0.1074,  0.0797, -0.1069]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.lk.bias',\n",
       "              tensor([ 0.0263,  0.0225,  0.0775,  0.0312,  0.0031,  0.0036,  0.0232,  0.0169,\n",
       "                       0.0813,  0.0639, -0.0179,  0.0734,  0.0074,  0.0315,  0.0059,  0.0066,\n",
       "                       0.0361,  0.0089, -0.0051, -0.0087,  0.0033,  0.0907,  0.0137,  0.0587,\n",
       "                      -0.0281, -0.0012,  0.0428,  0.0636,  0.0238, -0.0152, -0.0033, -0.0195,\n",
       "                      -0.0105, -0.0102,  0.1297,  0.0458,  0.0079, -0.0298,  0.0454,  0.0506,\n",
       "                       0.0143,  0.1250,  0.0148,  0.0095,  0.0008, -0.0061,  0.0076,  0.0135,\n",
       "                       0.1432, -0.0002,  0.0672,  0.0370,  0.0479,  0.0418,  0.0646,  0.1050,\n",
       "                       0.0109,  0.0826,  0.0508,  0.1110, -0.0335,  0.0185,  0.0232,  0.0681,\n",
       "                      -0.0189,  0.0126,  0.1187,  0.0462,  0.0028,  0.0059,  0.1086,  0.0771,\n",
       "                       0.0355,  0.0736,  0.0343,  0.0469,  0.0711,  0.0159,  0.0193,  0.0439,\n",
       "                       0.0240, -0.0049,  0.0701,  0.0718, -0.0062, -0.0274, -0.0088, -0.0093,\n",
       "                       0.0474,  0.0459,  0.1072,  0.0687,  0.0724, -0.0267, -0.0098,  0.0071,\n",
       "                      -0.0113,  0.0689, -0.0298,  0.0852,  0.0091,  0.0116, -0.0180,  0.0540,\n",
       "                      -0.0077, -0.0413, -0.0243, -0.0186, -0.0195, -0.0184,  0.0401,  0.0065,\n",
       "                       0.0491,  0.0019,  0.0819,  0.0304,  0.0109, -0.0027,  0.0792,  0.0728,\n",
       "                       0.0079,  0.0304, -0.0003,  0.0419,  0.0079, -0.0112, -0.0095, -0.0053],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.lv.weight',\n",
       "              tensor([[-0.0957,  0.0716, -0.0525,  ...,  0.0462, -0.0397,  0.0554],\n",
       "                      [-0.1225, -0.1115, -0.0064,  ...,  0.0685,  0.0435,  0.1010],\n",
       "                      [ 0.1193, -0.0697, -0.1141,  ...,  0.1167, -0.0787, -0.0570],\n",
       "                      ...,\n",
       "                      [-0.0463,  0.0763,  0.0589,  ..., -0.1099,  0.1194, -0.0375],\n",
       "                      [ 0.0691,  0.0239,  0.0660,  ..., -0.0321, -0.0610, -0.0024],\n",
       "                      [ 0.0448, -0.0969, -0.0832,  ...,  0.0330,  0.0509, -0.0178]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.lv.bias',\n",
       "              tensor([ 3.4009e-03, -1.3693e-03, -7.6887e-03, -1.1346e-03,  2.6950e-03,\n",
       "                      -1.5363e-02,  1.9485e-02,  4.9649e-03, -4.8449e-03,  5.3136e-03,\n",
       "                       3.1584e-02, -2.9394e-03, -2.9498e-03, -5.8496e-04,  1.3601e-02,\n",
       "                       2.9748e-03, -7.5848e-03,  6.8645e-03,  2.5463e-02,  5.5811e-04,\n",
       "                      -9.2354e-04, -1.8866e-03,  5.7735e-04,  4.7232e-03,  2.0982e-02,\n",
       "                       4.7517e-03, -1.3176e-04,  3.8642e-03, -6.1148e-03,  1.8004e-02,\n",
       "                      -1.3260e-03, -4.0076e-03, -1.0990e-03, -2.1735e-03,  4.4334e-03,\n",
       "                       6.5254e-03,  1.7961e-04,  1.3172e-03, -1.0210e-02, -2.5535e-03,\n",
       "                       1.3442e-03, -3.4138e-04, -1.2355e-02,  9.6653e-03, -5.2098e-03,\n",
       "                       1.8302e-02,  1.5365e-03,  6.8283e-04,  2.2029e-04, -2.2353e-03,\n",
       "                      -1.6246e-03, -2.3007e-03,  7.7362e-04,  4.2943e-03, -1.7707e-02,\n",
       "                       1.9918e-02,  1.8254e-03,  3.2792e-03,  5.8144e-03, -1.5888e-03,\n",
       "                       8.9813e-04, -6.6278e-03, -7.9920e-03,  1.9362e-03, -7.2041e-03,\n",
       "                      -2.0796e-03, -7.9642e-03, -3.0952e-03, -9.4065e-03,  1.9269e-02,\n",
       "                       2.2242e-02, -4.4564e-04, -5.4811e-03,  1.0687e-03,  3.3334e-02,\n",
       "                      -9.4012e-03,  1.0520e-02, -4.7383e-03, -4.2743e-04,  2.4660e-02,\n",
       "                      -5.1664e-03,  5.0420e-02,  5.5144e-03,  2.0352e-02,  2.1828e-03,\n",
       "                       7.3403e-04, -6.4568e-04, -2.0644e-03, -2.0634e-03,  1.2403e-03,\n",
       "                      -4.5647e-04, -1.4948e-04, -1.2593e-03,  4.4485e-03, -1.1653e-02,\n",
       "                      -1.2616e-03,  3.4591e-03,  1.3047e-02, -1.3656e-03,  6.7169e-03,\n",
       "                       4.0986e-04, -1.9604e-03,  9.3264e-03,  4.0319e-03,  6.8419e-05,\n",
       "                      -2.2985e-03,  3.1131e-02, -1.6813e-02, -1.1279e-02,  1.4199e-02,\n",
       "                      -4.5555e-03,  6.0870e-03,  6.3263e-03,  5.4102e-04,  2.1630e-02,\n",
       "                      -2.3746e-03,  5.8178e-03, -1.9727e-04, -8.5821e-03,  9.6701e-03,\n",
       "                       1.3126e-02,  6.3632e-03,  6.3874e-03,  4.9636e-03,  1.7447e-02,\n",
       "                      -6.2301e-03, -1.4964e-02, -9.8274e-03, -2.7364e-03, -2.4700e-03,\n",
       "                       4.5161e-03,  6.3653e-03, -4.0492e-03, -6.4609e-03,  1.7997e-02,\n",
       "                       1.7242e-03, -1.1887e-03,  2.7514e-02, -3.2323e-03,  5.4903e-04,\n",
       "                      -7.5653e-03, -3.0778e-03,  8.2058e-03, -2.3500e-03, -2.8426e-03,\n",
       "                      -1.7796e-04,  4.9663e-03, -2.8257e-03,  2.7210e-03, -5.7604e-04,\n",
       "                       1.1622e-03,  8.6246e-03,  9.3174e-03, -8.5272e-04,  2.6913e-03,\n",
       "                       1.3913e-03,  2.7045e-03,  3.5486e-03, -8.0376e-03,  7.9784e-03,\n",
       "                      -4.1256e-03,  2.2553e-02,  1.3030e-03, -3.5373e-04, -4.1618e-03,\n",
       "                       5.8710e-03,  6.7458e-03,  8.1927e-03, -2.2138e-03, -8.5188e-03,\n",
       "                       2.2803e-02, -3.7058e-03, -2.0699e-03,  3.6913e-02,  5.1602e-03,\n",
       "                      -5.6322e-03, -6.0066e-03, -1.5551e-03, -3.1050e-03, -3.1512e-03,\n",
       "                      -9.0276e-03,  3.2507e-03,  6.6154e-03, -3.5719e-05,  5.8892e-03,\n",
       "                       7.3313e-03,  6.1042e-03,  1.9704e-03,  3.8098e-03,  6.4408e-03,\n",
       "                       6.0473e-05,  1.0196e-02, -1.5973e-03,  1.0208e-03,  2.3642e-03,\n",
       "                      -2.9399e-03, -2.2810e-03, -4.6142e-03,  8.7995e-04, -5.3278e-03,\n",
       "                      -2.4919e-04,  9.6403e-03,  2.5111e-02,  1.0049e-02, -2.0016e-02,\n",
       "                      -6.5418e-04,  4.4029e-04, -3.6236e-03, -9.0576e-04,  9.8773e-04,\n",
       "                      -2.9690e-04,  1.0566e-02, -1.0323e-02, -2.1326e-03, -6.9831e-03,\n",
       "                       1.9765e-02,  1.6898e-02, -8.4862e-04,  2.8574e-03,  2.1840e-03,\n",
       "                       8.5775e-03,  6.0933e-03,  3.0825e-04,  9.0532e-04,  1.6037e-02,\n",
       "                       7.3065e-03, -4.6519e-03, -2.5414e-03, -6.5373e-05,  4.8441e-03,\n",
       "                       3.2379e-03, -3.3489e-03,  1.0674e-02,  1.1578e-03, -1.0622e-03,\n",
       "                       2.4823e-03,  7.3208e-03, -5.0411e-04, -1.5836e-03,  4.1779e-03,\n",
       "                      -1.0916e-02,  6.7693e-04,  1.0614e-02, -3.7952e-03,  1.0620e-03,\n",
       "                      -5.9224e-03, -3.8034e-03, -2.4119e-03,  1.7825e-02, -3.4156e-03,\n",
       "                      -1.6552e-02, -1.2955e-05,  1.3489e-03, -1.6086e-03,  7.9413e-04,\n",
       "                      -6.3052e-03], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.la.weight',\n",
       "              tensor([[-0.0957,  0.0229, -0.0667,  ..., -0.0556,  0.1551, -0.1256],\n",
       "                      [ 0.0733, -0.1362,  0.1125,  ..., -0.1496,  0.2186, -0.2019],\n",
       "                      [-0.0509,  0.0698,  0.0224,  ..., -0.0783, -0.0207,  0.0488],\n",
       "                      ...,\n",
       "                      [-0.0379, -0.0467, -0.0627,  ..., -0.0372,  0.0135, -0.0152],\n",
       "                      [-0.0202, -0.0844,  0.0988,  ...,  0.0305,  0.0664, -0.0717],\n",
       "                      [ 0.0636, -0.0053, -0.0267,  ..., -0.0482,  0.0550, -0.0065]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.la.bias',\n",
       "              tensor([ 3.1601e-02, -1.9312e-02, -7.9416e-03, -1.9819e-02, -1.3684e-02,\n",
       "                       1.3905e-02,  3.1152e-02,  5.8698e-02,  1.8561e-02, -1.0091e-02,\n",
       "                       6.2259e-02, -1.5011e-02, -3.3463e-02,  2.5158e-03, -1.1093e-02,\n",
       "                      -3.4244e-02,  2.1489e-02, -6.5664e-03,  4.2328e-02, -3.8267e-02,\n",
       "                      -3.1974e-02,  1.3532e-02,  9.3913e-03,  9.5748e-03,  9.2596e-03,\n",
       "                       2.8730e-02, -6.1427e-03,  1.9109e-02, -4.9144e-03, -5.4697e-03,\n",
       "                       2.3487e-02,  2.7713e-03, -1.1342e-02, -1.9366e-02, -6.1869e-03,\n",
       "                       5.3048e-02, -7.4772e-03,  1.2852e-02, -1.9716e-02, -3.8295e-02,\n",
       "                      -1.4198e-02,  2.3545e-03, -1.2594e-03,  1.0317e-02, -1.9216e-02,\n",
       "                      -3.6111e-03,  2.6603e-02, -3.0112e-02, -8.7454e-03,  2.4531e-02,\n",
       "                       7.8208e-03, -2.6410e-02, -2.6856e-02,  2.0033e-02,  2.6852e-02,\n",
       "                      -3.1220e-02, -7.4777e-03,  2.1000e-02, -1.3680e-02,  2.8382e-02,\n",
       "                      -3.3457e-02, -1.2910e-03, -4.8033e-02, -4.3060e-02,  4.7371e-02,\n",
       "                      -3.0374e-02, -2.1005e-02, -3.1915e-02,  2.3613e-02,  4.1983e-02,\n",
       "                      -3.6943e-02,  3.2779e-03, -1.5103e-02, -8.9862e-04, -3.4870e-02,\n",
       "                      -6.3834e-03,  2.3553e-02,  2.6164e-02,  1.0648e-01,  4.9608e-02,\n",
       "                       3.0915e-02,  2.0845e-02, -2.4614e-02,  1.5327e-02,  1.8320e-02,\n",
       "                      -5.0449e-02,  3.9578e-03,  1.4612e-02,  2.5531e-02, -2.9670e-02,\n",
       "                       1.3492e-02,  2.8099e-02,  3.4521e-02,  1.6369e-02, -2.4248e-02,\n",
       "                      -1.8482e-02,  7.6122e-03,  1.5863e-02, -2.3805e-02,  2.6482e-02,\n",
       "                      -2.3322e-02,  5.0301e-02,  5.2788e-02, -1.1974e-02, -6.6065e-03,\n",
       "                       1.2564e-02,  8.9194e-02,  1.5626e-02, -3.3604e-02,  6.1926e-03,\n",
       "                       6.5064e-04, -4.3394e-02, -1.3792e-02,  1.1624e-02, -7.8510e-03,\n",
       "                      -6.3086e-03,  5.5639e-02, -2.0157e-02,  9.6649e-04,  2.5045e-02,\n",
       "                       4.5825e-04,  2.7680e-02, -1.2265e-03,  2.5607e-02, -3.2253e-02,\n",
       "                      -1.4293e-03,  2.3434e-02, -6.8230e-02, -1.8370e-03,  6.9280e-04,\n",
       "                      -3.8034e-04,  6.4104e-05,  9.9346e-04,  1.3521e-03,  1.5754e-03,\n",
       "                      -1.0830e-03,  3.8233e-04,  3.6094e-04,  2.1007e-03, -6.6166e-05,\n",
       "                       2.0737e-03,  1.0321e-03, -8.4422e-04, -5.1447e-04,  1.4581e-03,\n",
       "                      -3.2439e-03,  1.0994e-03, -4.7511e-04,  9.7950e-04, -1.1912e-03,\n",
       "                       1.7544e-03, -5.9021e-04,  1.5308e-03, -5.5424e-04, -2.7298e-04,\n",
       "                       7.2087e-04,  1.0766e-03, -2.4358e-04,  1.3079e-04, -8.0178e-04,\n",
       "                      -4.3215e-04,  8.5890e-04, -1.5508e-03, -1.5245e-03,  1.8705e-03,\n",
       "                      -1.8387e-03, -3.0680e-05, -5.3687e-04, -4.9869e-04, -6.0658e-04,\n",
       "                      -3.6156e-04,  4.5267e-04, -2.6077e-04,  8.5401e-04,  3.6766e-03,\n",
       "                       2.7098e-05,  1.1751e-03,  9.1317e-05, -1.9201e-04,  1.1903e-03,\n",
       "                       1.6477e-05, -3.8109e-03, -7.4499e-04, -2.7312e-03, -1.6231e-03,\n",
       "                      -5.9451e-04,  1.5422e-03,  1.6427e-04,  3.1153e-04,  2.0819e-03,\n",
       "                       4.9657e-03, -9.6367e-04,  3.7202e-04, -4.1983e-04, -2.8443e-04,\n",
       "                       7.5817e-05,  2.0424e-04, -1.1136e-03, -1.7825e-03,  1.6838e-03,\n",
       "                      -8.5064e-04,  1.9314e-04,  3.4332e-04,  5.9910e-04, -2.0097e-04,\n",
       "                      -3.5905e-04, -1.7509e-04,  1.0260e-03, -1.5184e-04,  2.7100e-05,\n",
       "                       2.7621e-03,  1.8983e-03, -1.7336e-04,  6.2726e-04,  1.7005e-03,\n",
       "                       1.2728e-03,  1.7401e-03,  6.7907e-04,  5.8746e-04, -3.0483e-04,\n",
       "                      -1.0570e-03, -1.0212e-03, -8.6692e-04, -1.1791e-03,  2.4779e-04,\n",
       "                       6.7144e-05, -1.7980e-05,  1.4931e-05, -4.1741e-04, -3.5503e-04,\n",
       "                       6.4781e-04, -1.3938e-03, -9.3489e-04,  5.3758e-03,  5.4052e-03,\n",
       "                      -1.6126e-03, -5.0768e-04,  1.2799e-03,  1.0759e-03, -1.4545e-03,\n",
       "                      -3.9093e-04, -8.1109e-04, -4.4824e-04, -1.9362e-04, -8.8544e-05,\n",
       "                       7.6546e-04,  5.9812e-05,  9.8344e-04, -2.5969e-04,  1.5744e-03,\n",
       "                      -1.0235e-03,  1.2283e-03,  2.2630e-03,  4.2566e-04, -1.0679e-03,\n",
       "                       3.3600e-04], device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.lrbf.weight',\n",
       "              tensor([[-0.1020,  0.1357, -0.1482,  ..., -0.0216, -0.1982, -0.1401],\n",
       "                      [-0.1627, -0.1511, -0.0861,  ..., -0.1334, -0.0202,  0.1390],\n",
       "                      [ 0.1188,  0.0713, -0.0375,  ..., -0.1291, -0.1061,  0.0579],\n",
       "                      ...,\n",
       "                      [ 0.1540, -0.0060,  0.1471,  ...,  0.0338,  0.1710, -0.1709],\n",
       "                      [-0.1656, -0.0026,  0.1044,  ..., -0.0264, -0.1467,  0.1479],\n",
       "                      [ 0.0018,  0.1680,  0.0503,  ..., -0.1628, -0.0619, -0.1757]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.lkrbf.weight',\n",
       "              tensor([[-0.1702, -0.0777, -0.1325,  ...,  0.0805, -0.0601,  0.0763],\n",
       "                      [-0.0040,  0.1453,  0.1019,  ...,  0.1502,  0.0675,  0.0185],\n",
       "                      [-0.0303,  0.0976, -0.0748,  ..., -0.0606,  0.1672,  0.0778],\n",
       "                      ...,\n",
       "                      [ 0.1392,  0.0410, -0.0132,  ..., -0.1400, -0.0552,  0.1070],\n",
       "                      [-0.1330,  0.1259,  0.1294,  ..., -0.0715, -0.0125,  0.1386],\n",
       "                      [ 0.1193, -0.0408, -0.1033,  ...,  0.0797,  0.0928,  0.1268]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.Attention.lvrbf.weight',\n",
       "              tensor([[ 0.0291,  0.0107, -0.0693,  ..., -0.0682, -0.0642,  0.0402],\n",
       "                      [ 0.0355, -0.0113,  0.1170,  ..., -0.0751,  0.1290,  0.0070],\n",
       "                      [ 0.1102,  0.0932,  0.0837,  ..., -0.0128, -0.1175,  0.1048],\n",
       "                      ...,\n",
       "                      [-0.0927, -0.0844, -0.0837,  ...,  0.0863,  0.1081, -0.0088],\n",
       "                      [ 0.0930, -0.0351, -0.0275,  ..., -0.0355, -0.0616,  0.0488],\n",
       "                      [-0.0972,  0.0810, -0.1068,  ..., -0.0083,  0.0937, -0.0619]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.tp.weight',\n",
       "              tensor([ 0.4178,  0.9947,  1.3171,  0.3012,  1.6488,  0.4884, -0.6224,  0.2973,\n",
       "                       0.7532,  0.3141, -0.4746, -0.9618, -1.9700, -0.1334,  0.2259,  2.2479,\n",
       "                      -0.4629,  2.2331,  0.2460, -1.3074,  0.6646,  2.3895,  0.2226,  0.1474,\n",
       "                      -0.8650, -0.1902, -0.5772,  0.5806, -0.3979, -1.0880, -2.7503,  0.5076,\n",
       "                      -0.0470,  0.3099, -0.7818, -0.9565, -2.0544, -0.2058,  0.6980, -0.9458,\n",
       "                       0.7036, -0.3760, -0.2843, -0.5053,  0.7650, -0.2116, -0.2470,  0.4093,\n",
       "                       1.0581, -1.4412, -1.5840,  0.3184, -1.4538,  0.3682, -0.2495, -0.7195,\n",
       "                       1.2013, -1.1849,  0.1097,  1.3686,  0.7952, -0.3209, -1.3691, -0.0406,\n",
       "                       0.3920, -2.5226, -0.0617,  0.9703, -0.0551, -1.6664, -0.2707,  1.1156,\n",
       "                      -0.0892,  0.6432, -0.4704, -0.2694,  1.2711, -1.1620, -1.4773,  0.4822,\n",
       "                      -2.0249,  0.4368, -1.5093,  1.1233,  0.8404,  1.1682,  2.3027, -0.1315,\n",
       "                      -1.8604, -0.9076, -0.6921, -1.1496, -1.6800,  0.0693,  0.7394, -0.0489,\n",
       "                       0.0091, -2.0585,  0.0752,  0.6831,  1.6314,  0.1091,  1.4914, -0.8151,\n",
       "                      -0.2513, -1.1968,  0.1822, -0.0864,  1.3023, -1.4304, -0.9603,  0.0216,\n",
       "                       0.5336,  1.7785,  0.2907, -0.4336, -0.3985, -1.4589,  0.3109, -0.7257,\n",
       "                       1.0353,  0.8100,  2.4966,  0.4651, -0.2861,  0.9620, -1.5639,  1.3189,\n",
       "                       0.9688,  0.5230, -0.4565,  0.3853,  0.5003, -0.8555, -1.8445, -2.0585,\n",
       "                       0.0580, -0.8880, -2.2927, -0.4643,  1.1058,  0.5405, -0.1326, -0.2080,\n",
       "                       0.7006,  0.1086, -0.8576,  3.1337, -0.2748, -0.4491,  0.4835, -0.1053,\n",
       "                       0.4563, -1.1522,  2.4854, -0.0175, -0.4646,  1.7869,  0.5251,  1.0428,\n",
       "                      -0.8743,  2.0271,  0.0418, -2.3863, -2.3363, -0.4175,  1.1226,  0.5468,\n",
       "                      -0.9780, -0.8205, -0.7616, -0.6064, -0.5594, -0.7664,  0.6839, -1.0501,\n",
       "                      -0.9884, -0.6185, -0.2185,  0.9401,  0.1731, -1.0277, -0.5359, -0.4819,\n",
       "                      -1.9065, -1.0443, -0.6791, -0.1214, -0.8117,  1.5833, -0.4151, -0.9633,\n",
       "                       1.8775, -0.4401, -0.4078, -0.3417,  1.2713,  0.5517,  1.0431,  0.4079,\n",
       "                       0.1060, -1.9765, -1.3333, -2.1100, -0.0738, -0.7853,  0.5187, -1.7757,\n",
       "                       0.8154,  2.1919, -1.1389, -1.6707, -0.0869, -0.3522, -1.5306,  0.6149,\n",
       "                      -0.7520, -1.0819, -0.3208, -1.5990, -0.6407,  0.6265,  0.2338, -0.7183,\n",
       "                       1.1811,  0.6552,  0.2154, -0.4927, -0.5587, -0.7083,  0.1499, -0.9571,\n",
       "                      -0.7825,  0.4050, -1.7892,  1.0672,  0.4444,  0.9725, -1.3810, -1.7744,\n",
       "                      -0.5534, -0.1906,  0.7146,  0.4579,  2.0872, -0.8181,  0.4570,  0.7180,\n",
       "                      -0.5898,  0.6238,  0.9878,  0.2717, -1.4146, -0.4166, -1.1865,  0.6032,\n",
       "                      -1.1973, -0.9427, -0.1716, -0.0962, -0.3928, -0.8437,  0.8807, -0.4663,\n",
       "                      -1.3208,  0.4416,  1.9521, -0.8310,  1.1260, -0.9915,  0.7613, -0.3977,\n",
       "                      -1.0692, -1.7196,  0.9637, -0.2308, -0.1703, -0.1174, -0.2788, -0.9296,\n",
       "                       0.2163, -3.5304,  1.9922,  1.0656,  1.5024,  2.5399,  0.6331,  1.1065,\n",
       "                      -0.7316,  0.2975,  1.6461,  0.1679,  1.9417,  0.0962, -1.7117, -0.6921,\n",
       "                      -0.4062,  0.4673, -1.0246, -1.0193,  0.9411,  0.7759, -0.6865, -0.7380,\n",
       "                      -1.5088, -0.9986, -2.0996,  0.1513, -1.0269, -0.6937, -0.0561, -0.3646,\n",
       "                      -0.4308,  0.6593,  0.5507,  1.3624, -1.3404, -1.5110, -0.5296, -0.9653,\n",
       "                      -0.5156, -0.3386, -0.4157, -0.1515,  0.6525, -0.1002, -0.5907,  1.4490,\n",
       "                      -1.0579,  0.5211,  1.2703, -0.3242,  1.2891,  0.5851, -2.3012, -0.4609,\n",
       "                      -0.0989, -0.6189,  0.9585, -1.7136,  0.6531, -0.1318,  0.0933, -1.6807,\n",
       "                       0.6169, -0.8242,  1.0566, -0.3163,  0.1589,  0.5621,  0.5061, -0.7765,\n",
       "                       1.2587, -0.7963,  0.0862, -1.1521, -0.3448, -2.6823,  2.0893, -0.2976,\n",
       "                      -0.7542,  0.1122,  0.6984, -1.7759, -0.1318, -0.5773, -1.8726,  0.7125,\n",
       "                      -0.8563, -1.1195,  1.3558, -0.9379,  0.3492,  1.2159, -0.8465, -1.5368,\n",
       "                       0.8245, -0.6806,  0.3180, -0.2294,  1.6794, -0.3002, -0.4027,  0.2481],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.message.tp.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.1.update.actu.alpha',\n",
       "              tensor([0.9903, 0.9919, 1.0027, 0.9966, 0.9971, 1.0202, 0.9973, 0.9979, 0.9989,\n",
       "                      0.9958, 0.9950, 0.9969, 1.0007, 0.9917, 0.9930, 0.9985, 1.0025, 1.0062,\n",
       "                      1.0009, 0.9890, 0.9947, 0.9978, 0.9927, 0.9942, 0.9940, 1.0027, 0.9979,\n",
       "                      0.9953, 0.9977, 0.9882, 0.9863, 0.9981, 0.9903, 1.0008, 0.9900, 0.9995,\n",
       "                      0.9994, 0.9977, 0.9972, 0.9946, 1.0006, 0.9843, 1.0003, 0.9984, 0.9970,\n",
       "                      1.0060, 1.0034, 0.9950, 1.0093, 0.9992, 0.9983, 0.9891, 1.0058, 0.9981,\n",
       "                      0.9954, 1.0009, 0.9981, 0.9955, 1.0029, 0.9913, 1.0082, 0.9988, 0.9859,\n",
       "                      1.0081, 0.9939, 1.0011, 0.9944, 1.0004, 0.9995, 0.9958, 1.0027, 1.0019,\n",
       "                      0.9932, 0.9926, 1.0007, 1.0004, 0.9953, 0.9966, 0.9897, 0.9954, 0.9962,\n",
       "                      0.9937, 0.9960, 1.0113, 0.9947, 0.9989, 0.9960, 0.9933, 1.0111, 0.9925,\n",
       "                      0.9991, 0.9885, 0.9970, 0.9992, 0.9979, 1.0018, 0.9942, 0.9990, 0.9987,\n",
       "                      0.9988, 0.9985, 0.9977, 0.9916, 0.9955, 0.9978, 1.0108, 0.9968, 0.9884,\n",
       "                      1.0048, 0.9950, 0.9918, 1.0010, 1.0008, 1.0022, 0.9990, 0.9983, 0.9974,\n",
       "                      0.9986, 0.9995, 0.9981, 1.0062, 0.9989, 0.9909, 1.0001, 0.9961, 0.9932,\n",
       "                      0.9991, 1.0012], device='cuda:0')),\n",
       "             ('blocks.1.update.actu.beta',\n",
       "              tensor([1.7098, 1.7010, 1.6951, 1.7030, 1.7304, 1.6688, 1.7084, 1.7095, 1.7031,\n",
       "                      1.7054, 1.7172, 1.7111, 1.6560, 1.7049, 1.7184, 1.7313, 1.6968, 1.7144,\n",
       "                      1.6719, 1.7324, 1.7035, 1.7046, 1.7081, 1.6954, 1.7125, 1.7047, 1.7020,\n",
       "                      1.6952, 1.7074, 1.7028, 1.7048, 1.7153, 1.7013, 1.7168, 1.6738, 1.7127,\n",
       "                      1.7079, 1.6830, 1.6997, 1.7215, 1.6876, 1.6991, 1.7031, 1.7221, 1.7018,\n",
       "                      1.6582, 1.7349, 1.6980, 1.6945, 1.6983, 1.7195, 1.6855, 1.6832, 1.7131,\n",
       "                      1.7266, 1.6825, 1.7088, 1.6744, 1.6741, 1.7150, 1.7281, 1.7090, 1.6704,\n",
       "                      1.7561, 1.7247, 1.7015, 1.7293, 1.7045, 1.7248, 1.7290, 1.7013, 1.6824,\n",
       "                      1.7080, 1.7190, 1.7120, 1.7092, 1.7173, 1.7012, 1.7093, 1.6878, 1.7099,\n",
       "                      1.7041, 1.7106, 1.7044, 1.7026, 1.7332, 1.6885, 1.7127, 1.6955, 1.6954,\n",
       "                      1.7063, 1.7017, 1.6953, 1.6697, 1.7136, 1.7132, 1.7020, 1.7052, 1.7061,\n",
       "                      1.7135, 1.6963, 1.7024, 1.7011, 1.7391, 1.6905, 1.7002, 1.6859, 1.7116,\n",
       "                      1.7056, 1.7174, 1.7326, 1.6760, 1.7082, 1.7002, 1.6954, 1.7118, 1.6992,\n",
       "                      1.6975, 1.6951, 1.6765, 1.6994, 1.7309, 1.7074, 1.6995, 1.7309, 1.7017,\n",
       "                      1.6989, 1.7177], device='cuda:0')),\n",
       "             ('blocks.1.update.outt.weight',\n",
       "              tensor([ 0.4131, -0.3629, -0.4060,  ..., -0.9436, -0.5092, -1.3094],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.update.outt.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.1.update.outt.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.1.update.outs.weight',\n",
       "              tensor([[-0.1476,  0.1185, -0.0052,  ..., -0.0249, -0.0964, -0.0748],\n",
       "                      [ 0.1134,  0.1395,  0.0629,  ...,  0.0732, -0.0534, -0.0180],\n",
       "                      [-0.0176, -0.1484,  0.0656,  ..., -0.1001,  0.0883,  0.1467],\n",
       "                      ...,\n",
       "                      [-0.1112, -0.0475,  0.0513,  ...,  0.0590, -0.1012,  0.0565],\n",
       "                      [ 0.1056, -0.0513,  0.0589,  ...,  0.0387, -0.0210,  0.0597],\n",
       "                      [-0.0022,  0.0802, -0.0537,  ...,  0.0729, -0.0589,  0.0103]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.update.outs.bias',\n",
       "              tensor([ 5.5184e-05,  6.6874e-05, -6.1892e-05, -2.3291e-03, -4.4110e-03,\n",
       "                       2.3066e-03,  4.3085e-05,  3.8722e-03,  8.0454e-04,  9.1115e-04,\n",
       "                      -1.3580e-03,  6.7229e-04, -2.5772e-03, -4.6298e-05,  2.1384e-04,\n",
       "                      -8.3600e-05, -1.3777e-03,  2.4119e-03,  3.5918e-04,  1.3351e-03,\n",
       "                       1.6195e-03, -2.6968e-03,  8.1343e-04, -1.6186e-03, -1.0887e-03,\n",
       "                      -6.0386e-04,  1.8571e-03, -1.1058e-03,  6.0721e-04,  4.2892e-04,\n",
       "                       7.5241e-04, -1.7066e-03,  3.5978e-03,  1.2812e-03, -1.5105e-03,\n",
       "                       7.7185e-04, -1.0703e-03,  1.1835e-03, -3.9147e-04, -1.3634e-04,\n",
       "                      -2.4825e-04,  1.6645e-03,  2.0979e-03,  1.0994e-03,  8.7308e-04,\n",
       "                       7.4349e-04,  1.9486e-03, -1.2414e-03, -1.7447e-03, -7.6759e-04,\n",
       "                      -3.3150e-03, -7.6395e-05, -6.4549e-03,  1.8465e-03,  1.9903e-03,\n",
       "                      -3.7702e-03,  1.2893e-04, -9.1401e-04, -1.7339e-03, -5.8272e-04,\n",
       "                       2.4788e-03,  1.7131e-04, -8.3491e-03, -6.5983e-03,  4.1912e-04,\n",
       "                      -3.2068e-04,  1.7638e-03, -4.3977e-04,  1.1606e-03,  7.9234e-04,\n",
       "                      -1.3738e-03,  1.2945e-03, -1.3833e-03, -3.7419e-04, -2.7566e-03,\n",
       "                       7.4654e-04, -4.8065e-03, -2.2539e-03,  2.4991e-03,  2.9742e-03,\n",
       "                      -1.9175e-03, -1.4646e-03,  3.7598e-03,  2.1733e-03,  1.0238e-03,\n",
       "                      -2.9944e-04, -1.3627e-03,  6.8937e-04,  3.5504e-03, -1.3070e-03,\n",
       "                       1.5461e-03,  1.4745e-03, -7.0095e-04,  5.9659e-04,  6.7264e-04,\n",
       "                       2.0047e-03, -3.0655e-03, -3.3460e-04,  4.7025e-04,  6.6859e-04,\n",
       "                       2.2901e-04,  1.8076e-04,  1.8493e-03,  9.7315e-04, -1.2278e-03,\n",
       "                       1.6819e-03,  5.1845e-04, -2.9134e-03, -5.2340e-03,  9.0610e-04,\n",
       "                       2.0927e-04,  6.7556e-04, -2.5347e-03,  1.7019e-03,  1.6311e-03,\n",
       "                       7.6412e-04, -1.6385e-03,  8.3909e-05, -2.4682e-04, -1.0099e-03,\n",
       "                       1.4989e-03,  1.0941e-03,  7.7384e-03, -2.5612e-03,  1.7023e-03,\n",
       "                      -2.0351e-04, -1.4177e-03, -4.3477e-04], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lq.weight',\n",
       "              tensor([ 0.9817,  0.5519, -0.2814,  ...,  0.1933,  0.3756, -0.7318],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lq.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lq.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lk.weight',\n",
       "              tensor([-0.6311, -0.9415,  0.5451,  ..., -0.0640,  1.4337, -0.0512],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lk.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lk.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lv.weight',\n",
       "              tensor([-0.1374,  0.5636, -0.0211,  ..., -1.2313, -1.4360,  0.1360],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lv.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lv.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.ls.weight',\n",
       "              tensor([[-0.0991, -0.0462, -0.0887,  ..., -0.1110,  0.0436, -0.0289],\n",
       "                      [ 0.0737, -0.1792,  0.0637,  ..., -0.1025, -0.0336, -0.0683],\n",
       "                      [-0.0192, -0.1176,  0.0599,  ...,  0.0090,  0.0283,  0.0039],\n",
       "                      ...,\n",
       "                      [ 0.0351,  0.0231,  0.0964,  ...,  0.0633,  0.0559, -0.0521],\n",
       "                      [-0.0265,  0.1088,  0.1458,  ...,  0.0411,  0.0472, -0.0141],\n",
       "                      [-0.1018,  0.0441,  0.0457,  ...,  0.1111,  0.0406, -0.1146]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.ls.bias',\n",
       "              tensor([ 8.7522e-04, -7.3092e-04, -2.5166e-03, -1.2459e-02, -1.5895e-03,\n",
       "                       5.2009e-04, -4.1796e-04, -9.1073e-04,  2.1363e-03, -2.2525e-03,\n",
       "                       7.4995e-04,  1.5961e-03, -1.1853e-03,  1.1407e-03,  3.6640e-04,\n",
       "                      -2.2562e-03, -1.4049e-03, -3.1083e-03, -2.6384e-03, -5.0579e-04,\n",
       "                      -2.6240e-03,  2.5455e-04, -9.6644e-05, -2.9297e-03, -7.3871e-04,\n",
       "                      -1.4729e-03, -2.1729e-03, -1.4255e-03, -1.2958e-03,  3.0529e-04,\n",
       "                      -1.4505e-03, -6.0754e-03, -3.7206e-03,  6.3942e-04,  4.5514e-03,\n",
       "                       7.3058e-04, -2.3998e-03,  1.8505e-03, -4.5430e-03, -1.1697e-02,\n",
       "                      -8.6438e-03,  1.8026e-04, -1.3170e-03, -6.7690e-03,  1.1265e-02,\n",
       "                      -1.2454e-03,  7.0317e-03, -6.7451e-04, -4.3948e-03, -4.9747e-03,\n",
       "                       1.1815e-04, -3.0098e-03,  4.2132e-04,  1.1250e-03, -3.4397e-03,\n",
       "                      -5.2095e-03,  1.0228e-03, -2.0989e-03, -4.5687e-04, -1.3823e-03,\n",
       "                       1.4631e-02,  3.3090e-03, -1.9567e-03, -4.0645e-03, -1.9770e-03,\n",
       "                       2.7770e-04,  6.1322e-04, -7.0050e-04, -1.9409e-03, -4.7768e-03,\n",
       "                      -9.2673e-03, -6.8929e-04, -1.5876e-03, -7.3835e-03,  1.8110e-04,\n",
       "                      -1.7929e-03, -6.8018e-05, -9.2600e-04, -1.7730e-03,  5.5442e-03,\n",
       "                      -2.3353e-03,  2.1934e-03, -4.8758e-03,  1.9908e-03,  2.2447e-04,\n",
       "                       2.4188e-04,  1.0072e-03, -3.1815e-03,  1.9610e-03,  5.9738e-04,\n",
       "                       1.0191e-03, -6.0424e-03, -3.2806e-03, -2.0038e-03,  1.9170e-03,\n",
       "                      -7.1507e-03, -1.3344e-03,  6.5050e-04, -4.0266e-03, -2.9285e-03,\n",
       "                      -7.9456e-04, -2.3375e-03, -4.8530e-03,  1.6362e-03, -1.9298e-03,\n",
       "                      -6.9249e-03, -6.4319e-04,  1.4722e-03, -1.2434e-03, -4.0761e-04,\n",
       "                       1.3493e-03,  1.6346e-03, -2.6884e-03, -3.5776e-03,  4.8543e-03,\n",
       "                      -1.2501e-04,  1.3279e-03, -1.8520e-03,  1.0857e-03,  7.3859e-04,\n",
       "                       8.6660e-04,  3.3096e-04, -1.2701e-02, -3.9553e-03, -1.8641e-03,\n",
       "                      -8.6318e-04, -8.4195e-03, -4.8499e-03, -1.0613e-02, -5.3024e-03,\n",
       "                      -8.3172e-03, -3.2074e-03, -5.5070e-03, -1.0328e-02, -9.6033e-03,\n",
       "                       4.8414e-03, -9.7809e-03, -1.1851e-02, -1.8799e-03, -2.1312e-03,\n",
       "                      -7.7104e-03, -9.3658e-03, -5.2245e-03, -7.9346e-04, -6.6484e-03,\n",
       "                      -7.1026e-03, -2.5264e-03, -5.8894e-03, -4.6447e-03, -1.5123e-03,\n",
       "                      -7.7923e-03, -2.2807e-03, -6.0908e-03, -6.5687e-03, -9.6285e-03,\n",
       "                      -8.4754e-03, -8.0596e-03, -1.1420e-02, -6.6549e-03, -4.1627e-03,\n",
       "                      -3.8732e-03, -7.7349e-03, -6.1096e-03, -1.0478e-02, -1.1331e-02,\n",
       "                      -1.1867e-03, -1.9663e-03, -4.4830e-03, -3.1195e-03, -6.7819e-03,\n",
       "                      -4.2411e-03, -9.7357e-03, -1.2111e-02, -1.0371e-02, -2.3161e-03,\n",
       "                      -1.0398e-02, -7.5177e-03, -7.7655e-03, -6.9095e-03, -6.7404e-03,\n",
       "                      -7.8452e-03, -4.0683e-03, -5.2733e-03, -7.9673e-03, -1.1373e-02,\n",
       "                      -1.0759e-02, -7.7180e-03, -8.3663e-03, -4.8586e-03, -1.1807e-02,\n",
       "                      -2.3235e-03, -4.9448e-03, -4.5072e-04, -1.7528e-03, -9.4496e-03,\n",
       "                      -9.4060e-03, -1.8643e-03, -5.4825e-03, -6.3440e-03, -5.3831e-03,\n",
       "                      -3.6496e-03, -1.0691e-02, -7.1141e-03, -1.2404e-02, -5.8586e-03,\n",
       "                      -9.5544e-03, -6.6485e-03, -1.0220e-02, -4.7753e-03, -9.8949e-03,\n",
       "                      -8.1882e-03, -1.1913e-02, -2.2429e-03, -1.4209e-02, -7.7034e-03,\n",
       "                      -9.3767e-03, -1.0331e-02, -1.5571e-03, -6.7782e-03, -1.2119e-02,\n",
       "                      -4.1622e-03, -7.2555e-03, -1.8783e-03, -8.3056e-03, -7.9854e-03,\n",
       "                      -5.1371e-03, -9.3467e-03, -2.8841e-03, -1.1010e-02, -1.0573e-03,\n",
       "                      -1.0235e-02, -8.2600e-03, -4.4687e-03, -9.0574e-03, -9.3913e-03,\n",
       "                      -2.0059e-02, -1.2574e-02, -1.1443e-02, -1.0468e-02, -6.3082e-03,\n",
       "                      -6.7167e-03,  3.9579e-03, -8.3987e-03, -7.2678e-03, -9.1660e-03,\n",
       "                      -9.7468e-03, -2.8157e-03, -5.9956e-03, -9.8145e-03, -1.1436e-02,\n",
       "                      -1.0391e-02, -3.7817e-03, -5.3844e-03, -8.9464e-03, -3.2718e-03,\n",
       "                      -9.5830e-03], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lvs.weight',\n",
       "              tensor([[ 0.0273, -0.1454, -0.0205,  ..., -0.0225, -0.1160, -0.0930],\n",
       "                      [ 0.1237, -0.1503, -0.0033,  ..., -0.0198, -0.0089, -0.0579],\n",
       "                      [ 0.1250,  0.0309,  0.0902,  ..., -0.0753, -0.0979,  0.0926],\n",
       "                      ...,\n",
       "                      [ 0.1028, -0.0549,  0.0649,  ...,  0.1399, -0.1073,  0.0126],\n",
       "                      [ 0.0281, -0.0658, -0.0649,  ..., -0.1290, -0.0968, -0.0853],\n",
       "                      [-0.1474, -0.0993,  0.0405,  ...,  0.1323, -0.1392, -0.0037]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.lvs.bias',\n",
       "              tensor([-2.2662e-03,  9.8894e-05, -3.0570e-03, -5.7880e-03, -1.6238e-03,\n",
       "                       4.2776e-03, -1.5976e-03,  9.4353e-04,  3.4689e-03, -3.3122e-03,\n",
       "                       1.8893e-03,  2.4396e-03, -3.9873e-03,  6.8198e-04,  5.5491e-04,\n",
       "                       1.2679e-03, -1.0574e-03,  8.8771e-04, -7.9030e-04,  4.0991e-03,\n",
       "                      -1.5924e-03, -2.1359e-03,  2.4602e-03, -2.5958e-03, -1.0431e-03,\n",
       "                      -6.6586e-05,  2.8037e-03, -9.3180e-04, -7.0693e-04,  2.2488e-03,\n",
       "                      -1.5840e-03, -2.4889e-03, -1.1506e-03,  2.0395e-03,  9.1322e-04,\n",
       "                      -2.9677e-03, -1.3003e-03,  2.0092e-03,  1.5366e-03, -9.7476e-04,\n",
       "                      -2.0044e-03,  1.1228e-03,  3.1470e-03, -2.3687e-03,  4.2010e-03,\n",
       "                       6.9720e-05,  5.1329e-03, -2.2898e-03, -2.4417e-03, -1.4783e-03,\n",
       "                      -1.4400e-03, -2.0051e-03, -4.5245e-04,  1.2147e-03,  3.5265e-04,\n",
       "                      -1.5224e-03, -9.3284e-04, -8.8482e-04, -4.5890e-03, -7.0115e-04,\n",
       "                       2.9515e-03,  6.5820e-04, -1.8694e-03, -3.5749e-03, -1.7664e-03,\n",
       "                       3.0266e-04,  2.5909e-03, -8.1254e-04, -2.0634e-03, -3.4877e-05,\n",
       "                      -1.5818e-03,  4.6750e-04, -1.8915e-03, -1.2219e-03, -4.3123e-04,\n",
       "                      -5.3777e-03, -3.6158e-04, -1.6055e-03,  6.2339e-03,  7.7561e-03,\n",
       "                      -1.2340e-03,  4.0814e-04,  3.7508e-04,  4.2173e-03,  1.3749e-03,\n",
       "                       2.9564e-03,  5.0050e-04,  1.1663e-04,  2.0849e-03, -9.8798e-04,\n",
       "                       2.8523e-03, -6.0159e-04, -8.3398e-04, -3.4045e-03,  2.6055e-03,\n",
       "                      -9.1380e-05, -1.2251e-03, -2.9114e-03,  9.6407e-05, -3.0845e-05,\n",
       "                       3.3799e-04,  2.3271e-04,  1.6428e-03,  2.6725e-03, -7.3289e-04,\n",
       "                      -3.5419e-03,  1.4375e-03,  4.7171e-03, -3.0621e-03,  7.0977e-04,\n",
       "                       5.2502e-04,  1.4913e-03, -1.7988e-03,  3.5440e-04,  7.7138e-03,\n",
       "                       2.0368e-03,  3.1944e-04,  1.6874e-03,  7.4597e-04, -2.2500e-03,\n",
       "                       2.3560e-03,  1.4465e-03, -2.6694e-03, -2.3254e-03, -6.5880e-04,\n",
       "                      -1.1154e-04, -1.5247e-03, -2.8392e-03], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.tp1.weight', tensor([], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.tp1.output_mask',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.tp2.weight',\n",
       "              tensor([-0.0353,  0.9089, -0.9703,  0.6438,  0.0994,  0.8075,  1.5362, -1.0480,\n",
       "                      -1.2645,  0.6921, -2.2464,  0.7533,  1.3236,  1.7320, -0.1765, -0.9762,\n",
       "                       0.0930,  2.1170, -0.0858,  0.2606,  0.0228,  1.8195,  2.6791,  0.5937,\n",
       "                      -1.4654,  0.5277, -0.2276,  2.4157,  0.2230,  0.6963,  0.5943, -0.3407,\n",
       "                      -0.9829,  1.8493,  1.0538,  0.2612, -0.2657, -0.2609,  0.4572,  0.0862,\n",
       "                       0.0952,  0.2858, -0.5023,  0.7015,  0.3920, -0.8549,  0.9129,  0.1213,\n",
       "                      -0.3239, -0.8532, -0.7141, -1.0936,  0.8254,  0.8455,  1.2275,  1.0699,\n",
       "                      -1.2803, -0.6196,  0.7243, -2.3332, -1.2783, -1.3062,  0.9647,  0.2605,\n",
       "                       4.0036, -1.0111,  0.9304, -0.2114, -0.7802, -1.1280, -0.8951, -1.0302,\n",
       "                       1.0828,  0.4446, -0.9530,  0.0259,  0.3044, -0.7754, -0.1476, -1.0646,\n",
       "                      -0.8054, -1.1866, -0.5064,  1.5681,  1.4865,  0.6368,  0.0729, -1.3459,\n",
       "                       1.6425, -2.6145,  2.4529, -0.2647,  0.2640, -1.7532,  1.0429, -1.0535,\n",
       "                       1.2641,  1.3854, -1.3868, -0.3657,  2.2871,  0.4612, -0.9023,  2.2100,\n",
       "                      -0.9742,  0.2445,  0.1674,  3.0145, -1.5738,  1.0687, -1.8318, -0.2676,\n",
       "                      -0.4498,  0.2372,  0.4183, -0.3329, -0.1004, -1.9170, -0.8317,  1.0166,\n",
       "                       0.3259, -0.7755,  0.5429, -0.1401,  0.9176, -2.2160, -2.0176, -0.8254,\n",
       "                       1.0299,  0.4266, -0.8295,  0.0950, -0.6167, -1.7392, -1.5126, -1.9378,\n",
       "                      -1.4389,  0.6594,  1.0497, -0.5701,  0.1671, -1.0154,  1.6147, -0.0121,\n",
       "                      -0.6456,  1.9823,  1.1723,  0.9515, -0.9724, -0.3213, -0.4453, -0.9026,\n",
       "                      -0.3125,  0.0944,  0.6192, -0.5531,  0.6448, -0.5120,  0.9688,  1.8763,\n",
       "                      -2.2181, -1.8073, -1.2794, -0.3432,  0.7081,  2.6521,  0.1064, -1.3802,\n",
       "                       0.4935, -0.6053,  1.7939, -0.1988, -0.0659,  0.3333, -1.2109,  1.6092,\n",
       "                      -1.5021,  0.7070,  0.6452, -0.9032,  0.2430,  0.1636,  2.2915,  0.6133,\n",
       "                      -0.0466,  0.7596, -1.0080,  0.4874,  1.1861,  0.1229,  0.4767,  0.5313,\n",
       "                       0.7114,  0.5258,  0.4448, -0.1576, -2.4292, -0.2589,  0.8269, -1.6471,\n",
       "                      -0.1354, -0.6062, -0.7899,  0.4265, -0.1999, -0.5886, -1.2004,  0.4360,\n",
       "                      -0.9077,  0.5958,  0.3764, -0.0590,  1.1521,  0.0821, -0.4648, -1.8456,\n",
       "                       0.2470,  0.1055,  1.0781,  0.1664,  0.1591, -0.4581, -0.0705, -0.3380,\n",
       "                       1.1689, -1.2398, -0.5110,  1.1730,  2.0760, -0.0122, -0.1871,  1.3866,\n",
       "                       0.2231, -0.3651, -0.7214,  1.9080,  0.4723,  0.6332, -0.1031,  0.5888,\n",
       "                       2.4228,  0.4945,  0.8378,  0.7467, -0.1034,  0.2718, -0.0072, -0.0762,\n",
       "                       0.2750,  0.4533,  1.5720, -0.8955,  2.0072, -0.9718,  0.0100,  1.1785,\n",
       "                      -0.4830,  1.0339, -1.4878,  0.2385,  0.4048,  0.2538, -1.1288,  0.8612,\n",
       "                       0.2978,  0.0989, -0.7592, -0.2420, -0.2588,  1.1413, -0.0313, -1.5245,\n",
       "                       0.0753, -1.4140,  1.1569,  0.1747, -1.1093, -1.0907,  0.3275, -0.4600,\n",
       "                       0.4724,  0.8433, -0.3280,  0.1678,  0.6560, -0.1135,  1.0094, -1.0108,\n",
       "                      -0.3394, -0.4998, -1.5860,  1.6342, -2.1002,  0.2339,  0.1820,  0.2663,\n",
       "                      -0.1035, -1.1377,  0.5108, -0.2060, -1.0048, -2.0708, -0.0531,  0.5094,\n",
       "                      -2.2155,  0.7514, -1.1909,  0.1220, -0.4974,  0.0618,  1.2619,  1.7717,\n",
       "                      -1.0708, -1.3480, -0.8098,  0.4867,  1.1054,  1.3697, -2.0137, -0.6859,\n",
       "                      -0.9593,  1.1912,  0.4551, -1.4466,  0.7316,  0.3991, -1.6482,  1.1337,\n",
       "                       0.2087, -0.8877,  1.2729, -1.3916,  0.0106, -0.1399,  1.0849, -1.1705,\n",
       "                       0.4105,  0.1834, -0.3378,  0.1628,  1.9802,  0.3620,  0.6968, -0.3233,\n",
       "                      -1.4971,  1.7440,  0.6765, -2.4980,  0.4823,  0.7618, -0.4631, -0.2040,\n",
       "                       1.8050, -0.0048, -1.6127,  0.0642,  0.0893,  0.1149, -0.4226, -1.4414,\n",
       "                      -2.1503,  0.5234, -0.0817, -1.9779, -1.6060, -1.0990,  1.1765, -1.2106,\n",
       "                       0.5919, -0.1346, -0.8068,  1.2408, -0.2500, -1.8272,  0.0659, -0.6327,\n",
       "                      -2.1204,  0.7292, -2.2037,  1.2897, -1.3910,  1.7251,  0.2769,  1.2751],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.tp2.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.actlvs.alpha',\n",
       "              tensor([1.0019, 1.0003, 0.9976, 0.9937, 0.9985, 1.0020, 1.0004, 0.9996, 1.0025,\n",
       "                      0.9981, 1.0008, 1.0015, 1.0028, 1.0011, 1.0015, 0.9984, 0.9993, 0.9984,\n",
       "                      0.9989, 1.0018, 0.9982, 1.0014, 1.0001, 0.9991, 0.9989, 0.9997, 0.9995,\n",
       "                      0.9988, 0.9983, 1.0011, 0.9996, 0.9998, 0.9970, 1.0022, 1.0045, 0.9993,\n",
       "                      0.9982, 1.0024, 0.9995, 0.9931, 0.9946, 1.0003, 1.0022, 0.9945, 1.0094,\n",
       "                      0.9991, 1.0071, 1.0004, 0.9961, 0.9977, 1.0029, 0.9993, 1.0003, 1.0018,\n",
       "                      0.9977, 1.0018, 1.0001, 0.9988, 1.0013, 0.9977, 1.0122, 1.0001, 1.0006,\n",
       "                      0.9983, 0.9986, 1.0005, 1.0015, 1.0001, 1.0000, 0.9995, 0.9942, 0.9999,\n",
       "                      0.9963, 0.9943, 1.0001, 0.9990, 1.0006, 1.0002, 1.0002, 1.0082, 0.9982,\n",
       "                      1.0032, 0.9984, 1.0022, 1.0004, 1.0033, 1.0005, 0.9985, 1.0017, 1.0014,\n",
       "                      1.0022, 0.9962, 0.9995, 0.9985, 1.0021, 0.9961, 1.0000, 1.0030, 0.9986,\n",
       "                      0.9976, 0.9994, 0.9983, 0.9995, 1.0018, 0.9985, 0.9962, 1.0008, 1.0015,\n",
       "                      0.9991, 1.0001, 1.0014, 1.0021, 0.9980, 0.9988, 1.0067, 1.0012, 1.0016,\n",
       "                      0.9996, 1.0025, 1.0011, 1.0012, 1.0008, 0.9929, 0.9973, 0.9985, 1.0004,\n",
       "                      0.9947, 0.9958], device='cuda:0')),\n",
       "             ('blocks.1.update.uattn.actlvs.beta',\n",
       "              tensor([1.7014, 1.7025, 1.6983, 1.7027, 1.7007, 1.7032, 1.7031, 1.7031, 1.7044,\n",
       "                      1.7036, 1.7027, 1.7035, 1.7010, 1.7033, 1.7036, 1.7019, 1.7021, 1.7041,\n",
       "                      1.7055, 1.7065, 1.7016, 1.7036, 1.7032, 1.7029, 1.7005, 1.7022, 1.6997,\n",
       "                      1.7008, 1.7023, 1.7029, 1.7027, 1.7023, 1.7036, 1.7051, 1.7002, 1.7032,\n",
       "                      1.7004, 1.7037, 1.7044, 1.7039, 1.7024, 1.7021, 1.7044, 1.7046, 1.7115,\n",
       "                      1.6982, 1.7090, 1.7019, 1.6982, 1.7039, 1.7004, 1.7018, 1.7014, 1.7038,\n",
       "                      1.7035, 1.7024, 1.7049, 1.7012, 1.7014, 1.7067, 1.6879, 1.7046, 1.7028,\n",
       "                      1.7025, 1.7013, 1.7021, 1.7030, 1.6974, 1.7024, 1.7015, 1.6973, 1.7018,\n",
       "                      1.7013, 1.7055, 1.7006, 1.7030, 1.7008, 1.7037, 1.7004, 1.7094, 1.7016,\n",
       "                      1.6997, 1.7033, 1.7045, 1.7027, 1.7051, 1.6997, 1.7024, 1.7042, 1.7002,\n",
       "                      1.7043, 1.7123, 1.7005, 1.7030, 1.7020, 1.7094, 1.6996, 1.6989, 1.6989,\n",
       "                      1.7006, 1.7008, 1.7009, 1.7146, 1.7049, 1.7004, 1.7056, 1.7011, 1.7046,\n",
       "                      1.6985, 1.7021, 1.7037, 1.7042, 1.6979, 1.7039, 1.7088, 1.7030, 1.7096,\n",
       "                      1.7008, 1.6999, 1.7004, 1.7030, 1.7023, 1.7080, 1.7038, 1.7017, 1.7002,\n",
       "                      1.7077, 1.6973], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.actq.alpha',\n",
       "              tensor([1.0137, 1.0649, 1.0433, 1.0140, 1.0597, 1.1246, 1.0657, 0.9980, 1.0688,\n",
       "                      1.0519, 1.1049, 1.0283, 1.0377, 1.1292, 1.0606, 1.0326, 1.1116, 1.0354,\n",
       "                      1.0357, 0.9924, 1.0505, 1.0909, 1.0876, 1.0164, 1.0756, 1.0780, 1.1073,\n",
       "                      1.0207, 1.0482, 1.0895, 1.0518, 1.0215, 1.0349, 1.0366, 1.0075, 1.0090,\n",
       "                      1.0641, 1.0798, 1.0182, 1.0291, 1.0664, 1.0220, 1.0722, 1.0470, 1.0568,\n",
       "                      0.9915, 0.9936, 1.0685, 1.0114, 1.0234, 1.0326, 1.0268, 1.0360, 1.0602,\n",
       "                      1.0392, 1.0467, 1.0582, 1.0285, 0.9966, 1.0530, 1.0459, 1.0429, 1.0661,\n",
       "                      1.0503, 1.0042, 1.0468, 0.9891, 1.0423, 1.0799, 1.0433, 1.0205, 1.0252,\n",
       "                      1.1017, 1.0584, 1.1304, 1.0342, 0.9797, 1.1284, 1.1048, 1.0230, 1.0057,\n",
       "                      1.0710, 1.0280, 0.9977, 1.0157, 1.0562, 1.0205, 1.0194, 0.9951, 0.9888,\n",
       "                      1.0337, 1.0509, 1.0001, 1.0417, 1.0029, 1.0512, 1.0429, 0.9957, 1.0782,\n",
       "                      0.9921, 1.0360, 1.1014, 1.0364, 1.0721, 1.0545, 1.0371, 1.1033, 1.0294,\n",
       "                      1.0150, 1.0566, 1.0817, 1.0419, 0.9995, 1.0479, 1.0098, 0.9882, 1.0369,\n",
       "                      1.0472, 1.0287, 1.0364, 1.0538, 1.0191, 1.0180, 0.9773, 1.0513, 1.0681,\n",
       "                      1.0558, 1.0225], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.actq.beta',\n",
       "              tensor([1.7204, 1.7047, 1.6945, 1.7115, 1.7516, 1.7628, 1.7219, 1.7004, 1.7290,\n",
       "                      1.7355, 1.7547, 1.7265, 1.7107, 1.7911, 1.7532, 1.7000, 1.7817, 1.7379,\n",
       "                      1.7008, 1.6919, 1.7595, 1.7773, 1.7092, 1.7019, 1.7013, 1.6922, 1.7837,\n",
       "                      1.6802, 1.7160, 1.7622, 1.7560, 1.7136, 1.7163, 1.6898, 1.6990, 1.6796,\n",
       "                      1.7568, 1.7255, 1.7289, 1.6801, 1.7469, 1.7127, 1.7593, 1.7413, 1.7147,\n",
       "                      1.7069, 1.7578, 1.7348, 1.7068, 1.7222, 1.7167, 1.7240, 1.7116, 1.7289,\n",
       "                      1.7067, 1.7481, 1.7396, 1.7287, 1.7054, 1.7506, 1.7210, 1.7143, 1.7525,\n",
       "                      1.7301, 1.7031, 1.7371, 1.6975, 1.7370, 1.7738, 1.7640, 1.7001, 1.7094,\n",
       "                      1.7015, 1.7335, 1.7612, 1.6834, 1.7460, 1.7836, 1.7168, 1.6890, 1.7031,\n",
       "                      1.7120, 1.7144, 1.6998, 1.7029, 1.7278, 1.7142, 1.7274, 1.7225, 1.7132,\n",
       "                      1.7117, 1.7259, 1.7159, 1.7036, 1.6932, 1.7340, 1.7194, 1.7025, 1.7073,\n",
       "                      1.7064, 1.7597, 1.7739, 1.7124, 1.7504, 1.7574, 1.7332, 1.7274, 1.7014,\n",
       "                      1.6786, 1.7482, 1.7578, 1.7349, 1.7070, 1.7038, 1.7160, 1.7077, 1.7048,\n",
       "                      1.7297, 1.7204, 1.7398, 1.7420, 1.7284, 1.7174, 1.7363, 1.7086, 1.7286,\n",
       "                      1.7533, 1.7446], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.actk.alpha',\n",
       "              tensor([1.0420, 1.0259, 1.0532, 0.9976, 1.0879, 1.0147, 1.0156, 0.9941, 1.0741,\n",
       "                      1.0072, 1.1147, 1.0418, 1.0336, 1.0523, 1.0010, 1.0322, 0.9927, 1.0439,\n",
       "                      1.0147, 0.9902, 1.0165, 0.9896, 1.0970, 1.0340, 1.0687, 1.0089, 1.1077,\n",
       "                      1.0406, 1.0385, 1.1952, 1.0492, 0.9897, 1.0358, 1.0294, 0.9977, 1.0134,\n",
       "                      1.0002, 1.1075, 1.0285, 1.0327, 1.0625, 1.0482, 1.0884, 1.0056, 1.1055,\n",
       "                      0.9877, 1.0525, 1.0532, 1.0154, 1.0709, 1.0035, 1.0099, 1.0978, 1.0293,\n",
       "                      1.0330, 1.0580, 1.0712, 1.0796, 1.0927, 1.0718, 1.1593, 1.1456, 1.0924,\n",
       "                      1.0204, 1.0240, 1.0443, 0.9993, 0.9995, 1.0049, 0.9986, 1.0221, 1.0021,\n",
       "                      1.1063, 1.0393, 1.0301, 1.0183, 1.0439, 1.0340, 1.0266, 1.0050, 1.0181,\n",
       "                      1.0586, 0.9978, 1.0054, 1.0616, 1.0885, 1.0626, 1.1171, 1.0738, 1.0439,\n",
       "                      1.1057, 0.9970, 1.0517, 1.1037, 1.0448, 1.0607, 0.9881, 1.0374, 1.0025,\n",
       "                      1.0461, 1.0110, 1.0511, 1.0625, 1.0382, 1.0503, 1.0077, 1.0453, 0.9998,\n",
       "                      1.0316, 1.0402, 1.0029, 1.0913, 0.9941, 1.0522, 1.0152, 1.0256, 1.0575,\n",
       "                      1.0625, 1.0567, 1.0391, 1.0715, 1.0396, 1.0932, 1.0518, 1.0252, 1.0725,\n",
       "                      1.0489, 1.0280], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.actk.beta',\n",
       "              tensor([1.6808, 1.7304, 1.7460, 1.7032, 1.7478, 1.6935, 1.6816, 1.6976, 1.7701,\n",
       "                      1.7092, 1.7594, 1.7266, 1.7137, 1.7479, 1.6965, 1.7261, 1.7135, 1.7382,\n",
       "                      1.7226, 1.7034, 1.6757, 1.7055, 1.7554, 1.7314, 1.7503, 1.6947, 1.6592,\n",
       "                      1.7346, 1.7380, 1.7065, 1.7478, 1.7094, 1.7019, 1.6620, 1.7012, 1.6940,\n",
       "                      1.7030, 1.7553, 1.7014, 1.7256, 1.7727, 1.7388, 1.6133, 1.7088, 1.6895,\n",
       "                      1.6818, 1.7592, 1.7374, 1.7154, 1.7700, 1.6994, 1.7105, 1.7294, 1.7267,\n",
       "                      1.6921, 1.6590, 1.7549, 1.7672, 1.7770, 1.7496, 1.7650, 1.7933, 1.7691,\n",
       "                      1.7225, 1.7173, 1.7401, 1.6982, 1.7015, 1.6871, 1.6931, 1.7229, 1.7075,\n",
       "                      1.7022, 1.7353, 1.6637, 1.7195, 1.6397, 1.7193, 1.7180, 1.7012, 1.7177,\n",
       "                      1.7484, 1.6948, 1.6890, 1.7568, 1.7283, 1.6371, 1.7956, 1.6153, 1.7433,\n",
       "                      1.6506, 1.6958, 1.6574, 1.7402, 1.6678, 1.7460, 1.7092, 1.7224, 1.6872,\n",
       "                      1.7314, 1.6795, 1.7280, 1.6933, 1.6756, 1.7541, 1.6970, 1.6681, 1.6996,\n",
       "                      1.7245, 1.6740, 1.7067, 1.7551, 1.7034, 1.7519, 1.7156, 1.7251, 1.7696,\n",
       "                      1.7611, 1.6500, 1.6612, 1.6464, 1.6635, 1.6186, 1.7482, 1.6788, 1.7653,\n",
       "                      1.7669, 1.7362], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.actv.alpha',\n",
       "              tensor([1.0670, 1.0042, 0.9994, 1.0019, 1.0095, 1.0003, 1.0035, 0.9989, 1.0011,\n",
       "                      0.9998, 1.0017, 1.0048, 0.9823, 1.0312, 1.0015, 1.0062, 1.0170, 0.9995,\n",
       "                      0.9960, 0.9996, 0.9978, 0.9957, 1.0060, 0.9980, 0.9905, 0.9943, 0.9958,\n",
       "                      1.0089, 0.9918, 0.9955, 1.0102, 0.9880, 0.9977, 1.0107, 0.9998, 1.0110,\n",
       "                      1.0084, 1.0019, 1.0034, 1.0042, 0.9991, 1.0167, 0.9939, 1.0043, 1.0166,\n",
       "                      1.0098, 1.0053, 1.0164, 0.9982, 0.9888, 0.9970, 1.0035, 0.9968, 0.9991,\n",
       "                      1.0033, 0.9991, 1.0065, 0.9999, 0.9974, 1.0044, 1.0309, 1.0002, 1.0060,\n",
       "                      1.0008, 1.0135, 0.9955, 1.0125, 1.0062, 0.9978, 1.0057, 1.0038, 0.9958,\n",
       "                      0.9981, 1.0129, 1.0296, 0.9904, 1.0042, 0.9998, 0.9912, 0.9932, 1.0078,\n",
       "                      1.0101, 1.0049, 0.9952, 1.0108, 0.9981, 0.9998, 0.9939, 1.0118, 0.9983,\n",
       "                      1.0069, 0.9878, 0.9971, 1.0353, 0.9886, 1.0043, 0.9977, 0.9988, 1.0043,\n",
       "                      1.0105, 0.9995, 1.0028, 0.9920, 1.0010, 0.9897, 0.9968, 1.0013, 0.9998,\n",
       "                      0.9793, 1.0008, 0.9841, 1.0018, 0.9885, 1.0038, 0.9944, 0.9919, 1.0044,\n",
       "                      1.0056, 0.9989, 0.9968, 0.9986, 0.9850, 1.0003, 1.0491, 0.9984, 1.0100,\n",
       "                      1.0018, 1.0023, 0.9968, 0.9961, 1.0001, 1.0013, 0.9988, 0.9974, 1.0013,\n",
       "                      0.9994, 1.0005, 0.9982, 0.9984, 0.9989, 0.9991, 1.0268, 1.0065, 0.9992,\n",
       "                      0.9821, 1.0014, 0.9904, 0.9956, 0.9975, 0.9948, 0.9976, 0.9959, 1.0011,\n",
       "                      0.9802, 1.0025, 1.0073, 1.0008, 0.9947, 1.0322, 0.9957, 0.9935, 0.9919,\n",
       "                      1.0023, 0.9972, 1.0021, 0.9939, 0.9982, 0.9981, 1.0007, 0.9959, 1.0037,\n",
       "                      1.0024, 1.0001, 0.9970, 1.0375, 0.9910, 0.9998, 1.0049, 1.0105, 1.0030,\n",
       "                      0.9984, 0.9932, 1.0011, 1.0113, 1.0019, 1.0078, 0.9968, 1.0061, 1.0273,\n",
       "                      1.0048, 1.0029, 1.0021, 0.9960, 1.0049, 1.0016, 1.0007, 1.0008, 0.9996,\n",
       "                      0.9920, 0.9956, 1.0072, 1.0006, 1.0031, 1.0018, 0.9834, 1.0046, 1.0063,\n",
       "                      1.0030, 1.0058, 0.9952, 1.0047, 0.9973, 1.0002, 0.9952, 1.0071, 0.9980,\n",
       "                      0.9948, 0.9963, 0.9967, 0.9895, 1.0008, 0.9938, 0.9957, 1.0071, 1.0023,\n",
       "                      1.0004, 0.9918, 0.9987, 0.9954, 0.9905, 1.0386, 1.0007, 1.0014, 1.0034,\n",
       "                      0.9957, 0.9997, 1.0011, 1.0332, 0.9951, 0.9975, 0.9941, 0.9973, 1.0135,\n",
       "                      1.0082, 0.9996, 0.9962, 1.0128, 1.0172, 0.9964, 1.0089, 1.0039, 0.9967,\n",
       "                      0.9960, 0.9924, 1.0042, 0.9978], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.actv.beta',\n",
       "              tensor([1.7670, 1.7065, 1.7033, 1.7037, 1.6911, 1.7041, 1.7049, 1.7061, 1.7079,\n",
       "                      1.7012, 1.7041, 1.6928, 1.7235, 1.6718, 1.7046, 1.6950, 1.7180, 1.7038,\n",
       "                      1.6847, 1.7011, 1.6973, 1.6959, 1.7084, 1.7011, 1.7005, 1.7072, 1.7064,\n",
       "                      1.6856, 1.6935, 1.6990, 1.7123, 1.7113, 1.6997, 1.6810, 1.7027, 1.6975,\n",
       "                      1.6947, 1.7037, 1.7065, 1.6993, 1.6990, 1.7185, 1.7037, 1.6974, 1.7035,\n",
       "                      1.6941, 1.6954, 1.6842, 1.6977, 1.7076, 1.7000, 1.7031, 1.7010, 1.7004,\n",
       "                      1.7060, 1.7017, 1.7084, 1.7030, 1.7028, 1.7058, 1.7147, 1.6969, 1.6965,\n",
       "                      1.6984, 1.7210, 1.7034, 1.6891, 1.7039, 1.7034, 1.6968, 1.6994, 1.6963,\n",
       "                      1.7038, 1.7150, 1.7258, 1.7073, 1.7046, 1.7019, 1.6959, 1.6952, 1.7101,\n",
       "                      1.7117, 1.6980, 1.7003, 1.7131, 1.7029, 1.7049, 1.6954, 1.6961, 1.7000,\n",
       "                      1.7090, 1.7063, 1.6949, 1.7269, 1.6919, 1.7064, 1.7014, 1.6989, 1.6972,\n",
       "                      1.7190, 1.7067, 1.6970, 1.7121, 1.6949, 1.7086, 1.6968, 1.6957, 1.7029,\n",
       "                      1.7055, 1.7040, 1.7210, 1.7031, 1.7168, 1.7055, 1.7082, 1.6942, 1.7022,\n",
       "                      1.7063, 1.7010, 1.7042, 1.7046, 1.6994, 1.7021, 1.7514, 1.7005, 1.7139,\n",
       "                      1.6948, 1.7025, 1.6995, 1.6920, 1.7022, 1.7153, 1.6970, 1.6969, 1.7043,\n",
       "                      1.7011, 1.7034, 1.6981, 1.7122, 1.7032, 1.7007, 1.7315, 1.6737, 1.7015,\n",
       "                      1.7197, 1.7029, 1.7094, 1.6971, 1.6990, 1.6976, 1.7043, 1.7019, 1.7046,\n",
       "                      1.7216, 1.6835, 1.6961, 1.7007, 1.7100, 1.7450, 1.7056, 1.7008, 1.6996,\n",
       "                      1.7044, 1.7109, 1.7019, 1.7122, 1.7007, 1.6992, 1.7028, 1.6987, 1.6977,\n",
       "                      1.7138, 1.7023, 1.6991, 1.7429, 1.6997, 1.7089, 1.7068, 1.6954, 1.7068,\n",
       "                      1.7008, 1.7105, 1.7021, 1.7128, 1.7032, 1.7095, 1.7025, 1.7129, 1.7278,\n",
       "                      1.7066, 1.7000, 1.7045, 1.7079, 1.7092, 1.7042, 1.6986, 1.7019, 1.7001,\n",
       "                      1.6983, 1.6983, 1.6940, 1.6991, 1.7052, 1.6974, 1.7152, 1.7073, 1.7007,\n",
       "                      1.7020, 1.6974, 1.6967, 1.7055, 1.7009, 1.7011, 1.6968, 1.6958, 1.7017,\n",
       "                      1.7007, 1.6868, 1.6968, 1.6963, 1.7049, 1.6961, 1.6980, 1.6938, 1.6978,\n",
       "                      1.7036, 1.6953, 1.7007, 1.7030, 1.6920, 1.7421, 1.6970, 1.7019, 1.7013,\n",
       "                      1.7084, 1.7018, 1.7110, 1.7342, 1.6985, 1.7035, 1.6843, 1.6961, 1.6900,\n",
       "                      1.6950, 1.7030, 1.6980, 1.7157, 1.6909, 1.7033, 1.7119, 1.7054, 1.6962,\n",
       "                      1.6997, 1.7122, 1.6969, 1.6989], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.acta.alpha',\n",
       "              tensor([1.0516, 1.0650, 1.0347, 1.0494, 1.0333, 1.0307, 1.0264, 1.0592, 1.0194,\n",
       "                      1.0248, 1.0303, 1.0483, 1.0444, 1.0216, 1.0080, 1.1247, 1.0769, 1.0331,\n",
       "                      1.0388, 1.0750, 1.0403, 1.0446, 1.0302, 1.0294, 1.0707, 1.0409, 1.0404,\n",
       "                      1.0485, 1.0281, 1.0206, 1.0523, 1.0327, 1.0453, 1.0280, 1.0789, 1.0767,\n",
       "                      1.0299, 1.0325, 1.0291, 1.0578, 1.0432, 1.0532, 1.0591, 1.0222, 1.0640,\n",
       "                      1.0461, 1.0362, 1.0309, 1.0335, 1.0597, 1.0914, 1.0552, 1.0050, 1.0363,\n",
       "                      1.0542, 1.0379, 1.0203, 1.0288, 1.0311, 1.0119, 1.0472, 1.0819, 1.0758,\n",
       "                      1.0550, 1.0624, 1.0374, 1.0146, 1.0763, 1.0450, 1.0389, 1.0293, 1.0258,\n",
       "                      1.0630, 1.0086, 1.0766, 1.0406, 1.0175, 1.0725, 1.0449, 1.0734, 0.9969,\n",
       "                      1.0895, 1.0486, 1.0751, 1.0393, 1.0285, 1.0680, 1.0231, 1.1201, 1.0467,\n",
       "                      1.0478, 1.0606, 0.9890, 1.0465, 1.0831, 1.0460, 1.0348, 1.0123, 1.0426,\n",
       "                      1.0355, 1.0267, 1.0503, 1.0652, 1.0386, 1.0376, 1.0527, 0.9923, 1.0350,\n",
       "                      1.0510, 1.0308, 0.9972, 1.0707, 1.0870, 1.0106, 1.0970, 1.0554, 1.0478,\n",
       "                      0.9963, 1.1115, 1.0570, 1.0632, 1.0475, 1.0630, 1.0431, 1.0531, 1.0203,\n",
       "                      1.0543, 1.0266, 0.9996, 0.9992, 0.9888, 0.9930, 0.9989, 0.9867, 0.9946,\n",
       "                      0.9887, 0.9957, 0.9967, 0.9917, 0.9976, 0.9896, 0.9859, 0.9978, 0.9854,\n",
       "                      0.9962, 0.9971, 0.9968, 0.9928, 0.9938, 0.9920, 0.9968, 1.0007, 0.9989,\n",
       "                      1.0038, 0.9988, 1.0001, 0.9907, 0.9983, 1.0005, 0.9935, 0.9916, 0.9980,\n",
       "                      0.9993, 1.0001, 0.9973, 0.9931, 1.0005, 1.0026, 0.9868, 0.9955, 0.9997,\n",
       "                      0.9960, 1.0025, 1.0022, 1.0008, 0.9983, 0.9989, 0.9941, 0.9942, 0.9896,\n",
       "                      1.0019, 0.9948, 0.9941, 0.9954, 0.9908, 0.9976, 0.9955, 1.0000, 0.9961,\n",
       "                      0.9960, 0.9990, 1.0003, 0.9963, 0.9909, 0.9998, 1.0010, 1.0012, 0.9944,\n",
       "                      0.9959, 1.0021, 1.0007, 0.9940, 0.9997, 1.0010, 0.9993, 0.9958, 0.9984,\n",
       "                      0.9986, 0.9968, 0.9990, 0.9971, 0.9962, 0.9960, 1.0012, 0.9908, 0.9988,\n",
       "                      1.0050, 0.9921, 0.9971, 0.9953, 0.9908, 0.9981, 0.9847, 0.9921, 0.9972,\n",
       "                      0.9951, 0.9868, 0.9876, 0.9969, 0.9984, 0.9890, 0.9972, 0.9997, 0.9963,\n",
       "                      1.0011, 0.9948, 1.0013, 1.0054, 1.0009, 1.0030, 0.9977, 0.9987, 1.0005,\n",
       "                      0.9910, 0.9955, 0.9935, 0.9955, 0.9952, 0.9919, 1.0015, 0.9978, 0.9961,\n",
       "                      1.0000, 0.9943, 0.9909, 0.9999], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.acta.beta',\n",
       "              tensor([1.6828, 1.6844, 1.7142, 1.7077, 1.7112, 1.7178, 1.6974, 1.6922, 1.7009,\n",
       "                      1.7135, 1.6890, 1.7081, 1.7164, 1.7063, 1.7025, 1.7767, 1.7318, 1.7097,\n",
       "                      1.7135, 1.7269, 1.7249, 1.7143, 1.7014, 1.7051, 1.6703, 1.7231, 1.6901,\n",
       "                      1.6954, 1.7023, 1.7013, 1.7527, 1.7193, 1.7092, 1.6938, 1.7000, 1.7025,\n",
       "                      1.6916, 1.7014, 1.7072, 1.6820, 1.7245, 1.7416, 1.7053, 1.7155, 1.7299,\n",
       "                      1.7194, 1.7098, 1.7053, 1.7063, 1.7049, 1.7437, 1.7063, 1.6906, 1.7106,\n",
       "                      1.7443, 1.7189, 1.7179, 1.7153, 1.7341, 1.7013, 1.7136, 1.7054, 1.7365,\n",
       "                      1.6848, 1.6852, 1.7131, 1.6843, 1.7486, 1.7072, 1.7173, 1.7094, 1.7067,\n",
       "                      1.6918, 1.7654, 1.6598, 1.7164, 1.7058, 1.7161, 1.6948, 1.7285, 1.7062,\n",
       "                      1.6830, 1.7168, 1.7254, 1.7142, 1.7260, 1.7243, 1.7036, 1.6583, 1.6762,\n",
       "                      1.7026, 1.6779, 1.7039, 1.7102, 1.7359, 1.7125, 1.7281, 1.6626, 1.7082,\n",
       "                      1.7318, 1.7090, 1.7111, 1.7250, 1.7064, 1.7146, 1.7137, 1.7000, 1.7150,\n",
       "                      1.7255, 1.6959, 1.7091, 1.7442, 1.7505, 1.7000, 1.6919, 1.7025, 1.7000,\n",
       "                      1.7076, 1.6980, 1.7426, 1.7187, 1.7477, 1.7345, 1.7147, 1.7139, 1.6938,\n",
       "                      1.7005, 1.6881, 1.6936, 1.7172, 1.6985, 1.6734, 1.7050, 1.7029, 1.7012,\n",
       "                      1.7117, 1.6970, 1.7024, 1.7020, 1.7085, 1.7087, 1.6952, 1.7004, 1.7091,\n",
       "                      1.7047, 1.7213, 1.7026, 1.7042, 1.7012, 1.7046, 1.6974, 1.7148, 1.7034,\n",
       "                      1.7215, 1.6998, 1.7157, 1.7000, 1.6981, 1.6970, 1.7007, 1.7005, 1.7039,\n",
       "                      1.6862, 1.7028, 1.6956, 1.7011, 1.6942, 1.7113, 1.7019, 1.6985, 1.7025,\n",
       "                      1.7125, 1.7409, 1.7014, 1.7053, 1.7008, 1.7066, 1.7005, 1.7072, 1.7114,\n",
       "                      1.6961, 1.6994, 1.6955, 1.7035, 1.6939, 1.7127, 1.6945, 1.7020, 1.6990,\n",
       "                      1.7067, 1.6985, 1.6869, 1.6984, 1.7001, 1.6972, 1.6947, 1.7043, 1.7024,\n",
       "                      1.7008, 1.7121, 1.7215, 1.7043, 1.7074, 1.6997, 1.7134, 1.6932, 1.7113,\n",
       "                      1.7000, 1.6982, 1.6843, 1.6913, 1.6788, 1.7157, 1.7025, 1.7053, 1.6966,\n",
       "                      1.6884, 1.7092, 1.6734, 1.7189, 1.6980, 1.6949, 1.7008, 1.6940, 1.7049,\n",
       "                      1.6942, 1.6944, 1.7038, 1.7015, 1.6978, 1.7064, 1.7162, 1.6932, 1.7103,\n",
       "                      1.6845, 1.7098, 1.7076, 1.7087, 1.6888, 1.7285, 1.7099, 1.6732, 1.7005,\n",
       "                      1.6891, 1.6997, 1.7056, 1.6965, 1.6839, 1.6977, 1.7030, 1.7032, 1.7051,\n",
       "                      1.7065, 1.7049, 1.7036, 1.7059], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.lq.weight',\n",
       "              tensor([[-0.0267,  0.0734,  0.1244,  ...,  0.0674,  0.0423, -0.0489],\n",
       "                      [ 0.0157,  0.1393,  0.0529,  ..., -0.0830, -0.0575,  0.0047],\n",
       "                      [-0.1330,  0.1556,  0.0666,  ...,  0.0437, -0.0643,  0.1275],\n",
       "                      ...,\n",
       "                      [ 0.0319, -0.0521,  0.0417,  ..., -0.0512, -0.0482, -0.0146],\n",
       "                      [-0.0386, -0.0357,  0.1069,  ..., -0.0096, -0.1882,  0.1590],\n",
       "                      [ 0.0680,  0.0021,  0.0252,  ..., -0.0424,  0.0036,  0.1122]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.lq.bias',\n",
       "              tensor([ 0.0103,  0.0361,  0.0137,  0.0131,  0.0526,  0.0656,  0.0322, -0.0105,\n",
       "                      -0.0080,  0.0323,  0.0757,  0.0173,  0.0200,  0.0738,  0.0570,  0.0386,\n",
       "                       0.0411,  0.0197,  0.0179,  0.0113,  0.0396,  0.0409,  0.0519, -0.0052,\n",
       "                       0.0633,  0.0265,  0.0827,  0.0138,  0.0173,  0.0315,  0.0517,  0.0060,\n",
       "                       0.0305,  0.0271,  0.0011,  0.0100,  0.0479,  0.0434, -0.0081,  0.0047,\n",
       "                       0.0624,  0.0168,  0.0560,  0.0276,  0.0323, -0.0139, -0.0309,  0.0530,\n",
       "                       0.0127, -0.0130,  0.0157,  0.0113,  0.0156,  0.0505,  0.0123,  0.0196,\n",
       "                       0.0362,  0.0190, -0.0143,  0.0442,  0.0209,  0.0073,  0.0352,  0.0425,\n",
       "                      -0.0040,  0.0325, -0.0161,  0.0256,  0.0483,  0.0202, -0.0208,  0.0024,\n",
       "                       0.0130,  0.0035,  0.0372,  0.0214, -0.0138,  0.0915,  0.0493,  0.0185,\n",
       "                       0.0046,  0.0433,  0.0155, -0.0070,  0.0013,  0.0365,  0.0137,  0.0080,\n",
       "                      -0.0291, -0.0097,  0.0221,  0.0406, -0.0397,  0.0002, -0.0027,  0.0268,\n",
       "                       0.0207,  0.0038,  0.0660, -0.0036,  0.0168,  0.0421,  0.0143,  0.0333,\n",
       "                       0.0190,  0.0179,  0.0549,  0.0234,  0.0107,  0.0344,  0.0587,  0.0409,\n",
       "                       0.0036,  0.0358,  0.0093,  0.0039,  0.0200,  0.0299,  0.0111,  0.0081,\n",
       "                       0.0363,  0.0399,  0.0241, -0.0151,  0.0170,  0.0543,  0.0382,  0.0197],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.lk.weight',\n",
       "              tensor([[ 0.0391,  0.0792,  0.0244,  ..., -0.0835,  0.1198,  0.0815],\n",
       "                      [ 0.1147,  0.1511, -0.1290,  ..., -0.1053,  0.0114, -0.1127],\n",
       "                      [ 0.0318,  0.1247, -0.1104,  ..., -0.0773,  0.0698,  0.0970],\n",
       "                      ...,\n",
       "                      [ 0.1076,  0.0550,  0.0326,  ..., -0.1384, -0.0605, -0.0069],\n",
       "                      [-0.1384,  0.1837,  0.1945,  ...,  0.0107,  0.1230,  0.0629],\n",
       "                      [-0.0453,  0.1455,  0.2087,  ...,  0.0766,  0.0019,  0.1358]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.lk.bias',\n",
       "              tensor([ 0.0100,  0.0232,  0.0483, -0.0025,  0.0626,  0.0151,  0.0131, -0.0026,\n",
       "                       0.0686,  0.0104,  0.1065,  0.0315,  0.0198,  0.0493, -0.0082,  0.0221,\n",
       "                      -0.0059,  0.0358,  0.0309,  0.0149, -0.0162,  0.0015,  0.0992,  0.0303,\n",
       "                       0.0653,  0.0026,  0.0570,  0.0428,  0.0386,  0.0824,  0.0522, -0.0113,\n",
       "                       0.0369, -0.0367,  0.0037,  0.0069, -0.0019,  0.0406,  0.0345,  0.0024,\n",
       "                       0.0651,  0.0386, -0.0338,  0.0016,  0.0463, -0.0273,  0.0534,  0.0419,\n",
       "                       0.0050,  0.0698, -0.0046,  0.0134,  0.0379,  0.0236, -0.0125, -0.0119,\n",
       "                       0.0539,  0.0722,  0.0915,  0.0309,  0.1321,  0.0872,  0.0707,  0.0235,\n",
       "                       0.0300,  0.0416, -0.0009,  0.0021, -0.0108, -0.0030,  0.0167,  0.0032,\n",
       "                       0.0670,  0.0364, -0.0253,  0.0118, -0.0215,  0.0143,  0.0190, -0.0055,\n",
       "                       0.0119,  0.0609, -0.0089, -0.0038,  0.0446,  0.0539, -0.0157,  0.0790,\n",
       "                      -0.0174,  0.0275,  0.0693, -0.0024,  0.0129,  0.0770, -0.0042,  0.0263,\n",
       "                      -0.0013,  0.0214, -0.0100,  0.0381, -0.0004,  0.0239,  0.0814, -0.0149,\n",
       "                       0.0511,  0.0106, -0.0403,  0.0043,  0.0229,  0.0141,  0.0041,  0.0607,\n",
       "                      -0.0111,  0.0482,  0.0144,  0.0219,  0.0592,  0.0291, -0.0372, -0.0246,\n",
       "                      -0.0520, -0.0242, -0.0541,  0.0516,  0.0063,  0.0708,  0.0534,  0.0244],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.lv.weight',\n",
       "              tensor([[ 0.0639, -0.0773,  0.0461,  ...,  0.0099,  0.0021, -0.0970],\n",
       "                      [ 0.0998, -0.0020, -0.1102,  ..., -0.0271,  0.1112, -0.0352],\n",
       "                      [-0.0255, -0.0036,  0.1092,  ..., -0.0107, -0.1060, -0.0146],\n",
       "                      ...,\n",
       "                      [-0.0631, -0.0492,  0.0466,  ...,  0.1173,  0.0855, -0.0544],\n",
       "                      [ 0.0855, -0.0090, -0.0505,  ...,  0.0787, -0.0638,  0.0710],\n",
       "                      [-0.0646,  0.0003,  0.0218,  ..., -0.0183,  0.0936,  0.0448]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.lv.bias',\n",
       "              tensor([ 4.7768e-02,  2.1574e-03,  3.7600e-04,  9.1372e-03, -6.7496e-03,\n",
       "                      -8.2472e-03,  1.4454e-03,  1.7282e-03,  1.2163e-03,  6.4652e-03,\n",
       "                       7.6884e-04, -2.5367e-03, -2.6997e-03,  8.2861e-03, -2.4827e-03,\n",
       "                      -1.2112e-02,  1.5842e-02, -3.9242e-03, -2.5183e-03, -6.6784e-04,\n",
       "                      -9.2440e-03,  8.6565e-04,  1.1478e-02, -7.3392e-03, -9.3831e-03,\n",
       "                       6.6465e-04,  2.6476e-03, -7.8977e-03, -2.9589e-03, -3.5297e-03,\n",
       "                       1.0262e-02, -8.0712e-03, -4.8146e-04, -1.1481e-02, -2.1967e-03,\n",
       "                       1.0709e-02, -9.7450e-03,  3.7351e-03,  1.9027e-03,  6.5425e-03,\n",
       "                       1.5308e-04,  7.9793e-03, -4.2102e-03, -1.4739e-03,  3.3452e-03,\n",
       "                       3.3475e-03, -2.0185e-02, -9.1513e-03,  6.3134e-03,  9.3690e-03,\n",
       "                       3.1395e-03,  4.2734e-03, -1.0331e-03,  2.6317e-03,  9.3900e-03,\n",
       "                       2.1458e-03,  5.8880e-03,  3.9699e-04, -4.1511e-03,  4.4978e-03,\n",
       "                       3.8906e-02, -9.8743e-03, -7.0432e-03, -8.1971e-03,  4.5295e-03,\n",
       "                      -8.9154e-03, -5.4724e-04,  5.0017e-04,  3.8249e-03, -2.9657e-03,\n",
       "                      -1.8530e-03, -3.8345e-03,  7.0378e-04,  1.2904e-02,  8.8408e-03,\n",
       "                      -3.6249e-03,  7.0736e-03,  2.4981e-03, -7.5357e-03, -8.9423e-03,\n",
       "                       6.9712e-03,  1.2826e-02,  7.0056e-03,  2.8398e-04,  1.0995e-02,\n",
       "                       7.8028e-03,  5.7341e-03, -1.0313e-02,  6.7905e-03,  2.1152e-02,\n",
       "                       8.3844e-03, -3.1584e-03, -3.7289e-03,  4.0953e-02, -1.0355e-02,\n",
       "                       4.0736e-03, -7.1331e-03, -7.9842e-03, -4.5015e-03,  1.0507e-02,\n",
       "                       7.1749e-04, -4.1663e-03, -1.6613e-03, -2.2066e-04,  3.0882e-03,\n",
       "                      -3.6757e-03,  1.2469e-04, -2.7272e-03, -2.6375e-03, -8.4098e-05,\n",
       "                       3.9601e-03,  4.9009e-03,  6.0633e-03,  3.5924e-03, -3.1073e-03,\n",
       "                      -8.2307e-03,  6.5428e-05, -1.3891e-02,  1.3119e-03, -1.0072e-02,\n",
       "                       6.3322e-04, -6.8181e-03, -2.3092e-04,  4.4888e-02, -2.0913e-03,\n",
       "                       3.3039e-03, -5.2534e-04, -5.8983e-03, -6.1884e-03, -5.8360e-03,\n",
       "                       1.7552e-03,  5.6144e-03, -3.6224e-03, -4.3551e-03,  3.7346e-03,\n",
       "                      -6.2317e-03,  1.7841e-03,  2.3145e-03,  4.8603e-03, -8.6289e-03,\n",
       "                       5.0415e-04,  1.7814e-02,  2.5979e-03,  1.1230e-03, -1.4331e-02,\n",
       "                       3.7196e-03, -5.4331e-03, -4.7005e-03, -3.8322e-03, -5.7792e-03,\n",
       "                      -5.8211e-03, -1.1065e-03,  6.0868e-03, -1.0171e-02, -1.0718e-02,\n",
       "                      -1.2215e-02, -6.6376e-03, -5.3890e-03,  2.7697e-02,  5.8753e-03,\n",
       "                      -3.0008e-03, -8.9782e-03,  8.7052e-03,  2.6805e-03, -1.3327e-03,\n",
       "                       1.2016e-02, -2.9957e-04,  2.1736e-03,  9.3450e-04, -7.9621e-03,\n",
       "                      -3.9388e-03,  6.5858e-03, -2.4311e-04, -6.9652e-03,  2.6760e-02,\n",
       "                      -9.5932e-03,  1.2019e-03,  1.3949e-02,  5.5919e-03,  8.2728e-04,\n",
       "                      -7.1506e-04, -4.5799e-03,  4.6612e-03,  1.0873e-02,  5.0439e-03,\n",
       "                       7.0412e-03, -3.0236e-03,  4.3922e-03,  2.2035e-02,  4.8173e-03,\n",
       "                       1.6849e-03,  1.2500e-03,  1.0405e-02,  4.1241e-03,  3.3059e-03,\n",
       "                       1.4249e-03,  4.1931e-03,  1.1102e-03, -6.4931e-04, -5.2189e-03,\n",
       "                      -6.2722e-03, -4.5433e-03,  1.9324e-03,  8.2430e-04,  7.6725e-03,\n",
       "                       6.2399e-03,  1.7191e-02,  4.4493e-03, -8.9952e-03, -4.9027e-03,\n",
       "                       4.1560e-03, -9.6282e-04, -5.9799e-04, -2.8044e-03, -4.2575e-03,\n",
       "                      -3.2971e-03,  7.7842e-03, -8.5088e-03, -3.7134e-03,  7.7046e-03,\n",
       "                       8.2613e-03, -5.7218e-03, -2.8415e-03, -3.8744e-03,  1.6779e-03,\n",
       "                       1.1272e-03, -6.4392e-04,  7.2170e-04, -1.4820e-04, -8.9405e-03,\n",
       "                       3.2462e-02, -3.0777e-03, -5.6602e-03, -5.9254e-03, -3.2507e-03,\n",
       "                       2.8427e-04,  4.2077e-03,  3.4068e-02, -5.2096e-03,  6.9665e-03,\n",
       "                      -8.3327e-03, -3.0919e-03, -3.2851e-03,  3.2075e-04, -3.3299e-03,\n",
       "                      -5.6598e-03,  1.2183e-02, -8.5925e-03, -5.5593e-03,  1.5236e-02,\n",
       "                       4.2140e-03, -2.7601e-03,  3.4482e-03, -1.0304e-03,  1.0588e-03,\n",
       "                      -1.0581e-03], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.la.weight',\n",
       "              tensor([[ 0.0213, -0.0984, -0.0242,  ...,  0.1162,  0.0635,  0.0423],\n",
       "                      [ 0.0593,  0.1609,  0.1196,  ...,  0.0487,  0.0650, -0.2053],\n",
       "                      [ 0.1411, -0.0741, -0.0240,  ...,  0.1071, -0.0276,  0.0977],\n",
       "                      ...,\n",
       "                      [ 0.0281, -0.0192,  0.0439,  ...,  0.0461, -0.0531,  0.0057],\n",
       "                      [-0.0219,  0.0190, -0.0218,  ...,  0.0151, -0.1089,  0.0298],\n",
       "                      [ 0.0075,  0.0672, -0.0928,  ...,  0.1092,  0.0330, -0.0082]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.la.bias',\n",
       "              tensor([-4.5724e-02, -4.7566e-02,  1.1695e-02, -3.1263e-02,  2.9896e-02,\n",
       "                       8.8548e-03, -2.7497e-02,  9.9463e-04, -7.9831e-03, -2.3207e-02,\n",
       "                       2.3142e-02, -2.5170e-02,  3.2498e-02,  3.2475e-02, -1.3987e-02,\n",
       "                       3.8873e-02, -3.8277e-02, -1.9187e-02,  3.6973e-02,  2.3349e-02,\n",
       "                       4.6255e-02, -2.0259e-02, -3.1331e-02, -2.1813e-02, -5.1312e-02,\n",
       "                       1.7336e-02, -2.9191e-02, -3.2954e-02,  2.3011e-02,  1.0598e-03,\n",
       "                       4.3112e-02,  1.5857e-02, -2.3019e-02, -2.6098e-02,  4.3948e-02,\n",
       "                       2.3148e-02, -1.3111e-02, -3.1877e-02,  1.1675e-03,  1.7240e-02,\n",
       "                       5.2696e-02,  3.5848e-02,  5.0005e-02,  6.3425e-02,  1.5176e-02,\n",
       "                       1.9737e-02, -2.4873e-03, -3.6060e-02,  3.5683e-02,  2.3152e-02,\n",
       "                       4.3601e-02, -2.3954e-02, -3.5290e-03, -9.4717e-03,  3.0619e-02,\n",
       "                       2.0956e-02,  3.0149e-02, -1.3921e-02,  1.6502e-02,  2.9419e-02,\n",
       "                       5.6552e-02,  2.3879e-03, -6.4466e-02,  4.0686e-02, -5.9959e-02,\n",
       "                       2.0560e-02, -1.3962e-02,  6.1928e-02,  4.1465e-02, -7.3343e-03,\n",
       "                       3.7560e-02, -3.3186e-02, -3.9135e-02,  1.8963e-02, -8.3909e-02,\n",
       "                       2.0723e-02,  1.6228e-02, -4.0112e-02, -5.8953e-02,  3.4085e-02,\n",
       "                       5.7068e-03,  3.2015e-02, -9.4345e-03,  3.4566e-02, -1.6048e-03,\n",
       "                       2.2293e-02,  3.7017e-03,  2.4970e-02,  1.2668e-02, -3.2001e-02,\n",
       "                       2.0194e-02, -1.9044e-03,  2.6077e-03,  2.0342e-02,  7.1334e-02,\n",
       "                       4.0404e-03,  7.6013e-04, -2.0314e-02, -3.0102e-02, -1.1520e-02,\n",
       "                       1.0648e-02, -2.9958e-02,  2.1497e-02,  2.8276e-02,  2.1837e-02,\n",
       "                      -1.3130e-02, -8.6391e-03, -1.3842e-02,  2.5454e-02, -1.5505e-02,\n",
       "                       1.0722e-02, -3.7252e-02, -1.5475e-02,  2.0815e-02,  5.9139e-03,\n",
       "                       1.3229e-03, -2.6015e-02,  5.7722e-03,  4.6171e-03,  1.8767e-02,\n",
       "                       4.6139e-02,  4.6530e-02,  8.0134e-02,  2.9546e-02,  2.7319e-02,\n",
       "                      -3.2723e-02, -4.5913e-02, -3.0123e-03,  6.0878e-04,  6.3864e-04,\n",
       "                      -2.0053e-03, -1.8615e-04, -1.0292e-03, -1.8238e-03, -2.3342e-03,\n",
       "                       9.9749e-04,  1.6809e-06,  7.6025e-04,  3.2486e-05, -8.0913e-04,\n",
       "                      -2.0355e-04,  2.0439e-03,  5.5471e-06,  2.2047e-04,  4.9467e-04,\n",
       "                      -2.8079e-04, -6.0507e-04,  8.7044e-04, -4.5266e-04, -1.3767e-03,\n",
       "                      -8.1003e-04, -1.7331e-04,  7.8853e-04, -4.7441e-05, -5.5768e-04,\n",
       "                       9.6037e-04, -1.3176e-03,  1.8796e-03, -6.5380e-04, -4.8019e-04,\n",
       "                       1.3576e-05, -7.6340e-05,  4.5782e-04,  4.1679e-04,  2.5692e-04,\n",
       "                       1.1565e-03,  4.8700e-04,  4.2401e-03, -3.9159e-04, -2.7162e-03,\n",
       "                      -1.0067e-03,  8.2557e-04, -1.7227e-03,  3.8160e-04, -2.1975e-04,\n",
       "                       7.4573e-04,  1.5448e-03, -2.4675e-04, -2.5042e-04,  4.1453e-03,\n",
       "                      -1.5255e-03,  1.0944e-03,  2.7181e-04, -4.6324e-04, -7.4121e-04,\n",
       "                      -2.3904e-03,  9.7398e-05, -2.7342e-04, -7.1655e-04,  3.6432e-04,\n",
       "                      -1.4618e-03, -1.0995e-03,  1.2846e-03, -1.0804e-03, -5.1678e-04,\n",
       "                      -7.8227e-06, -4.9278e-04, -1.0206e-03,  7.8813e-04, -4.5439e-04,\n",
       "                      -4.5265e-05, -4.7664e-04, -5.0742e-04,  4.1168e-04,  7.4732e-04,\n",
       "                       6.1255e-04, -1.5222e-03, -2.7236e-03, -1.5812e-03, -3.9605e-03,\n",
       "                       5.4690e-05, -1.6007e-04, -1.3200e-03, -2.3465e-03,  4.0111e-04,\n",
       "                       3.0603e-04,  4.2809e-04,  1.6531e-03,  4.6174e-05,  8.0973e-04,\n",
       "                      -9.8336e-04, -1.4266e-03, -1.5002e-04,  8.2353e-04, -4.3043e-04,\n",
       "                      -5.2228e-04, -2.7402e-04, -1.3911e-04, -1.7710e-03, -3.1005e-04,\n",
       "                      -1.0854e-03, -2.5829e-05, -7.1442e-04,  3.2967e-04, -7.4664e-04,\n",
       "                      -3.4099e-03,  2.0226e-03,  7.5002e-05, -1.9853e-04,  1.7447e-03,\n",
       "                       1.8339e-03,  3.6122e-03,  3.3971e-03,  5.4655e-04, -1.7479e-04,\n",
       "                       9.6010e-06,  1.9086e-03, -1.7114e-04, -1.5996e-04, -6.4397e-06,\n",
       "                      -3.1067e-04,  6.0810e-05,  3.5130e-03,  6.0129e-04,  2.4072e-05,\n",
       "                      -1.6133e-04], device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.lrbf.weight',\n",
       "              tensor([[ 0.0527, -0.1084,  0.0058,  ..., -0.0863, -0.1521,  0.0233],\n",
       "                      [-0.0897, -0.0218,  0.0236,  ...,  0.1266, -0.1600, -0.1582],\n",
       "                      [-0.1753, -0.0713, -0.1915,  ..., -0.1036,  0.0092,  0.0100],\n",
       "                      ...,\n",
       "                      [ 0.0286,  0.0610, -0.0193,  ...,  0.0868, -0.0298,  0.0995],\n",
       "                      [-0.1231,  0.1266,  0.1292,  ...,  0.0339,  0.0849, -0.1546],\n",
       "                      [-0.1573, -0.0110,  0.1090,  ..., -0.1329,  0.1236, -0.0836]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.lkrbf.weight',\n",
       "              tensor([[-0.1137, -0.0362, -0.0769,  ..., -0.1014, -0.0065,  0.0123],\n",
       "                      [ 0.0839, -0.0214,  0.0446,  ...,  0.1132, -0.0488,  0.0599],\n",
       "                      [ 0.0802,  0.1579,  0.1471,  ...,  0.2069,  0.1143, -0.1022],\n",
       "                      ...,\n",
       "                      [ 0.0872,  0.0536,  0.0055,  ..., -0.0685, -0.0728,  0.0904],\n",
       "                      [-0.1818,  0.1306, -0.0642,  ...,  0.0940,  0.0398,  0.0580],\n",
       "                      [-0.0492,  0.1196,  0.1069,  ..., -0.1320,  0.1084, -0.0955]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.message.Attention.lvrbf.weight',\n",
       "              tensor([[-0.0086,  0.0947, -0.0971,  ...,  0.0108,  0.0577, -0.0785],\n",
       "                      [ 0.1237,  0.0060,  0.0669,  ...,  0.0694,  0.0123,  0.0994],\n",
       "                      [-0.0331, -0.0493, -0.0312,  ..., -0.0501,  0.1005, -0.0486],\n",
       "                      ...,\n",
       "                      [ 0.0593,  0.1187, -0.0499,  ...,  0.1173,  0.0697,  0.0009],\n",
       "                      [ 0.0271,  0.0049,  0.0433,  ...,  0.1120, -0.1197, -0.0083],\n",
       "                      [ 0.1108, -0.0082, -0.1140,  ..., -0.1000, -0.0207, -0.1123]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.message.tp.weight',\n",
       "              tensor([-1.0883e+00, -4.3714e-01,  9.3305e-01, -8.7658e-01,  1.1090e+00,\n",
       "                       7.0638e-01, -1.2477e+00,  3.9921e-01,  5.8898e-01,  7.0946e-01,\n",
       "                      -9.4613e-01,  1.8995e+00, -6.5150e-01,  1.1251e+00,  3.4296e-01,\n",
       "                       1.9971e-01, -1.0363e+00,  4.8810e-01, -7.4414e-01,  1.4217e+00,\n",
       "                      -9.8488e-01,  2.3611e-01,  1.1578e+00,  8.8237e-01, -1.1398e-02,\n",
       "                      -1.5520e+00,  4.8966e-01,  2.8909e-01, -8.6116e-01, -1.0331e+00,\n",
       "                      -7.8482e-01,  8.8949e-01,  1.1196e+00, -1.0038e+00,  4.0185e-01,\n",
       "                      -8.8870e-01, -3.9929e-01, -9.6333e-01, -6.5138e-01,  8.8312e-02,\n",
       "                       7.7277e-01, -1.7305e-02,  3.0402e-01,  8.6488e-02, -9.9154e-01,\n",
       "                       2.2819e-01,  5.3341e-01, -7.3371e-01, -5.8809e-01, -1.3829e+00,\n",
       "                       1.2677e+00, -8.5838e-01,  1.0216e+00,  7.2753e-01, -4.9271e-01,\n",
       "                      -3.5055e-01,  3.3625e-01,  1.2951e+00, -3.3445e-01,  2.7226e-02,\n",
       "                      -3.9882e-02, -4.8693e-01,  1.8076e-01,  9.0026e-01,  1.0486e-01,\n",
       "                       9.0852e-01, -8.0059e-01,  7.3304e-01, -6.9114e-01,  8.6493e-01,\n",
       "                       3.4005e-01, -7.7782e-02, -7.3200e-01, -1.4832e+00, -7.7036e-01,\n",
       "                      -1.8724e+00,  1.6495e+00,  1.8954e-01, -7.0551e-01,  9.5821e-01,\n",
       "                      -3.4854e-01,  5.4612e-01, -5.4056e-01,  2.6293e-01,  1.1127e+00,\n",
       "                      -1.2370e+00, -5.0777e-01,  1.2695e+00, -2.1330e+00, -3.8183e-01,\n",
       "                       9.4606e-01, -4.2088e-01, -1.1624e-01,  2.0528e+00, -2.7135e-01,\n",
       "                       1.8952e+00,  1.2144e+00, -1.6337e+00,  3.9815e+00, -2.6406e-01,\n",
       "                      -2.8765e-01,  3.5075e-01, -7.0790e-01,  9.5280e-01,  1.1513e+00,\n",
       "                       2.4500e+00,  2.2532e-01, -3.5510e-01, -1.6608e+00, -4.9947e-01,\n",
       "                      -4.5935e-01,  7.4591e-01, -8.6429e-01, -8.5208e-02,  1.5995e-01,\n",
       "                      -3.6115e-01, -1.0742e+00, -1.2515e-01, -5.0300e-01,  2.8166e-01,\n",
       "                       1.3696e+00,  2.1901e-01,  6.1764e-01, -1.5437e+00, -1.8145e+00,\n",
       "                      -1.1652e-01,  1.2614e+00, -2.8918e-01,  6.8116e-01, -1.1796e+00,\n",
       "                       1.0182e+00, -4.9704e-01,  1.1449e+00,  9.2453e-01, -8.9164e-01,\n",
       "                       1.5739e-01, -1.4196e-01,  5.8148e-01,  9.5515e-01, -5.4886e-01,\n",
       "                       1.2077e+00,  1.6857e-01,  5.8633e-01, -1.2210e+00, -6.5801e-01,\n",
       "                      -4.5474e-01, -7.0894e-01,  9.5446e-01, -3.6914e-02, -1.5833e+00,\n",
       "                       4.6315e-01,  6.1637e-02, -5.1232e-01, -1.0304e+00,  5.5108e-01,\n",
       "                       1.2262e-01,  1.2209e-01,  2.7097e-01,  1.8537e+00, -1.6183e+00,\n",
       "                       1.2849e+00, -6.7477e-01, -9.3664e-01, -1.8648e+00,  1.5738e+00,\n",
       "                      -3.1897e-01, -1.2979e+00, -1.4229e+00,  6.9959e-01,  2.2527e+00,\n",
       "                      -1.7352e+00,  4.0660e-01,  2.5004e+00,  2.8933e-01,  1.2103e+00,\n",
       "                       7.0692e-01, -1.0469e-01,  2.9853e-01,  5.9846e-02, -1.9919e+00,\n",
       "                      -1.0579e+00,  6.3946e-01,  1.6386e+00, -1.5397e+00,  9.8950e-01,\n",
       "                       1.1348e+00,  1.1249e+00, -3.0244e-01,  6.1775e-01,  1.2845e+00,\n",
       "                       1.4781e+00, -3.4284e-01, -1.1628e+00,  4.3363e-01,  5.3086e-02,\n",
       "                       9.1823e-01,  1.2865e+00, -3.7266e-01, -8.2435e-01, -3.7437e-01,\n",
       "                       2.9121e-01, -6.5880e-01, -5.6563e-01,  1.5205e-01, -2.4645e-01,\n",
       "                      -1.1186e+00,  4.2658e-01, -1.0111e+00, -5.4483e-02,  1.1212e+00,\n",
       "                       1.1873e+00, -1.8028e+00, -8.4962e-01,  1.0803e+00, -2.9337e-01,\n",
       "                       2.6752e-01, -8.9826e-01, -3.0717e-01, -4.9609e-01, -2.9109e-01,\n",
       "                      -2.1003e-01, -3.6471e-01,  4.6034e-02, -1.0513e+00, -6.3680e-01,\n",
       "                      -1.9567e+00,  1.8566e-01,  2.6952e+00, -4.6544e-01, -1.5801e+00,\n",
       "                      -3.8292e-01,  4.5178e-01, -2.0670e+00, -6.8549e-01, -2.2959e-01,\n",
       "                       7.0336e-01,  5.7538e-01,  7.2137e-01,  5.1807e-01,  5.6570e-01,\n",
       "                       1.6706e+00, -2.4892e-01,  1.5606e+00, -1.5720e+00, -1.0506e-01,\n",
       "                       9.0424e-01, -8.3289e-01, -1.2926e+00,  5.3009e-01, -1.1675e+00,\n",
       "                      -1.3565e+00, -8.9854e-01,  4.4723e-01, -7.5971e-01,  9.0581e-01,\n",
       "                       9.8274e-02, -1.3476e+00,  2.0328e+00,  3.8285e-01,  8.4178e-01,\n",
       "                      -2.8813e-01,  3.5269e-01, -7.8443e-02,  8.5599e-01,  1.0650e+00,\n",
       "                       1.2011e+00, -1.7886e-01, -7.8809e-01,  3.1546e-02,  1.4290e-01,\n",
       "                      -3.1681e-01, -1.7836e+00,  1.6725e+00,  1.7663e+00, -1.0784e+00,\n",
       "                       1.8117e-02,  2.1285e-01,  7.3886e-01, -5.6665e-04, -7.7023e-01,\n",
       "                      -1.1767e+00, -1.3429e+00, -5.0464e-01, -7.2357e-01, -6.7805e-01,\n",
       "                      -8.6727e-01, -5.9451e-01, -1.2409e+00, -1.0988e+00, -4.3823e-01,\n",
       "                       6.1947e-01, -8.4851e-01, -8.7583e-01, -7.7616e-01,  2.1341e+00,\n",
       "                      -2.2326e+00,  1.9032e+00, -1.0588e+00,  1.1622e+00, -1.2843e-01,\n",
       "                      -1.6931e+00,  4.0614e-01, -8.1402e-01, -9.1231e-01, -4.4303e-01,\n",
       "                       3.1176e-01, -1.1278e-01, -1.1992e+00,  8.1606e-02,  1.3853e+00,\n",
       "                      -1.2292e-02,  2.9279e-01,  6.0827e-01, -1.1540e+00,  2.3087e-01,\n",
       "                      -2.5071e-01, -7.5206e-02, -2.1484e+00, -1.3079e-01, -4.2016e-01,\n",
       "                      -3.5220e-01,  7.6545e-01,  2.5994e-01, -2.2617e+00, -1.8725e-01,\n",
       "                      -4.7956e-01, -7.1412e-01, -4.3186e-01, -1.4081e+00, -1.0179e+00,\n",
       "                       4.9949e-01, -5.0654e-01,  4.8335e-01,  3.8613e+00,  2.2179e+00,\n",
       "                      -1.4135e+00, -5.5749e-02, -1.5992e+00,  2.5935e-01, -8.3165e-01,\n",
       "                       1.8365e+00,  7.1768e-01, -7.5338e-01,  4.5307e-01,  1.2474e+00,\n",
       "                      -5.6794e-01,  1.2829e+00,  1.4548e+00, -3.3270e-02, -5.2714e-01,\n",
       "                      -1.3881e+00,  7.1336e-01,  6.7056e-01, -3.6107e-01,  8.6722e-01,\n",
       "                       1.5431e+00,  4.5228e-01, -4.1148e-01,  1.5831e-01,  2.3675e-02,\n",
       "                      -2.0185e+00,  1.8971e-01, -7.7607e-02, -1.4920e+00, -8.6370e-01,\n",
       "                       7.2917e-01, -3.2523e-01,  3.1817e-01,  5.8095e-01,  5.0587e-01,\n",
       "                       2.0483e+00, -7.5427e-01,  1.1844e+00,  1.2664e+00, -8.1617e-02,\n",
       "                       3.1596e-01, -3.6445e-01, -1.0607e+00, -1.2129e-01,  2.4238e-01,\n",
       "                      -7.0029e-02, -1.4919e-01, -8.5462e-01, -1.4546e+00], device='cuda:0')),\n",
       "             ('blocks.2.message.tp.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.2.update.actu.alpha',\n",
       "              tensor([0.9843, 0.9949, 0.9950, 0.9992, 0.9959, 1.0032, 0.9937, 0.9972, 0.9965,\n",
       "                      0.9929, 0.9925, 1.0006, 0.9956, 1.0006, 0.9951, 0.9976, 0.9983, 0.9925,\n",
       "                      1.0027, 0.9981, 0.9987, 0.9943, 1.0030, 1.0013, 0.9970, 1.0003, 0.9999,\n",
       "                      0.9841, 0.9924, 1.0013, 0.9947, 0.9910, 0.9921, 0.9971, 1.0050, 0.9928,\n",
       "                      1.0001, 1.0016, 1.0104, 0.9950, 1.0001, 0.9952, 1.0010, 1.0017, 1.0007,\n",
       "                      1.0052, 1.0038, 0.9930, 0.9998, 1.0015, 1.0023, 0.9933, 1.0061, 0.9945,\n",
       "                      0.9925, 0.9986, 0.9934, 0.9991, 0.9994, 0.9927, 1.0015, 0.9996, 0.9998,\n",
       "                      1.0027, 0.9839, 0.9973, 1.0061, 0.9974, 0.9998, 0.9883, 0.9996, 1.0005,\n",
       "                      1.0040, 0.9939, 0.9889, 0.9990, 0.9985, 1.0033, 0.9952, 1.0061, 0.9984,\n",
       "                      0.9988, 0.9980, 0.9974, 0.9961, 1.0004, 0.9971, 0.9938, 1.0002, 0.9916,\n",
       "                      1.0038, 0.9867, 0.9969, 0.9938, 0.9971, 1.0029, 1.0023, 0.9965, 0.9973,\n",
       "                      0.9993, 0.9997, 0.9924, 1.0014, 0.9913, 0.9867, 0.9986, 0.9958, 0.9963,\n",
       "                      0.9970, 0.9979, 0.9956, 0.9967, 0.9990, 0.9992, 1.0019, 0.9983, 0.9919,\n",
       "                      1.0000, 1.0023, 0.9977, 1.0009, 0.9990, 1.0020, 0.9958, 0.9948, 0.9938,\n",
       "                      1.0030, 1.0034], device='cuda:0')),\n",
       "             ('blocks.2.update.actu.beta',\n",
       "              tensor([1.7257, 1.6998, 1.7114, 1.7035, 1.7351, 1.6913, 1.6873, 1.7087, 1.7089,\n",
       "                      1.6941, 1.7052, 1.7107, 1.6969, 1.7096, 1.7049, 1.7035, 1.6761, 1.7081,\n",
       "                      1.6787, 1.6956, 1.7151, 1.6935, 1.7093, 1.6997, 1.7128, 1.6940, 1.7066,\n",
       "                      1.7102, 1.7035, 1.7127, 1.7059, 1.7087, 1.7044, 1.7048, 1.7161, 1.7217,\n",
       "                      1.7045, 1.7111, 1.7172, 1.7138, 1.6887, 1.7350, 1.6913, 1.7164, 1.7074,\n",
       "                      1.7386, 1.6929, 1.7031, 1.7139, 1.6918, 1.7022, 1.7040, 1.6678, 1.7096,\n",
       "                      1.7025, 1.7055, 1.7068, 1.7113, 1.6847, 1.6945, 1.6830, 1.6816, 1.6683,\n",
       "                      1.7234, 1.7105, 1.7038, 1.7006, 1.6984, 1.7174, 1.6811, 1.7114, 1.7061,\n",
       "                      1.7345, 1.6850, 1.6947, 1.7120, 1.7050, 1.6986, 1.7078, 1.7312, 1.6925,\n",
       "                      1.7356, 1.7005, 1.7293, 1.6976, 1.6757, 1.7021, 1.7046, 1.7090, 1.7018,\n",
       "                      1.7039, 1.6876, 1.7146, 1.7071, 1.7026, 1.6909, 1.7227, 1.7030, 1.6893,\n",
       "                      1.7146, 1.7092, 1.6958, 1.7130, 1.7302, 1.6832, 1.6863, 1.7221, 1.7034,\n",
       "                      1.7275, 1.7071, 1.7126, 1.6747, 1.7040, 1.6837, 1.7069, 1.7295, 1.6938,\n",
       "                      1.7032, 1.7206, 1.7075, 1.7175, 1.7032, 1.7077, 1.6964, 1.7067, 1.7034,\n",
       "                      1.7108, 1.7059], device='cuda:0')),\n",
       "             ('blocks.2.update.outt.weight',\n",
       "              tensor([ 0.2627, -2.2449, -0.8066,  ...,  0.1022,  0.7118,  0.0220],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.update.outt.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.2.update.outt.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.2.update.outs.weight',\n",
       "              tensor([[-0.0141, -0.0901, -0.1406,  ..., -0.1377, -0.0798,  0.0911],\n",
       "                      [-0.1397,  0.0558,  0.1011,  ...,  0.0929, -0.0640, -0.0786],\n",
       "                      [ 0.1115, -0.1388,  0.1131,  ..., -0.0840,  0.1121,  0.1195],\n",
       "                      ...,\n",
       "                      [ 0.0854, -0.1015, -0.0031,  ...,  0.0500,  0.0734, -0.1219],\n",
       "                      [-0.1248, -0.0275, -0.0450,  ...,  0.1524, -0.0488,  0.0034],\n",
       "                      [-0.1397,  0.0335, -0.0276,  ...,  0.0086,  0.1121,  0.1107]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.update.outs.bias',\n",
       "              tensor([-5.3279e-04, -3.4720e-04, -4.6567e-04, -2.9632e-03, -4.4610e-03,\n",
       "                       2.0003e-03,  1.3882e-04,  2.8685e-03,  6.8563e-04,  1.0091e-03,\n",
       "                      -1.4536e-03,  6.3031e-04, -2.6507e-03, -1.0080e-04,  1.8635e-07,\n",
       "                       1.1556e-04, -1.6291e-03,  1.9688e-03,  3.2250e-04,  1.3359e-03,\n",
       "                       1.8057e-03, -2.6533e-03,  1.0244e-03, -1.0207e-03, -1.1197e-03,\n",
       "                      -2.5342e-04,  1.7466e-03, -1.5415e-03,  4.8445e-04,  6.3330e-04,\n",
       "                       7.7939e-04, -1.8709e-03,  3.7315e-03,  7.5332e-04, -1.4025e-03,\n",
       "                       6.4711e-04, -9.7901e-04,  1.1535e-03, -9.0734e-04,  4.3779e-05,\n",
       "                      -3.2895e-04,  1.7216e-03,  1.4762e-03,  1.1336e-03,  1.0407e-03,\n",
       "                       5.8825e-04,  1.9790e-03, -1.2569e-03, -2.3143e-03, -8.8101e-04,\n",
       "                      -3.2569e-03,  2.2114e-04, -6.7420e-03,  1.9106e-03,  1.6222e-03,\n",
       "                      -3.8181e-03,  2.1627e-04, -9.7951e-04, -1.8706e-03, -4.1399e-04,\n",
       "                       3.5341e-03,  3.6326e-04, -9.4853e-03, -6.2282e-03,  4.0943e-04,\n",
       "                      -4.5203e-04,  1.9080e-03, -5.5320e-04,  9.8069e-04,  2.8522e-04,\n",
       "                      -1.3520e-03,  1.3801e-03, -1.2070e-03, -6.1219e-04, -2.7801e-03,\n",
       "                       6.9412e-04, -5.1426e-03, -2.5271e-03,  2.3567e-03,  2.9116e-03,\n",
       "                      -1.6130e-03, -1.3556e-03,  3.7486e-03,  1.7517e-03,  7.5023e-04,\n",
       "                      -2.9872e-04, -1.5433e-04,  5.7326e-04,  3.1664e-03, -1.4292e-03,\n",
       "                       1.6282e-03,  1.6464e-03, -7.1869e-04,  5.8831e-04,  5.8729e-04,\n",
       "                       1.8853e-03, -3.3311e-03, -2.4281e-04,  8.2006e-04,  8.3667e-04,\n",
       "                       2.3174e-04,  7.0910e-05,  2.2794e-03,  7.4852e-04, -2.0121e-03,\n",
       "                       1.8910e-03,  5.5700e-04, -2.5327e-03, -5.7464e-03,  7.0099e-04,\n",
       "                       1.5144e-04,  6.2644e-04, -2.7546e-03,  1.5804e-03,  1.6219e-03,\n",
       "                       6.8013e-04, -2.0306e-03,  2.9565e-05, -1.8552e-04, -1.2054e-03,\n",
       "                       1.1542e-03,  8.7310e-04,  6.0600e-03, -3.1055e-03,  1.6024e-03,\n",
       "                      -7.9020e-05, -1.4959e-03,  4.6938e-05], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lq.weight',\n",
       "              tensor([ 1.1538,  0.0997, -0.7603,  ...,  0.1510, -1.1440,  0.0311],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lq.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lq.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lk.weight',\n",
       "              tensor([ 0.5946, -0.9295,  0.0191,  ..., -0.8038,  0.0790,  0.6632],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lk.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lk.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lv.weight',\n",
       "              tensor([ 0.9905,  0.5740, -1.2543,  ..., -0.6494,  0.5812, -1.0359],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lv.bias', tensor([], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lv.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.ls.weight',\n",
       "              tensor([[-0.1258,  0.0301,  0.0351,  ...,  0.1823, -0.1376, -0.1019],\n",
       "                      [ 0.0049,  0.0582,  0.0781,  ..., -0.1067, -0.0354,  0.0343],\n",
       "                      [-0.0828,  0.0040, -0.0936,  ..., -0.0935,  0.0967, -0.0524],\n",
       "                      ...,\n",
       "                      [-0.0442, -0.0317, -0.0913,  ..., -0.0095, -0.0048,  0.0461],\n",
       "                      [ 0.1381, -0.0173,  0.0475,  ..., -0.0632, -0.0493,  0.1206],\n",
       "                      [ 0.0319, -0.0544,  0.0215,  ..., -0.0622, -0.0034,  0.0148]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.ls.bias',\n",
       "              tensor([ 1.1178e-02, -1.7169e-02, -2.5454e-03, -3.3223e-03, -2.4032e-03,\n",
       "                      -2.4834e-02, -5.8629e-03,  1.4017e-03,  7.9434e-04,  3.0466e-03,\n",
       "                      -3.9740e-03,  1.0155e-02, -8.4456e-03, -4.5092e-03, -2.3003e-03,\n",
       "                      -3.2088e-03, -5.7696e-03, -2.5866e-02,  3.2384e-04,  1.3697e-03,\n",
       "                       8.6168e-03,  5.9058e-04,  1.5069e-02, -3.7144e-03, -8.1754e-03,\n",
       "                      -2.8858e-03, -1.1150e-02, -1.1739e-02, -3.9466e-04, -2.2725e-02,\n",
       "                      -1.4216e-03, -3.1290e-04,  1.1627e-02, -1.6457e-02, -3.6300e-03,\n",
       "                      -3.4572e-03, -7.5701e-04, -2.9262e-03, -1.7687e-03, -2.6803e-03,\n",
       "                       1.0609e-03, -2.4800e-03, -5.3319e-03, -3.0645e-03, -2.7343e-03,\n",
       "                      -1.9515e-02,  1.3622e-02, -1.4821e-03, -1.3441e-03, -1.5220e-02,\n",
       "                       6.1245e-03,  1.5647e-04, -1.0029e-03,  3.3740e-03, -6.2856e-03,\n",
       "                      -4.0934e-03, -1.8922e-03,  1.3562e-02, -3.6503e-03, -8.6583e-05,\n",
       "                      -2.2417e-03, -1.3202e-03, -4.7212e-03, -1.6390e-02, -7.8765e-03,\n",
       "                       1.5954e-02, -4.4974e-03,  5.6127e-04,  1.2627e-02, -8.5816e-03,\n",
       "                       1.0292e-02, -6.2057e-04, -8.7409e-03, -8.5991e-03, -2.6321e-03,\n",
       "                      -8.8202e-03, -3.3402e-03, -6.4896e-03,  1.4605e-02, -6.4937e-03,\n",
       "                      -2.1149e-03, -8.3577e-03, -2.7825e-03, -7.1111e-04, -2.9854e-03,\n",
       "                      -3.7338e-03, -1.3922e-03, -3.0261e-03, -4.0414e-03, -2.0411e-02,\n",
       "                       4.2245e-03, -3.1794e-05,  1.4178e-03, -5.3792e-03,  8.5520e-04,\n",
       "                      -9.5518e-04, -8.9725e-03, -4.2656e-03, -2.2783e-03, -1.5927e-02,\n",
       "                      -1.7554e-03,  6.4759e-03, -2.5328e-03, -3.2499e-03, -1.1412e-02,\n",
       "                       3.2299e-04, -1.2815e-02, -8.9656e-04, -6.0834e-03, -5.5478e-04,\n",
       "                      -7.7273e-04, -1.2672e-03, -1.2874e-02, -1.1443e-03,  1.3358e-03,\n",
       "                      -2.5590e-03,  3.4115e-03,  3.0858e-03,  1.1502e-02,  2.4875e-03,\n",
       "                      -4.8551e-03,  3.9682e-04, -7.7385e-03,  2.1379e-04,  3.0773e-03,\n",
       "                       7.6544e-03, -8.2762e-03, -1.7560e-02, -1.2784e-02, -1.4420e-02,\n",
       "                      -9.7366e-03, -1.6545e-02, -9.9035e-03, -7.4718e-03, -1.3143e-02,\n",
       "                      -1.1858e-02, -1.0618e-02, -1.0343e-02, -1.0463e-02, -8.2053e-03,\n",
       "                      -1.0001e-02, -1.4722e-02, -1.1225e-02, -6.9416e-03, -8.6244e-03,\n",
       "                      -1.2620e-02, -1.7933e-02, -1.6044e-02, -1.7490e-02, -1.5274e-02,\n",
       "                      -1.1871e-02, -1.1651e-02, -1.2184e-02, -1.0684e-02, -1.4381e-02,\n",
       "                      -1.1808e-02, -1.3449e-02, -9.6107e-03, -1.4701e-02, -1.2281e-02,\n",
       "                      -1.1160e-02, -9.5464e-03, -1.6458e-02, -1.6834e-02, -7.6746e-03,\n",
       "                      -9.4282e-03, -9.5871e-03, -1.2313e-02, -1.1954e-02, -1.5058e-02,\n",
       "                      -1.3690e-02, -1.2721e-02, -1.0633e-02, -1.1145e-02, -1.4945e-02,\n",
       "                      -1.0985e-02, -7.3331e-03, -1.0015e-02, -9.7719e-03, -1.0537e-02,\n",
       "                      -1.3434e-02, -9.7176e-03, -1.9655e-02, -1.1787e-02, -1.7383e-02,\n",
       "                      -8.1092e-03, -7.8355e-03, -1.5766e-02, -1.1533e-02, -1.1003e-02,\n",
       "                      -8.9607e-03, -1.3118e-02, -1.0953e-02, -9.8767e-03, -1.6421e-02,\n",
       "                      -8.1688e-03, -1.0788e-02, -1.8590e-02, -1.1625e-02, -7.9558e-03,\n",
       "                      -1.1961e-02, -1.2945e-02, -9.9146e-03, -1.0503e-02, -1.3559e-02,\n",
       "                      -7.6883e-03, -1.0774e-02, -1.0160e-02, -1.0170e-02, -1.1844e-02,\n",
       "                      -8.8759e-03, -1.2271e-02, -1.3750e-02, -1.0698e-02, -8.9558e-03,\n",
       "                      -1.2484e-02, -1.0841e-02, -8.8647e-03, -1.1995e-02, -1.0760e-02,\n",
       "                      -2.0178e-02, -8.4250e-03, -1.4509e-02, -9.0628e-03, -1.5624e-02,\n",
       "                      -1.8508e-02, -7.9089e-03, -7.2176e-03, -1.8697e-02,  1.9881e-02,\n",
       "                      -1.1517e-02, -1.6550e-02, -8.0299e-03, -1.0117e-02, -1.5753e-02,\n",
       "                      -1.3792e-02, -1.2281e-02, -1.6548e-02, -1.0610e-02, -1.1597e-02,\n",
       "                      -1.0712e-02, -1.4800e-02, -1.0349e-02, -1.0479e-02, -1.2817e-02,\n",
       "                      -1.2829e-02, -1.6618e-02, -2.2846e-02, -1.1679e-02, -1.2976e-02,\n",
       "                      -1.1409e-02, -1.1540e-02, -1.5698e-02, -1.7697e-02, -1.1831e-02,\n",
       "                      -1.0615e-02], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lvs.weight',\n",
       "              tensor([[-0.0840,  0.1247,  0.0596,  ...,  0.1389, -0.1115,  0.0698],\n",
       "                      [-0.1135,  0.0334, -0.0746,  ..., -0.0594, -0.0816, -0.0506],\n",
       "                      [ 0.0745, -0.1193,  0.1334,  ...,  0.0505,  0.1062, -0.0471],\n",
       "                      ...,\n",
       "                      [-0.0286,  0.0773, -0.0436,  ..., -0.0917,  0.0333, -0.0246],\n",
       "                      [-0.0324,  0.0910,  0.0500,  ..., -0.0080, -0.0458, -0.0082],\n",
       "                      [ 0.0045,  0.0289, -0.1309,  ..., -0.0412,  0.0179,  0.0389]],\n",
       "                     device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.lvs.bias',\n",
       "              tensor([-1.5573e-02, -1.4385e-03,  2.3943e-03, -1.2112e-03, -1.5530e-03,\n",
       "                       7.9018e-04, -1.8430e-04,  3.8171e-03,  1.5526e-03,  2.8335e-03,\n",
       "                       1.0611e-04,  9.3480e-03, -1.5916e-03, -1.8997e-03,  5.5312e-04,\n",
       "                       1.3242e-03, -1.7885e-03, -1.2424e-03,  1.3161e-03, -5.8491e-04,\n",
       "                       1.0075e-02,  3.4353e-03,  1.3243e-02, -1.2711e-04, -1.6669e-03,\n",
       "                       3.8736e-04,  1.1450e-03, -3.9950e-03,  1.4919e-03,  2.6346e-03,\n",
       "                       1.5683e-03,  3.0452e-03,  1.5582e-02,  6.0118e-04,  1.9542e-03,\n",
       "                      -2.7319e-03,  1.5132e-03, -8.0511e-04, -1.1445e-03,  1.2791e-03,\n",
       "                      -1.2768e-03, -8.6798e-05,  2.3211e-04,  1.8509e-03,  2.0605e-06,\n",
       "                      -2.3768e-03,  2.4602e-02, -3.1439e-03, -1.0043e-02, -2.7651e-03,\n",
       "                      -1.8873e-03, -3.5266e-03, -2.2886e-03,  1.9912e-03,  3.2812e-04,\n",
       "                      -1.2922e-03,  1.2977e-03,  7.9080e-03, -6.4308e-04,  2.0240e-03,\n",
       "                       1.3444e-03,  1.3910e-03, -3.5478e-03, -2.3096e-03, -6.5064e-04,\n",
       "                       2.5037e-02,  1.2286e-03,  3.1600e-03, -4.1395e-04, -1.6384e-04,\n",
       "                       3.1321e-03,  5.5636e-03, -1.2905e-03,  5.8705e-04, -2.1323e-04,\n",
       "                      -8.1696e-03, -1.0852e-03,  3.7467e-05,  1.9009e-02,  1.1726e-03,\n",
       "                      -1.4356e-04, -4.1724e-03,  3.7352e-03,  8.1721e-04, -8.5217e-04,\n",
       "                      -2.0997e-03,  4.2399e-04,  1.5704e-03, -8.7120e-06, -8.9831e-04,\n",
       "                      -2.4040e-03,  1.9650e-03, -1.3133e-02, -2.7914e-04,  4.0941e-03,\n",
       "                       5.5468e-03, -2.9281e-03,  1.7605e-04,  5.7152e-04,  4.0371e-03,\n",
       "                      -4.7568e-05, -5.7934e-03, -1.3495e-03,  1.7059e-03, -7.3029e-03,\n",
       "                       1.5057e-03,  1.0303e-03, -9.9040e-04, -1.8642e-03,  1.9790e-03,\n",
       "                       2.5069e-04,  1.3801e-03, -2.5515e-03,  1.3956e-03,  4.3971e-03,\n",
       "                      -7.5258e-04,  3.2002e-03, -3.5436e-03, -1.1138e-02,  2.1858e-03,\n",
       "                       1.4295e-03, -7.0922e-04,  2.2329e-03,  1.0842e-03,  5.9684e-03,\n",
       "                       7.0790e-03, -2.0707e-03, -3.8402e-04], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.tp1.weight', tensor([], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.tp1.output_mask',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1.], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.tp2.weight',\n",
       "              tensor([-1.8807e+00, -1.0081e+00,  1.9593e-01, -8.0879e-01, -6.0979e-01,\n",
       "                       1.5243e-01,  6.3860e-01,  1.4022e+00, -4.6258e-01, -1.3545e+00,\n",
       "                       9.1128e-01, -1.6654e+00,  1.3208e+00,  2.6746e-01, -1.1605e+00,\n",
       "                      -5.5482e-01, -5.6343e-01, -1.6305e-01, -7.5374e-01,  2.0681e-02,\n",
       "                      -2.4881e-01,  2.7485e-01, -7.4598e-01,  8.3031e-02, -4.9696e-02,\n",
       "                       1.4142e+00, -9.9817e-01,  1.5115e+00,  6.9083e-02,  1.0056e+00,\n",
       "                       2.7728e+00, -2.2471e-01, -2.5061e-02, -1.0127e+00, -4.1630e-02,\n",
       "                       2.1148e+00,  1.0153e+00, -1.5123e+00, -3.3175e-01,  1.3170e+00,\n",
       "                      -3.1115e-01, -1.1014e-01,  7.6788e-01,  1.9712e-01,  1.2446e+00,\n",
       "                       4.1756e-01,  7.6322e-02,  3.1698e-01,  1.2571e+00,  4.7391e-01,\n",
       "                       2.1423e+00,  3.5291e-02,  1.7290e+00, -2.6499e-01,  1.3914e+00,\n",
       "                       1.5733e+00,  1.8475e+00,  2.0907e-01, -8.0816e-01,  1.2582e+00,\n",
       "                       7.6290e-01,  5.2592e-01,  4.3892e-01,  5.7329e-01,  1.3732e+00,\n",
       "                      -1.8313e-01,  7.9268e-01,  7.7217e-01,  2.2835e-01,  3.4615e-01,\n",
       "                      -1.1503e+00,  7.3881e-01,  8.3510e-01, -1.1634e+00, -1.3512e+00,\n",
       "                      -1.3046e+00, -3.3262e-01, -1.0150e+00,  9.3206e-01,  1.0463e+00,\n",
       "                      -6.6614e-01, -1.4926e+00,  1.1629e+00, -1.4266e+00, -1.8993e-01,\n",
       "                       5.8077e-01, -1.7349e-01,  1.3974e+00, -1.0794e+00, -2.2312e+00,\n",
       "                      -1.0408e+00, -4.9029e-01,  7.8445e-02,  1.1768e-01, -9.8730e-01,\n",
       "                       1.1078e+00,  5.1903e-01, -1.7162e+00,  2.0089e-01,  1.3764e-02,\n",
       "                       9.6251e-01,  4.9779e-01, -6.7054e-01, -1.4165e-01, -8.0733e-01,\n",
       "                       7.2339e-01,  1.9775e+00, -1.2490e+00, -8.9436e-01,  1.3813e-01,\n",
       "                       4.8083e-04,  2.4970e-01, -5.2752e-01, -6.7609e-02,  1.7160e+00,\n",
       "                       5.5779e-01, -2.9640e-01,  7.9033e-01, -7.7551e-01,  4.2289e-01,\n",
       "                      -5.2451e-01, -6.4704e-02, -1.8374e+00,  9.7718e-01, -6.0433e-01,\n",
       "                       3.7016e-01, -1.9491e+00, -1.2710e+00,  5.7342e-01, -5.8767e-01,\n",
       "                      -1.3744e+00, -1.8448e+00,  1.0693e+00,  6.4292e-01, -3.1561e-01,\n",
       "                       1.2221e-01,  4.3783e-02, -1.6545e+00, -2.0775e+00, -2.5957e-01,\n",
       "                       1.2401e+00, -1.6895e+00,  5.8547e-01,  4.5107e-01,  5.6086e-01,\n",
       "                       1.7266e+00, -2.4750e-03, -5.5861e-01, -1.6346e+00,  4.4259e-01,\n",
       "                      -1.3126e+00,  9.5032e-02,  2.4971e+00, -1.4777e-02,  1.9782e-01,\n",
       "                      -1.1110e+00,  7.0907e-01,  9.8215e-01,  1.6892e+00, -1.8802e-01,\n",
       "                      -9.2647e-01,  1.3697e+00,  5.4811e-02,  3.7977e-01, -2.0581e+00,\n",
       "                      -2.5442e+00,  1.5234e-01, -1.5322e-01,  4.6403e-01, -2.4158e-01,\n",
       "                       1.5516e+00, -9.2919e-01, -1.3282e-01, -6.0326e-01,  3.4798e-01,\n",
       "                      -4.0687e-01, -1.5511e+00, -6.2989e-01, -1.6833e+00, -1.1929e+00,\n",
       "                      -1.1757e+00,  1.4216e+00, -2.9297e-03, -2.7034e+00, -8.3514e-01,\n",
       "                      -5.6102e-01, -1.7128e-01,  2.5129e-01,  2.2831e+00,  1.0132e-01,\n",
       "                       6.1717e-01, -1.9478e+00, -9.6695e-03,  4.4444e-01, -1.5033e+00,\n",
       "                       1.8128e+00,  2.1550e-01, -1.1218e+00, -1.2443e+00, -9.2062e-01,\n",
       "                       6.2745e-01, -2.2403e-01,  9.6391e-02,  1.8637e-02,  1.6273e-01,\n",
       "                       8.4727e-01,  1.4945e+00,  4.1867e-01, -9.5527e-01, -6.1100e-01,\n",
       "                      -2.1669e-01, -1.6598e+00, -1.9201e+00, -1.2749e+00,  2.0241e+00,\n",
       "                       1.0189e+00,  1.7755e-01,  1.1911e+00,  1.2937e+00,  2.4426e-01,\n",
       "                      -7.1566e-01, -1.2027e+00, -1.8249e+00,  6.9217e-01,  4.5545e-01,\n",
       "                      -1.3453e-01, -3.0419e-01, -2.3731e-01, -1.0542e-02, -6.4224e-01,\n",
       "                      -6.9912e-01, -2.0141e+00,  9.8828e-01, -2.5552e-01, -1.0161e+00,\n",
       "                       4.8810e-01, -5.3386e-02, -6.4971e-01, -1.1972e+00, -6.3665e-01,\n",
       "                       8.0707e-01, -6.7039e-01,  8.7787e-01, -5.5211e-01,  2.5707e-01,\n",
       "                      -1.5812e-01,  3.8198e-01,  1.1754e+00,  1.3344e+00, -1.3581e+00,\n",
       "                       1.0068e+00, -1.1493e+00, -2.2999e-01,  5.9969e-03,  1.3318e+00,\n",
       "                       1.1177e+00,  1.2560e+00,  8.1682e-01, -2.1287e-01, -2.3366e-01,\n",
       "                      -6.0957e-01, -1.9517e+00,  2.6958e-01, -1.2479e+00,  4.5468e-02,\n",
       "                      -6.9331e-01,  3.4332e-01,  7.8338e-01, -2.1246e+00,  8.3521e-01,\n",
       "                      -1.3001e+00,  4.5931e-01, -1.4106e+00,  9.6892e-01,  1.9277e-01,\n",
       "                      -3.1793e-01, -2.0024e+00, -1.0028e+00, -1.3520e+00,  6.2957e-01,\n",
       "                      -1.2280e+00, -7.6933e-01, -8.0251e-01,  7.2573e-01, -8.3375e-02,\n",
       "                       3.7241e-01,  1.5299e+00,  1.4172e+00,  5.7923e-01, -3.9009e-02,\n",
       "                      -8.3126e-03,  3.8312e-01, -1.3436e+00,  1.4185e+00, -1.1471e-01,\n",
       "                      -1.2547e+00,  5.0808e-01,  1.8849e-01, -8.8641e-01,  1.0228e+00,\n",
       "                       1.0833e-01, -2.8122e-01,  1.1566e+00, -2.0018e-01, -7.8747e-01,\n",
       "                       2.2443e-01, -5.9945e-01, -1.6714e-01,  4.8714e-01, -3.8754e-02,\n",
       "                      -1.0887e+00, -4.6249e-01, -1.1476e+00, -1.0712e+00, -5.7707e-02,\n",
       "                      -4.9194e-01, -8.7288e-02,  1.5684e-01,  1.3262e+00, -4.1772e-02,\n",
       "                       8.8636e-01,  7.1464e-02, -1.2671e+00,  5.1527e-02, -1.6213e-01,\n",
       "                       5.2997e-01, -6.9937e-01, -3.4600e-01,  6.1679e-01, -1.1668e+00,\n",
       "                      -1.7304e-01,  1.1798e+00, -2.0606e+00,  2.2590e-01, -1.7139e-01,\n",
       "                       1.6951e-02, -5.7360e-01, -2.1319e+00, -3.4969e-01,  9.8113e-01,\n",
       "                       8.2283e-01,  7.6574e-01, -2.3770e+00,  1.0064e+00, -1.4868e+00,\n",
       "                      -9.4179e-03,  1.2512e-01, -2.2956e-01,  3.7505e-01, -1.1091e-01,\n",
       "                       1.3978e+00, -1.9890e-01,  1.1044e+00, -6.6351e-01, -1.3092e+00,\n",
       "                      -1.7298e+00,  1.2256e+00, -5.3344e-01,  5.7546e-01,  2.5280e+00,\n",
       "                      -2.1243e-01, -4.8784e-01,  1.0762e+00, -9.5171e-01,  7.7829e-01,\n",
       "                      -3.5098e-01, -6.0288e-01, -6.1665e-01,  5.1261e-01,  9.2078e-01,\n",
       "                       2.2279e-01, -8.4660e-01,  6.0814e-01, -6.4950e-01,  9.7865e-01,\n",
       "                       6.4208e-01,  2.2058e-01,  1.6317e+00, -2.8956e-01, -2.4450e-01,\n",
       "                       3.1185e-01,  2.1291e-02,  2.0084e+00, -8.4660e-01], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.tp2.output_mask',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.actlvs.alpha',\n",
       "              tensor([1.0221, 0.9952, 1.0012, 0.9988, 0.9982, 1.0000, 0.9986, 1.0021, 1.0021,\n",
       "                      1.0007, 0.9989, 1.0090, 0.9966, 0.9985, 1.0037, 1.0014, 0.9995, 0.9971,\n",
       "                      1.0009, 0.9996, 1.0078, 1.0011, 1.0104, 1.0004, 0.9995, 0.9998, 0.9999,\n",
       "                      0.9994, 1.0003, 1.0016, 0.9887, 1.0021, 1.0124, 0.9990, 0.9991, 0.9999,\n",
       "                      1.0060, 0.9991, 1.0002, 1.0039, 1.0046, 0.9989, 0.9994, 0.9998, 1.0001,\n",
       "                      0.9974, 1.0134, 0.9967, 0.9923, 1.0013, 1.0060, 0.9970, 0.9984, 1.0015,\n",
       "                      0.9993, 0.9991, 1.0009, 1.0076, 1.0023, 1.0014, 1.0006, 1.0003, 1.0018,\n",
       "                      0.9994, 1.0001, 1.0434, 1.0008, 1.0045, 0.9990, 0.9968, 1.0039, 1.0013,\n",
       "                      1.0021, 0.9976, 0.9991, 0.9952, 0.9996, 0.9977, 1.0147, 0.9997, 1.0000,\n",
       "                      0.9987, 1.0000, 1.0030, 0.9991, 1.0014, 1.0001, 1.0053, 0.9989, 1.0017,\n",
       "                      0.9985, 1.0007, 0.9983, 1.0018, 1.0019, 1.0027, 0.9986, 0.9980, 1.0008,\n",
       "                      1.0022, 1.0001, 1.0035, 1.0000, 1.0017, 1.0006, 1.0017, 0.9983, 1.0005,\n",
       "                      1.0061, 1.0033, 0.9999, 1.0005, 1.0022, 1.0009, 1.0068, 1.0006, 0.9988,\n",
       "                      1.0015, 1.0002, 1.0039, 0.9992, 0.9998, 0.9943, 1.0010, 1.0038, 1.0069,\n",
       "                      1.0007, 1.0025], device='cuda:0')),\n",
       "             ('blocks.2.update.uattn.actlvs.beta',\n",
       "              tensor([1.6950, 1.7016, 1.7033, 1.6988, 1.7009, 1.7007, 1.6965, 1.7053, 1.7041,\n",
       "                      1.7034, 1.6994, 1.7112, 1.6987, 1.7052, 1.7070, 1.7020, 1.7016, 1.7041,\n",
       "                      1.7032, 1.7036, 1.7113, 1.7031, 1.7164, 1.7029, 1.7014, 1.7019, 1.7028,\n",
       "                      1.7011, 1.7027, 1.7003, 1.7143, 1.7016, 1.7127, 1.7005, 1.7012, 1.7037,\n",
       "                      1.7067, 1.7024, 1.7021, 1.7071, 1.6953, 1.7009, 1.7006, 1.7019, 1.6992,\n",
       "                      1.7034, 1.7201, 1.6987, 1.6959, 1.7025, 1.6965, 1.6987, 1.7013, 1.7037,\n",
       "                      1.7025, 1.7016, 1.7025, 1.7101, 1.7004, 1.7003, 1.7024, 1.7012, 1.7031,\n",
       "                      1.6985, 1.7014, 1.7407, 1.7040, 1.7063, 1.7070, 1.7014, 1.7049, 1.7035,\n",
       "                      1.6974, 1.6991, 1.6994, 1.7065, 1.7011, 1.7004, 1.7162, 1.7012, 1.7013,\n",
       "                      1.7029, 1.7039, 1.7007, 1.6969, 1.7009, 1.7013, 1.7061, 1.7028, 1.7020,\n",
       "                      1.7002, 1.7029, 1.7009, 1.6988, 1.7050, 1.7094, 1.7010, 1.6997, 1.6997,\n",
       "                      1.7018, 1.7039, 1.6995, 1.7020, 1.7085, 1.7023, 1.7036, 1.7021, 1.6990,\n",
       "                      1.6999, 1.6986, 1.7019, 1.7024, 1.7004, 1.7030, 1.7140, 1.7040, 1.7008,\n",
       "                      1.7056, 1.7016, 1.7052, 1.7026, 1.7006, 1.7024, 1.7036, 1.7060, 1.7090,\n",
       "                      1.7011, 1.7022], device='cuda:0')),\n",
       "             ('sout.mlp.0.weight',\n",
       "              tensor([[ 0.1086,  0.1253, -0.0503,  ..., -0.0365, -0.0219, -0.0767],\n",
       "                      [ 0.0172,  0.1228, -0.0965,  ..., -0.0290, -0.0032,  0.0261],\n",
       "                      [ 0.1422,  0.1258, -0.0844,  ..., -0.0328,  0.0299, -0.1151],\n",
       "                      ...,\n",
       "                      [-0.0401, -0.0169, -0.0531,  ...,  0.1071,  0.0041,  0.0794],\n",
       "                      [ 0.0148, -0.0547,  0.0253,  ...,  0.1213, -0.0336, -0.0329],\n",
       "                      [ 0.1300,  0.0088,  0.0815,  ...,  0.0453,  0.0686, -0.0257]],\n",
       "                     device='cuda:0')),\n",
       "             ('sout.mlp.0.bias',\n",
       "              tensor([ 3.6428e-04, -1.0865e-03, -2.4298e-03,  5.1283e-04, -2.1053e-03,\n",
       "                      -4.2455e-04, -2.4057e-03, -4.8033e-04, -2.7190e-03,  7.9212e-04,\n",
       "                      -1.9209e-04, -5.8699e-04, -8.5039e-04,  8.6800e-04, -9.2641e-04,\n",
       "                       1.3127e-04, -1.7099e-03, -1.9884e-03, -9.2751e-03, -1.1180e-03,\n",
       "                      -1.3660e-03, -1.4498e-03,  1.7263e-03, -3.2933e-03,  3.4874e-04,\n",
       "                      -2.1837e-03, -3.4284e-03,  1.8971e-04, -1.7777e-03,  6.8035e-04,\n",
       "                       7.8141e-04, -1.1324e-03, -1.5006e-03,  4.6695e-04, -5.2689e-03,\n",
       "                       4.3936e-04, -2.4635e-03,  7.6149e-04, -1.4679e-03, -5.6072e-04,\n",
       "                       3.7684e-04, -1.8204e-03,  6.6365e-04, -1.6193e-03, -7.3767e-04,\n",
       "                      -5.0199e-03, -2.2537e-03, -1.4898e-03, -6.5995e-03, -7.0143e-04,\n",
       "                      -1.4108e-03,  1.5844e-03, -3.1676e-05, -3.2422e-03, -3.3354e-03,\n",
       "                      -1.2709e-03, -5.6933e-03,  1.2151e-03,  8.0280e-05, -1.7681e-03,\n",
       "                      -2.4427e-03,  1.9813e-03, -1.8846e-03, -9.2157e-04,  5.4322e-04,\n",
       "                      -2.2045e-03, -1.2691e-03, -4.7731e-04, -1.0585e-03,  6.6295e-04,\n",
       "                       4.0485e-04, -1.4183e-03, -1.2573e-03, -2.8758e-03,  2.8804e-04,\n",
       "                      -1.7872e-03, -8.2160e-04, -1.6775e-03, -3.5637e-03,  5.2019e-04,\n",
       "                      -1.3791e-04, -2.1401e-03, -7.1307e-04,  4.2547e-04, -6.5675e-03,\n",
       "                      -1.3704e-03, -4.8208e-04, -1.0432e-02,  2.1342e-04, -4.4574e-03,\n",
       "                      -4.9046e-04,  1.2557e-03, -1.7223e-03, -2.6059e-03,  6.7780e-04,\n",
       "                       1.4411e-04, -2.9942e-04, -1.4735e-03, -2.3172e-03,  5.8722e-06,\n",
       "                      -1.1441e-03, -3.3520e-03, -2.2684e-03, -6.3429e-04, -2.1070e-04,\n",
       "                      -2.9963e-04, -2.3675e-03, -6.2546e-04, -1.9726e-03, -1.2581e-03,\n",
       "                      -7.8946e-04,  1.5130e-04,  6.8573e-04, -1.3798e-03,  4.8166e-04,\n",
       "                       5.9308e-04,  3.1591e-03, -2.8546e-03, -2.2827e-03, -3.0796e-03,\n",
       "                      -2.2539e-03, -1.2691e-03,  9.5877e-04,  3.3263e-04, -2.0622e-03,\n",
       "                      -2.4070e-03, -1.6581e-03, -1.2789e-03], device='cuda:0')),\n",
       "             ('sout.mlp.1.alpha',\n",
       "              tensor([1.0000, 0.9984, 0.9969, 0.9998, 0.9975, 0.9991, 0.9980, 0.9973, 0.9963,\n",
       "                      0.9942, 0.9999, 0.9983, 0.9997, 0.9980, 1.0028, 1.0001, 0.9976, 0.9980,\n",
       "                      0.9950, 0.9969, 0.9971, 0.9986, 0.9984, 0.9963, 1.0012, 0.9955, 0.9937,\n",
       "                      0.9994, 0.9982, 0.9995, 0.9996, 0.9980, 0.9983, 0.9990, 0.9890, 0.9960,\n",
       "                      0.9974, 0.9999, 0.9979, 0.9973, 0.9995, 0.9932, 0.9997, 0.9962, 1.0014,\n",
       "                      0.9990, 0.9971, 0.9980, 0.9972, 0.9964, 0.9979, 1.0014, 0.9989, 0.9967,\n",
       "                      0.9971, 0.9985, 0.9954, 1.0013, 1.0010, 0.9993, 0.9974, 1.0004, 0.9990,\n",
       "                      0.9975, 1.0003, 0.9969, 0.9989, 0.9978, 0.9982, 0.9996, 0.9998, 0.9974,\n",
       "                      0.9985, 0.9962, 1.0004, 0.9979, 0.9987, 0.9998, 0.9934, 0.9997, 0.9985,\n",
       "                      0.9975, 0.9989, 0.9995, 0.9961, 0.9953, 0.9999, 0.9939, 0.9970, 0.9930,\n",
       "                      0.9978, 0.9972, 0.9982, 0.9967, 1.0003, 0.9990, 0.9987, 0.9983, 0.9969,\n",
       "                      0.9989, 0.9984, 0.9964, 0.9958, 0.9977, 0.9992, 0.9989, 0.9971, 0.9964,\n",
       "                      0.9982, 0.9986, 0.9990, 0.9986, 0.9994, 0.9986, 0.9989, 0.9992, 1.0022,\n",
       "                      0.9952, 0.9967, 0.9946, 0.9961, 0.9988, 0.9999, 0.9990, 0.9976, 0.9965,\n",
       "                      0.9968, 0.9985], device='cuda:0')),\n",
       "             ('sout.mlp.1.beta',\n",
       "              tensor([1.7031, 1.7001, 1.6983, 1.7021, 1.6978, 1.7022, 1.7009, 1.6996, 1.6981,\n",
       "                      1.7012, 1.7021, 1.6992, 1.7024, 1.7008, 1.7030, 1.6994, 1.6997, 1.7000,\n",
       "                      1.7106, 1.7047, 1.6969, 1.7007, 1.7005, 1.6995, 1.7025, 1.7030, 1.6990,\n",
       "                      1.7015, 1.7011, 1.7020, 1.7019, 1.7019, 1.7005, 1.6969, 1.7056, 1.7030,\n",
       "                      1.7024, 1.7017, 1.6979, 1.7029, 1.7022, 1.6949, 1.7026, 1.7011, 1.7025,\n",
       "                      1.7054, 1.6984, 1.6973, 1.6982, 1.7008, 1.7031, 1.6990, 1.7008, 1.7009,\n",
       "                      1.6998, 1.7003, 1.7026, 1.7035, 1.7029, 1.7014, 1.7039, 1.7030, 1.7029,\n",
       "                      1.6996, 1.7018, 1.6992, 1.7010, 1.7019, 1.6995, 1.7009, 1.7024, 1.7026,\n",
       "                      1.6984, 1.7046, 1.7002, 1.7008, 1.7001, 1.7018, 1.6954, 1.7020, 1.7023,\n",
       "                      1.7029, 1.7035, 1.7001, 1.6992, 1.7011, 1.7022, 1.7104, 1.7009, 1.6956,\n",
       "                      1.7001, 1.7005, 1.7001, 1.7018, 1.7013, 1.7017, 1.7013, 1.7015, 1.6989,\n",
       "                      1.6983, 1.7026, 1.7043, 1.6979, 1.7026, 1.7003, 1.6970, 1.7007, 1.6999,\n",
       "                      1.7003, 1.7028, 1.7008, 1.7090, 1.6992, 1.7029, 1.7005, 1.7007, 1.6986,\n",
       "                      1.6973, 1.6985, 1.6965, 1.7031, 1.7004, 1.7022, 1.7001, 1.6995, 1.6964,\n",
       "                      1.7010, 1.7022], device='cuda:0')),\n",
       "             ('sout.mlp.3.weight',\n",
       "              tensor([[-4.7942e-02,  1.5055e-01,  1.5131e-01, -8.4674e-02,  3.8418e-03,\n",
       "                       -6.9738e-02, -2.4473e-02, -2.1150e-01,  6.6745e-02, -4.5937e-02,\n",
       "                        7.4982e-02,  1.5943e-01,  1.5245e-01, -1.9054e-02,  1.0524e-01,\n",
       "                        5.0796e-02,  1.5135e-01,  7.3501e-02, -9.0573e-02, -1.1660e-01,\n",
       "                       -2.0386e-01,  1.3358e-01, -9.9484e-02,  1.9429e-02, -1.8588e-01,\n",
       "                        2.1113e-02,  1.3693e-02, -1.0878e-01, -4.4460e-02, -5.8298e-02,\n",
       "                       -6.9726e-02, -1.1723e-01,  4.0894e-02, -1.7071e-01,  1.6307e-01,\n",
       "                       -2.9445e-02, -1.9282e-01, -6.8719e-02,  1.0269e-01, -8.7050e-02,\n",
       "                       -1.9221e-01, -1.2057e-01, -1.9170e-01,  1.6118e-01,  1.5846e-01,\n",
       "                       -1.3808e-01,  7.1646e-02,  1.9654e-01,  1.9027e-04,  8.2477e-02,\n",
       "                       -6.4223e-02,  4.8146e-02, -1.1253e-01,  5.0732e-02,  4.6695e-02,\n",
       "                        6.7297e-02,  1.6747e-01, -1.1862e-01, -3.2590e-02,  1.2406e-01,\n",
       "                       -1.8803e-03, -6.7963e-02,  1.3920e-01, -1.6111e-01,  1.3726e-01,\n",
       "                        1.9605e-01,  1.7012e-02, -5.2562e-02,  2.0054e-01, -1.0250e-01,\n",
       "                       -1.3926e-01,  6.4554e-02,  1.7956e-01, -1.1274e-02,  1.6751e-01,\n",
       "                        2.0951e-01, -5.9229e-02,  1.6898e-01,  1.1345e-01, -1.7449e-02,\n",
       "                       -5.9508e-02,  6.9296e-02, -8.6939e-02, -1.5821e-01, -5.7333e-04,\n",
       "                        8.3359e-02,  1.2246e-01, -1.1855e-01, -2.0499e-01,  1.8440e-01,\n",
       "                       -2.0053e-01, -3.2020e-02,  6.4181e-02,  1.3265e-01, -1.2584e-01,\n",
       "                       -1.3669e-01, -4.1504e-02,  5.7595e-02,  2.1188e-01, -1.7802e-01,\n",
       "                       -1.3397e-01, -1.4290e-01,  2.7855e-02, -1.5074e-01,  1.2098e-01,\n",
       "                        2.0381e-01, -3.4592e-03,  1.3619e-01,  4.0889e-03,  1.4198e-01,\n",
       "                       -1.7960e-01, -1.4019e-01, -1.8949e-01,  1.8833e-01, -2.0653e-01,\n",
       "                       -1.7856e-01, -1.1395e-01,  1.0711e-01,  1.5561e-01,  1.7207e-01,\n",
       "                        1.9016e-01,  3.0190e-02, -1.2715e-01, -2.0565e-01, -1.1977e-01,\n",
       "                        1.1008e-01, -1.7753e-01, -9.0920e-03]], device='cuda:0')),\n",
       "             ('sout.mlp.3.bias', tensor([-0.0014], device='cuda:0'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''After the training is completed, take out the learnable parameters and save them as a .pth file.'''\n",
    "state_dict=model.state_dict\n",
    "\n",
    "state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d200f0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'npacharge_param.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040d6d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''When needed model , simply load parameters on the untrained model. The parameters we have trained are saved in trained_Param/.'''\n",
    "state_dict=torch.load('npacharge_param.pth')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70369f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
